# 企业文化

## Supercell（超级细胞）

- 倒金字塔结构

    > 传统的金字塔型的组织架构是工业革命时代的产物，在流水线一样的工厂里，工作都是标准的，工人们只需日复一日地重复同样的事情，不允许犯任何错误。可是，这种做法，在游戏业甚至是所有创意行业却是行不通的。

    - 全体团队成员都需要具备很强的主动性。那些对他人依赖性强的人不太适合这种工作环境。它使人们意见更好地融合，每个人都像参与到我们正在做的事情中，形成了一种良好、健康的工作环境。

    - CEO埃卡·潘纳宁：自认为是“行业内最没权力的CEO”。他在每个项目中只有两个权力：

        - 1.审批一个团队的组建
        - 2.审批一个游戏是否可以从Beta测试进入全球上线的阶段

    - 决策权掌握在开发团队手中：那些真正参与研发的开发者们就有更多的自由，也能萌发更多的创意，他们做的决定越多，往往也更好更高效，因为决策者是真正接触用户的人。

        - 《部落冲突》的游戏主管伊诺·乔司：“我不是决定事物的人，我会提出我认为存在的问题的地方、可以改进的地方，但我不是做决定的人。团队做决定。我作为协调者，组织团队一起讨论并达成统一意见。我曾经提出过一些想法，被团队完全否决了。”

    - 要做到真正放权，就要容忍失败：失败并不是一件可耻的事情，如果一款游戏证明不具备竞争力，他们就会果敢地砍掉，甚至还会开香槟庆祝。

        - Supercell推出了5款商业化游戏，创作出《卡通农场》、《部落冲突》、《海岛奇兵》和《皇室战争》等大作。而在这些光鲜亮丽的背后，鲜为人知的是，他们砍掉了超过20款游戏。

    - 缺点：

        - 沟通很困难：我们把注意力集中在自己的事情上，没有有效地分享信息。

- 小团队+中台：开发过程中公共和通用的游戏素材和算法整合起来，并积累了非常科学的研发工具和框架体系，构建了一个功能非常强大的中台。这样强大的中台可以支持若干个小团队在短时间内开发出一款新的游戏。

    - 团队小而精：CEO说：“游戏行业竞争太激烈，未来难以预测。你只能尽可能组建最优秀的团队，允许这些团队在最好的工作环境下工作，从而实现成功几率的最大化。归根结底，这几乎是你所能够掌控的唯一一件事情。”

    - 阿里例子：

        - 每个电商业务都会涉及到商品信息，订单，支付，仓储，物流等等这样的通用系统，但各个板块之间数据不能共享，势必造成更大的浪费。

        - 阿里的6大中台（兵种）：

            | 中台     |                                                                                                                         |
            |----------|-------------------------------------------------------------------------------------------------------------------------|
            | 业务中台 | 提供重用服务，例如用户中心、订单中心之类的开箱即用可重用能力，为战场提供了空军支援能力，随叫随到，威力强大             |
            | 数据中台 | 提供数据分析能力，帮助从数据中学习改进，调整方向，为战场提供了海军支援能力                                              |
            | 算法中台 | 提供算法能力，帮助提供更加个性化的服务，增强用户体验，为战场提供了陆军支援能力，随机应变，所向披靡                      |
            | 技术中台 | 提供自建系统部分的技术支撑能力，帮助解决基础设施，分布式数据库等底层技术问题，为前台特种兵提供了精良的武器装备         |
            | 研发中台 | 提供自建系统部分的管理和技术实践支撑能力，帮助快速搭建项目、管理进度、测试、持续集成、持续交付，是前台特种兵的训练基地 |
            | 组织中台 | 为项目提供投资管理、风险管理、资源调度等，是战场的指挥部，战争的大脑，指挥前线，调度后方                                |

    - 国内的一众互联网科技公司包括腾讯、百度、京东、滴滴等，都开始了中台建设的步伐。

- 员工可以跳到别的岗位上：觉得自己的兴趣和才华在别处的员工，工作室允许他们自由地移动到别的部门。

# 理论
## Little’s Law（利特尔法则）

- [infoq：跟我一起认识 Little’s Law](https://www.infoq.cn/article/uzfdjVym5vEPRA8DOxYG)

    - Little’s Law：延迟和吞吐的关系是受并发数影响的，抛开并发数去找另外两者的关系是没有规律的。

        - 并发用户数：指真正对服务发送请求的用户数量，需要注意和在线用户数的区别

            - 例子：在线用户数为 1000，其中只有 100 个用户的操作触发了与远端服务的交互，并发用户数是 100

        - 响应时间：Little’s Law 中是“平均响应时间”，而实际工作中“分位值”来作为响应时间的统计值来衡量性能的。平均值只是作为一个辅助参考。

            - 例子：平均工资通常没多大参考价值，有可能很多人是被平均的。

            - 分为值：假如一共有100个请求，那么排在第90位的响应时间就是90分位值。有90分位、95分位、75分位。
                ![image](./Pictures/soft-architecture/分为值.avif)

    - 并发数 = 吞吐量 * 响应时间

        - 假如一个程序只有 1 个线程，这个线程每秒可以处理 10 次事件，那么我们说这个程序处理单次事件的延迟为 100ms，吞吐为 10 次/秒。

        - 假如一个程序有 4 个线程，每个线程每秒可以处理 5 次事件，那么我们说这个程序处理单次事件的延迟为 200ms，吞吐为 20 次/秒。

        - 假如一个程序有 1 个线程，每个线程每秒可以处理 20 次事件，那么我们说这个程序处理单次事件的延迟为 50ms，吞吐为 20 次/秒。

    ![image](./Pictures/soft-architecture/Little’s-Law.avif)

    - 拐点：并发用户数增加，吞吐量开始出现下降的趋势，同时响应时间也开始增大

    - 在“拐点”之前和刚进入拐点这段区域：系统是“稳定”的，并发数、吞吐量、平均响应时间是符合 Little’s Law 公式的。

## 长尾理论

- 长尾理论：原来不受到重视的销量小但种类多的产品或服务由于总量巨大，累积起来的总收益超过主流产品的现象。在互联网领域，长尾效应尤为显著。

    - 例子：亚马逊40%的书本销售来自于本地书店里不卖的书本。音乐影视串流市场、智能手机应用市场、线上游戏市场陆续发生这种现象，网络选择客制化的兴起也让实体市场产品逐渐零碎化，例如名不见经传的餐厅在网络市场下爆红。

    - 例子：亚马逊一半左右的销售来自于比较热门的商品，而另一半却来自相对不那么热门的商品。这跟传统的“二八定律（80%的业绩来自20%的产品）”完全相反

# SRE (Site Reliability Engineering，可靠性工程）

- SRE 的出发点是可用性是成功的先决条件。


- SLO：定义每个服务的用户可以接受的最低可靠性水平，然后将其作为你的 SLO
    - 例子：在一个月之中，99.9% 的请求延迟有在 300ms 内

        - 为什么不是100%？因为服务越可靠，其运营成本就越高。

- SLA:基于 SLO 制定的商业合约。承诺其 SLO 应在一段时间内达到特定水准，若未达到一段时间内保证的目标则会产生惩罚机制，比如向客户退款，或免费提供客户更长的服务订阅时间等。

    - 超出 SLO 会伤害到整体业务团队，因此服务应努力保持在 SLO 内。

# 微服务

## 微服务理论

- [邱小侠：微服务架构的理论基础 - 康威定律](https://developer.aliyun.com/article/8611)

    - 康威四大定律：

        - 1.组织的沟通和系统设计之间的紧密联系。对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计。

            - 沟通成本 = n(n-1)/2，沟通成本随着项目或者组织的人员增加呈指数级增长。

                - 博物学家古尔德说：组织体大小很大程度上决定组织形态。蜘蛛真变得像大象一样大，那么它的形态也会变得和大象类似。

                - 亚马逊的Bezos这样比喻：如果2个披萨不够一个团队吃的，那么这个团队就太大了。一般一个互联网公司小产品的团队差不多就是7，8人左右（包含前后端测试交互用研等，可能身兼数职）。

                | 人数            | 复杂度                                |
                |-----------------|---------------------------------------|
                | 5个人的项目组   | 需要沟通的渠道是 5*(5–1)/2 = 10       |
                | 15个人的项目组  | 需要沟通的渠道是15*(15–1)/2 = 105     |
                | 50个人的项目组  | 需要沟通的渠道是50*(50–1)/2 = 1225    |
                | 150个人的项目组 | 需要沟通的渠道是150*(150–1)/2 = 11175 |

            - Dunbar Number（邓巴数）：150个人是人类的维系关系的极限

                | 关系             | 个数      |
                |------------------|-----------|
                | 亲密（intimate） | 朋友: 5   |
                | 信任（trusted）  | 朋友: 15  |
                | 接近（close）    | 朋友: 35  |
                | 临时（casual）   | 朋友: 150 |

                ![image](./Pictures/soft-architecture/Dunbar'Number.avif)

        - 2.时间再多一件事情也不可能做的完美，但总有时间做完一件事情

            - 对于一个巨复杂的系统，我们永远无法考虑周全。Eric Hollnagel认为最好的解决办法是抓主线

                - 有点类似于毛泽东说的《不要四面出击》

            - Eric被一家航空公司请去做安全咨询顾问，复杂保证飞机飞行系统的稳定性和安全性。Eric认为做到安全有两种方式：

                - 1.常规的安全：指的是尽可能多的发现并消除错误的部分，达到绝对安全，这是理想。
                - 2.弹性安全：即使发生错误，只要及时恢复，也能正常工作，这是现实。

                - 对于飞机这样的复杂系统，再牛逼的人也无法考虑到漏洞的方方面面，所以Eric建议放弃打造完美系统的想法，而是通过不断的试飞，发现问题，确保问题发生时，系统能自动复原即可，而不追求飞行系统的绝对正确和安全。

                - 类似于持续集成、敏捷开发：

                    - 对于一个分布式系统，我们几乎永远不可能找到并修复所有的bug，单元测试覆盖1000%也没有用。解决方法不是消灭这些问题，而是容忍这些问题，在问题发生时，能自动回复，微服务组成的系统，每一个微服务都可能挂掉，这是常态，我们只有有足够的冗余和备份即可。即所谓的 弹性设计（Resilience） 或者叫高可用设计（High Availability）。

        - 3.独立自治的子系统减少沟通成本

            - 如果你的团队分成前端团队，Java后台开发团队，DBA团队，运维团队，你的系统就会长成下面的样子

                ![image](./Pictures/soft-architecture/subsystem.avif)

            - 如果你的系统是按照业务边界划分（微服务架构）

                - 定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。

                ![image](./Pictures/soft-architecture/subsystem1.avif)

        - 4.分而治之

            - 人多管不过来啊，找几个经理帮我管，我管经理

            - 每个经理都被赋予一定的职责去做大系统的某一小部分，他们和大系统便有了沟通的边界，所以大的系统也会因此被拆分成一个个小团队负责的小系统（微服务）

### 谁适合微服务？

- 微服务比较适合未来有一定的扩展复杂度，且有很大用户增量预期的应用，说人话就是新兴的互联网公司

    ![image](./Pictures/soft-architecture/microservice.avif)

- [王者荣耀为什么不使用微服务架构？](https://www.zhihu.com/question/359630395/answer/954452799)

    - 游戏的核心在于10 个人之间各种游戏事件的高速网络通信

        - 微服务为了把业务完美拆解，把原来的同一个进程里的模块拆分成不同的服务，显著增加额外的网络开销。

## 微服务架构

- [邱小侠：微服务（Microservice）那点事](https://developer.aliyun.com/article/2764)

    - 分布式：按功能拆分成独立的服务，跑在独立的一般都在独立的虚拟机上

    - API Gateway：提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合

        - 有可能成为单点故障点或者性能的瓶颈。

        ![image](./Pictures/soft-architecture/API-Gateway.avif)

    - 服务之间如何通信？

        ![image](./Pictures/soft-architecture/communication.avif)

        - 同步调用：

            - REST（JAX-RS）
            - RPC（Dubbo）

        - 异步消息调用：

            - 能成为调用之间的缓冲，确保消息积压不会冲垮被调用方

            - 不过需要付出的代价是一致性的减弱，需要接受数据最终一致性

            - 后台服务一般要实现幂等性，因为消息发送出于性能的考虑一般会有重复（保证消息的被收到且仅收到一次对性能是很大的考验）

            - 必须引入一个独立的 broker，如果公司内部没有技术积累，对 broker 分布式管理也是一个很大的挑战。

            | 软件   |
            |--------|
            | Kafka  |
            | Notify |
            | MetaQ  |

    - 负载均衡：每一个服务都是有多个拷贝。一个服务随时可能下线，也可能应对临时访问压力增加新的服务节点。
        - 通过 zookeeper 等类似技术做服务注册信息的分布式管理

            - 服务上线时，服务提供者将自己的服务信息注册到 ZK（或类似框架）
            - 通过心跳维持长链接，实时更新链接信息
            - 服务调用者通过 ZK 寻址，根据可定制算法，找到一个服务，还可以将服务信息缓存在本地以提高性能
            - 当服务下线时，ZK 会发通知给服务客户端

## 度量方式

- 要以业务价值为导向，而不是研发人员产出为导向

    - 错误例子：以代码量、功能数

    - 正确例子：前置时间（lead time）、周期时间（cycle time）。这些用户推崇的整体质量交付。

## 工程

### 微信

- [腾讯技术工程：月活 12.8 亿的微信是如何防止崩溃的？](https://cloud.tencent.com/developer/article/2010913)

    - 单体服务，一个事件只用一个请求，但微服务下，一个事件可能要请求很多的服务，任何一个服务过载失败，就会造成其他的请求都是无效的。

    - 如何判断过载？

        - 为什么不使用响应时间？因为响应时间是跟服务相关的，很多微服务是链式调用，响应时间是不可控的，也是无法标准化的，很难作为一个统一的判断依据。

        - 为什么不使用 CPU 负载：CPU 负载高不代表服务过载，因为一个服务请求处理及时，CPU 处于高位反而是比较良好的表现。

        - 通常判断过载可以使用吞吐量，延迟，CPU 使用率，丢包率，待处理请求数，请求处理事件等等。

            - 微信使用在请求在队列中的平均等待时间作为判断标准，就是从请求到达，到开始处理的时间。腾讯微服务默认的超时时间是 500ms，通过计算每秒或每 2000 个请求的平均等待时间是否超过 20ms，判断是否过载，这个 20ms 是根据微信后台 5 年摸索出来的门槛值。

    - 过载保护策略：

        - 1.业务优先级

            ![image](./Pictures/soft-architecture/wechat-priority.avif)

        - 2.用户优先级

            > 微信分了几十个业务优先级，每个业务优先级下有 128 个用户优先级，所以总的优先级是几千个。

            - 通过 hash 用户唯一 ID，计算用户优先级，为了防止出现总是打豆豆的现象，hash 函数每小时更换
            - 为啥不采用会话 ID 计算优先级呢？采用会话 ID 在用户重新登录时刷新，用户会养成坏习惯，在服务有问题时就会重新登录，这样无疑进一步加剧了服务的过载情况。

        - 3.自适应优先级调整

### QQ音乐

- [腾讯云开发者：优雅应对故障：QQ音乐怎么做高可用架构体系？](https://cloud.tencent.com/developer/article/2206300)

    - 1.异地双中心：

        - 深圳和上海各有API-Gateway（接入层）：从而实现STGW（腾讯基于 Nginx 自研的支持大规模并发的七层负载均衡服务）

            ![image](./Pictures/soft-architecture/qq-music.avif)

        - 逻辑层：深圳读/写；上海只读，上海的写请求由API网关路由到深圳中心处理

        - 存储层：深圳写入存储，通过同步中心/存储组件同步到上海。同步组件为[Cmongo（腾讯研发的MongoDB）](https://github.com/Tencent/CMONGO)和CKV+（腾讯自研的分布式kv数据库）

            - [CKV+之进化历程](https://cloud.tencent.com/developer/article/1387361)
                - 兼容redis协议
                - 多租户模式
                - CKV+在最终一致的数据同步基础上，引入了基于Raft协议的强一致同步逻辑

    - 2.异地容灾：在API网关上做故障转移，降低客户端参与度。

        ![image](./Pictures/soft-architecture/qq-music1.avif)

        - 1.API网关故障转移：当本地中心API返回失败时（包括触发熔断和限流），API网关把请求路由到异地处理。以此解决API故障的场景。

            - 为防止异地重试流量被压垮，出现双中心雪崩，要有自适应重试方案，在异地成功率下降的时候，取消重试：

                - 引入重试窗口：耗光后，取消重试

        - 2.客户端故障转移：当API网关发生超时的时候，客户单进行异地重试。如果网关有回包，即使API返回失败，客户端也不重试。解决API网关故障的场景。

        - 当双中心的API-Gateway均异常：所有客户端请求冻结一段时间。

    - 3.自适应限流：请求量超出阈值后在主调直接丢弃请求，在集群扩缩容后需要及时更新限流阈值

    - 4.熔断：

        ![image](./Pictures/soft-architecture/qq-music2.avif)

        - 当“统一权限”服务的其中一个依赖服务（比如歌曲权限配置服务）出现故障时，只能被动的等待依赖服务报错或者请求超时，下游连接池会逐渐被耗光，入口请求大量堆积，CPU、内存等资源逐渐耗尽，导致服务宕掉。
        - 而依赖“统一权限”服务的上游服务，也会因为相同的原因出现故障，一系列的级联故障最终会导致整个系统宕掉。

        - 传统熔断器 有三种状态：Closed、Half Open、Open

            - Open状态：拒绝所有请求

            - 进入Closed状态时瞬间会有大量请求，服务端可能还没有完全恢复，会导致熔断器又切换到Open状态，一种比较刚性的熔断策略。

        - SRE熔断器 有两种状态：Closed、Half-Open

            - 根据请求成功率自适应地丢弃请求，尽可能多地让请求成功请求到服务端，是一种更弹性的熔断策略。

            - 熔断器阈值：

                - 正常情况下 requests（窗口时间内请求数） = accepts（正常处理的请求数） 时丢弃概率为0。
                - K：敏感度，K越小丢弃概率越大，一般在1.5-2之间

                - requests不断减少直到 requests 等于 K * accepts 时：熔断器就会打开，并按照概率丢弃请求。

            - QQ音乐采用SRE熔断器

    - 动态超时

        - 微服务架构的演进，超时逐渐被标准化到RPC中

        - 传统超时会设定一个固定的阈值，响应时间超过阈值就返回失败。

        - 微服务基于EMA算法动态调整超时时长。

            - [EMA算法](https://github.com/jiamao/ema-timeout)是综合利用历史上积累到的数据，预测下一个周期内的期望。EMA算法引入“平均超时”的概念，用平均响应时间代替固定超时时间，只要平均响应时间没有超时即可，而不是要求每次都不能超时。

    - 服务分级

        - 每日邮件推送1级服务和2级服务的观测数据

        - 为针对1级服务和2级服务制定SLO（达到某一段时间内的目标数值），签订SLA（无法完成商业承诺，就付出代价）

        - API-Gateway根据服务分级限流，优先确保1级服务通过

        | 等级                                                           | 例子                                         |
        |----------------------------------------------------------------|----------------------------------------------|
        | 1级 ：如果出现故障会导致用户或业务产生重大损失                 | 登录服务、流媒体服务、权限服务、数专服务等。 |
        | 2级 ：如果出现故障会导致用户体验受到影响，但是不会完全无法使用 | 排行榜服务、评论服务等。                     |
        | 3级 ：不容易注意或很难发现                                     | 用户头像服务，弹窗服务等。                   |
        | 4级 ：即使失败，也不会对用户体验造成影响                       | 比如红点服务等。                             |

    - 工具链：在故障触发之前，尽可能多地识别风险，针对性地加固和防范，而不是等着故障发生。

        - 混沌工程：通过注入网络超时等故障，主动找出系统中的脆弱环节

            - QQ音乐使用ChaosMesh结合其他组件打造的混沌工程平台

        - 全链路压测：通过注入流量给系统施加压力的方式，来发现系统的性能瓶颈

        - Prometheus + Grafana做可视化展示

            - 秒级监控：基于Prometheus构建联邦集群，每3秒抓取一次数据，实现了准实时监控。并对活动进行快照采集，记录活动发生时所有微服务的请求峰值

            - 历史数据回溯：当我们需要回溯近一个月甚至一年前的指标趋势时，性能是个极大挑战。由于历史数据的精度要求不高。通过Prometheus联邦进行阶梯降采样，可以永久存放历史数据，同时也极大降低存储成本。
        - Logging

            - ELK（ElasticSearch、Logstash、Kibana）构建日志处理平台

                ![image](./Pictures/soft-architecture/qq-music-Logging.avif)

            - Filebeat 作为日志采集和传送器。Filebeat监视服务日志文件并将日志数据发送到Kafka。Kafka 在Filebeat和Logstash之间做解耦。
            - Logstash 解析多种日志格式并发送给下游。ElasticSearch 存储Logstash处理后的数据，并建立索引以便快速检索。
            - Kibana 是一个基于ElasticSearch查看日志的系统，可以使用查询语法来搜索日志，在查询时制定时间和日期范围或使用正则表达式来查找匹配的字符串。

        - Tracing追踪：一个客户端请求由系统中大量微服务配合完成处理，这增加了定位问题的难度。

            - Tracing在触发第一个调用时生成关联标识Trace ID，我们可以通过RPC把它传递给所有的后续调用，就能关联整条调用链。Tracing还通过Span来表示调用链中的各个调用之间的关系。

            - QQ音乐基于jaeger构建分布式链路追踪系统，实现分布式架构下的事务追踪、性能分析、故障溯源、服务依赖拓扑。

                - 1.jaeger client发送的spans通过jaeger-agent（代理）转发到jaeger-collector。
                - 2.jaeger-collector 接收后，验证和清洗数据后转发至kafka。
                - 3.jaeger-ingester 从kafka消费数据，并存储到ElasticSearch。
                - 4.jaeger-query 封装用于从ElasticSearch中检索traces的APIs。

                ![image](./Pictures/soft-architecture/qq-music-jaeger.avif)

        - profile：基于[conprof](https://github.com/geekgao/conprof)搭建持续性能分析系统

        - Dumps

            - core dumps：在进程崩溃时把进程内存写入一个镜像中以供分析，或者把panic信息写到日志中

                - 在容器环境中实施困难，panic信息写入日志则容易被其他日志冲掉且感知太弱。

            - QQ音乐使用的方式是在RPC框架中以拦截器的方式注入，发生panic后上报到sentry平台。
