# 企业文化

## Supercell（超级细胞）

- 倒金字塔结构

    > 传统的金字塔型的组织架构是工业革命时代的产物，在流水线一样的工厂里，工作都是标准的，工人们只需日复一日地重复同样的事情，不允许犯任何错误。可是，这种做法，在游戏业甚至是所有创意行业却是行不通的。

    - 全体团队成员都需要具备很强的主动性。那些对他人依赖性强的人不太适合这种工作环境。它使人们意见更好地融合，每个人都像参与到我们正在做的事情中，形成了一种良好、健康的工作环境。

    - CEO埃卡·潘纳宁：自认为是“行业内最没权力的CEO”。他在每个项目中只有两个权力：

        - 1.审批一个团队的组建
        - 2.审批一个游戏是否可以从Beta测试进入全球上线的阶段

    - 决策权掌握在开发团队手中：那些真正参与研发的开发者们就有更多的自由，也能萌发更多的创意，他们做的决定越多，往往也更好更高效，因为决策者是真正接触用户的人。

        - 《部落冲突》的游戏主管伊诺·乔司：“我不是决定事物的人，我会提出我认为存在的问题的地方、可以改进的地方，但我不是做决定的人。团队做决定。我作为协调者，组织团队一起讨论并达成统一意见。我曾经提出过一些想法，被团队完全否决了。”

    - 要做到真正放权，就要容忍失败：失败并不是一件可耻的事情，如果一款游戏证明不具备竞争力，他们就会果敢地砍掉，甚至还会开香槟庆祝。

        - Supercell推出了5款商业化游戏，创作出《卡通农场》、《部落冲突》、《海岛奇兵》和《皇室战争》等大作。而在这些光鲜亮丽的背后，鲜为人知的是，他们砍掉了超过20款游戏。

    - 缺点：

        - 沟通很困难：我们把注意力集中在自己的事情上，没有有效地分享信息。

- 小团队+中台：开发过程中公共和通用的游戏素材和算法整合起来，并积累了非常科学的研发工具和框架体系，构建了一个功能非常强大的中台。这样强大的中台可以支持若干个小团队在短时间内开发出一款新的游戏。

    - 团队小而精：CEO说：“游戏行业竞争太激烈，未来难以预测。你只能尽可能组建最优秀的团队，允许这些团队在最好的工作环境下工作，从而实现成功几率的最大化。归根结底，这几乎是你所能够掌控的唯一一件事情。”

    - 阿里例子：

        - 每个电商业务都会涉及到商品信息，订单，支付，仓储，物流等等这样的通用系统，但各个板块之间数据不能共享，势必造成更大的浪费。

        - 阿里的6大中台（兵种）：

            | 中台     |                                                                                                                         |
            |----------|-------------------------------------------------------------------------------------------------------------------------|
            | 业务中台 | 提供重用服务，例如用户中心、订单中心之类的开箱即用可重用能力，为战场提供了空军支援能力，随叫随到，威力强大             |
            | 数据中台 | 提供数据分析能力，帮助从数据中学习改进，调整方向，为战场提供了海军支援能力                                              |
            | 算法中台 | 提供算法能力，帮助提供更加个性化的服务，增强用户体验，为战场提供了陆军支援能力，随机应变，所向披靡                      |
            | 技术中台 | 提供自建系统部分的技术支撑能力，帮助解决基础设施，分布式数据库等底层技术问题，为前台特种兵提供了精良的武器装备         |
            | 研发中台 | 提供自建系统部分的管理和技术实践支撑能力，帮助快速搭建项目、管理进度、测试、持续集成、持续交付，是前台特种兵的训练基地 |
            | 组织中台 | 为项目提供投资管理、风险管理、资源调度等，是战场的指挥部，战争的大脑，指挥前线，调度后方                                |

    - 腾讯例子：

        - 引擎中台对接的是腾讯以及外部的各大实验室，比如腾讯优图实验室、AILab实验室、XLab实验室等等，还有一些安全平台，证照库等。

        - 业务中台，是指在逻辑层有很多公用的服务，我们不需要每一个模块都去实现，有很多公用的服务可以抽取到业务中台去实现，比如像图像的处理、视频处理、下载代理，计费上报等。

        - 数据中台,因为每个业务都会有很多相关的数据处理，比如说计费、统计、业务报表、质量、分析、收入成本、客户分析对账等等，所以这一块我们统一抽象成了一个数据中台。


- 员工可以跳到别的岗位上：觉得自己的兴趣和才华在别处的员工，工作室允许他们自由地移动到别的部门。

# 理论
## Little’s Law（利特尔法则）

- [infoq：跟我一起认识 Little’s Law](https://www.infoq.cn/article/uzfdjVym5vEPRA8DOxYG)

    - Little’s Law：延迟和吞吐的关系是受并发数影响的，抛开并发数去找另外两者的关系是没有规律的。

        - 并发用户数：指真正对服务发送请求的用户数量，需要注意和在线用户数的区别

            - 例子：在线用户数为 1000，其中只有 100 个用户的操作触发了与远端服务的交互，并发用户数是 100

        - 响应时间：Little’s Law 中是“平均响应时间”，而实际工作中“分位值”来作为响应时间的统计值来衡量性能的。平均值只是作为一个辅助参考。

            - 例子：平均工资通常没多大参考价值，有可能很多人是被平均的。

            - 分为值：假如一共有100个请求，那么排在第90位的响应时间就是90分位值。有90分位、95分位、75分位。
                ![image](./Pictures/soft-architecture/分为值.avif)

    - 并发数 = 吞吐量 * 响应时间

        - 假如一个程序只有 1 个线程，这个线程每秒可以处理 10 次事件，那么我们说这个程序处理单次事件的延迟为 100ms，吞吐为 10 次/秒。

        - 假如一个程序有 4 个线程，每个线程每秒可以处理 5 次事件，那么我们说这个程序处理单次事件的延迟为 200ms，吞吐为 20 次/秒。

        - 假如一个程序有 1 个线程，每个线程每秒可以处理 20 次事件，那么我们说这个程序处理单次事件的延迟为 50ms，吞吐为 20 次/秒。

    ![image](./Pictures/soft-architecture/Little’s-Law.avif)

    - 拐点：并发用户数增加，吞吐量开始出现下降的趋势，同时响应时间也开始增大

    - 在“拐点”之前和刚进入拐点这段区域：系统是“稳定”的，并发数、吞吐量、平均响应时间是符合 Little’s Law 公式的。

## 长尾理论

- 长尾理论：原来不受到重视的销量小但种类多的产品或服务由于总量巨大，累积起来的总收益超过主流产品的现象。在互联网领域，长尾效应尤为显著。

    - 例子：亚马逊40%的书本销售来自于本地书店里不卖的书本。音乐影视串流市场、智能手机应用市场、线上游戏市场陆续发生这种现象，网络选择客制化的兴起也让实体市场产品逐渐零碎化，例如名不见经传的餐厅在网络市场下爆红。

    - 例子：亚马逊一半左右的销售来自于比较热门的商品，而另一半却来自相对不那么热门的商品。这跟传统的“二八定律（80%的业绩来自20%的产品）”完全相反

# 软技能

- [腾讯云开发者：如何成为优秀工程师之软技能篇](https://zhuanlan.zhihu.com/p/587383325)

- [阿里开发者：六年团队Leader实战秘诀｜程序员最重要的八种软技能](https://developer.aliyun.com/article/933310?spm=a2c6h.14164896.0.0.40ddd46eXOv9U4)

- [腾讯大讲堂：一篇文章入门专利写作（万字干货）](https://cloud.tencent.com/developer/article/2092422?areaSource=&traceId=)

# 基础设施

- 德国的防核弹机房

    - 机房处在一个乡下的地方，上空是德国政府规定禁飞区，房子是一米多厚的混凝土墙，门是钢板的，地下每一层要经过好几道铁门可以进去。

    - 在法国有数据备份

    - 两套电力系统

# api设计

- [阿里技术：深度 | API 设计最佳实践的思考](https://developer.aliyun.com/article/701810?spm=a2c6h.12873639.0.0.33e56605iyuCWs)

- [苏三说技术：瞧瞧别人家的API接口，那叫一个优雅](https://juejin.cn/post/7176220436714225721)

# 架构师

- [腾讯云开发者：优秀程序员，如何提高架构能力？](https://cloud.tencent.com/developer/article/1722323)

    - 架构发展史：

        - 1.演进就是技术编程框架为核心，展开的一系列规划和解耦部分

        - 2.就进入了高并发、分布式，应对大流量的状态。更加注重的是外围基础设施

        - 3.基于数据的应用架构，也就是越来越多的基于数据的挖掘产生新的应用。

    - 架构是随着整个行业的发展和社会需要去发展的：

        - 1.在 2000 年前后是门户、社交时代，PC 互联网蓬勃爆发的年代，有四大门户。互联网主要是新闻内容传递为主。

            - CDN 蓬勃发展
            - 技术上从编译型语言，逐步过度到动态解释性语言的广泛应用
            - 关系型数据库也开始被广泛应用。开始大量应用缓存，弥补关系型数据库存取能力不足的一些场景需求。

        - 2.移动互联网阶段:需要更强的存储和计算能力。云计算，大规模机器开始出现

        - 3.在 IoT 广泛应用之前不会再有指数级终端设备联网，基础工程能力不再是问题。

            - 在大数据、AI 架构方面发展。比如，如何用图数据库解决复杂关系图谱的问题，GPU 集群、弹性计算、机器学习框架都越来越重要。

    - 架构要根据从用户需求出发

        - 在不同时期抓住用户当时的核心痛点，演进架构，解决掉用户的这些问题，才能成功。

        - 而不是根据已有的技术能力，YY 出产品功能，然后推给用户，可想而知，这样的产品一定会被用户用脚投票，无论背后的技术架构多么巧妙，业务注定会失败。

    - 系统的可用性：根据当月的不可用时间除以当月的总时间

        - 问题：在低峰期和高峰期挂掉十分钟，对业务的影响可能会相差很大

            - 腾讯在内部计算可用性：从请求的角度出发。被拒绝的请求量，加上超时的请求量，然后除以总的请求量

    - 可用性要考虑亚健康：

        - 我们总是假设系统里面的服务器状态是正常的或故障的。没有考虑亚健康：交换机转发能力下降、CPU 有降频、内存在做 ECC 纠错、，硬盘异常导致 IO 延迟陡增

        - 建设全链路的探测和监控，快速地把这些异常的，处于亚健康状态的节点剔除。

    - 长期方案固然要有，但短期方案也非常重要。不一定需要用最理想和技术方案去解决，但可以借鉴架构的思路。

    - 生产架构本质上也是一种架构：

        - 贝壳业务都是在白天去跑，晚上没有多少人去看房子，这个时候晚上做混沌工程，即使系统短时间出问题影响也没有那么大，还有时间修复。

    - 降级方式取决于这个架构师对于业务的了解：在什么条件下熔断什么样的东西对我们的损失是最小的？这件事情反映了一个架构师是不是对技术有非常深刻的了解

        - 做高可用架构的时候首先技术肯定是要好的。只要技术很好，业务场景不了解的话，会带来非常大的问题

    - 接手一个完全陌生领域的业务系统，比从零开始的项目要难：

        - 错误做法：把整个系统的边际和现在的系统逻辑过程看完，然后把业务梳理完，最后自己把这样的业务和技术重新地、完整地设计出一个新的架构，完全全新，基于他自己思想。

            - 问题：这是一个时间的过程，如果是一步到位的话，很容易会翻船。

                - 最理想的那个好到现实的差：其实它的距离感不仅来自于技术的好坏，还有来自于对业务的理解，以及你对团队的理解，包括来自于你对时间和商业成本的考虑。

                - 那么什么才是最好呢？要随着时间的发展去看，前提条件是第一次要让这个系统能够可用，并且达到商业目标，这是最快要做的，剩下的事情就是心中的理想。

    - 接受一个全新项目时：

        - 错误做法：花至少 1 年时间，比如要花一到两个季度调研某个技术，然后再花半年时间去做相应的落地

        - 正确做法：快速地试错，然后先把这个原型搭出来。看看这个是不是用户要的，高可用、高并发、高性能，哪个方面更重要，就投入相应的资源在上面去做相应的演进。

            - 先把整个代码的关键逻辑和分层结构列出来、画出来，弄清楚有哪些模块，模块之间是怎么通讯的，中间件都有哪些，三方服务有哪些等等。之后再去分析风险点，把风险点、呈现的问题和故障列出来，再去设计合理方案。

            - 架构师首先要了解系统现状、业务现状、团队能力现状，再因地制宜。千万不要拿到一个通用解决方案马上就去实施，要去分析自己的业务情况，是不是真的需要高并发、需要低延迟。

    - 如何提升架构能力：

        - linux发展了那么多年到现在架构的精髓依然被应用在非常多的地方，底层核心的东西是不太会变的，一定要去深入理解。

        - 架构的意义在于我们怎么去理解技术的原理，真正深入计算机原理，计算机是什么，存储是什么，为什么今天这样的东西存在，然后去想像这件事情，不停地在这里探索一系列的东西。

        - 要把这个东西尝试着去开源，放到网上让更多的人使用、验证、给你反馈。这个反馈非常重要，总是闭门造车、没有反馈的话架构能力很难提升。

            - 没有用户的话你就做你系统的用户，可以做很多的机器人测试客户端出来，往你的系统发请求

- [腾讯云开发者：大咖们如何评判优秀架构师？](https://cloud.tencent.com/developer/article/1625249)

    - 优秀的架构师要解决一个实际的问题

        - 这只是优秀的程序员，而不是优秀的架构师：Go 语言本身自带垃圾回收机制，很难干涉具体时间点进行垃圾回收，就容易导致系统实时性不足的问题。为了解决这个问题，团队做了很多方案，最后都没法上线，最终决定把 Go 语言的垃圾回收机制关掉。这样导致的内存泄漏，团队负责人竟然不把它算作泄漏，而是对上级重新 “定义” 为“内存增长”，交易关闭的时候重启就好了。

    - 最好的架构师不是具备了多丰富的知识点，他最需要的特质是折中，他可以在任何场景下都给出优雅的设计方案。

        - 不要去过度设计。比如说当前阶段用微服务 1.0 就可以的话，不用再去强行上微服务 2.0，只要架构能够满足当下的业务需求，同时具备未来一段时间的可扩展性就可以了。

         - 腾讯这样的大公司，架构设计上要关注于高并发

         - 对小型团队来说，架构设计更应满足快速迭代、持续交付的特性。

    - 优秀的架构应该满足的关键就是降本增效：是增加了人力和其他成本，还是让人力、运维等降低了，或者让效率提高了？

    - 要具备一个良好的架构认知的思维模型：

        - 在一个比较低级的思维模型里面，你即使学了再多的知识，在我看来也仅仅是低水平的重复。
        - 需要的是更高维度的认知，更高维度的架构设计能力，能够把某个点打穿打透。

    - 架构师要扛起来四门功课：能多打酱油、能和稀泥、肯背黑锅、敢拉仇恨

    - 要搞明白什么地方是重要：

        - 如果时间充裕，架构过程应该在建模、分层、耦合、调用等环节上做到充分论证讨论。

        - 时间紧任务重，横向比较的点，一定要想明白最重要的事情是什么，最重要的目标是什么，可能会有哪些变化？架构师也是一个决策环节，不一定要去做所有不可能完成的任务。

    - 代码写不好，大概率架构设计也不行，因为架构设计的本质还是结构

        - 如果你代码写得好，那么必然具备能做好拆解的前提条件，不然很难说代码写不好的人架构设计能做好。
        - 另外一点，看源码是很好的一点，一些最火的开源项目的源码，社区讨论的 issue，要多去看多去交流，了解别人是怎么做的。

# 架构安全

- 防拖库：个人和住址也要分开存放，用的时候拿到密钥再去组织，密钥也要动态更新，单独被读取只能是一个无法识别的数据片段。

# SRE (Site Reliability Engineering，可靠性工程）

- SRE 的出发点是可用性是成功的先决条件。


- SLO：定义每个服务的用户可以接受的最低可靠性水平，然后将其作为你的 SLO
    - 例子：在一个月之中，99.9% 的请求延迟有在 300ms 内

        - 为什么不是100%？因为服务越可靠，其运营成本就越高。

- SLA:基于 SLO 制定的商业合约。承诺其 SLO 应在一段时间内达到特定水准，若未达到一段时间内保证的目标则会产生惩罚机制，比如向客户退款，或免费提供客户更长的服务订阅时间等。

    - 超出 SLO 会伤害到整体业务团队，因此服务应努力保持在 SLO 内。

# 微服务

## 微服务理论

- [邱小侠：微服务架构的理论基础 - 康威定律](https://developer.aliyun.com/article/8611)

    - 康威四大定律：

        - 1.组织的沟通和系统设计之间的紧密联系。对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计。

            - 沟通成本 = n(n-1)/2，沟通成本随着项目或者组织的人员增加呈指数级增长。

                - 博物学家古尔德说：组织体大小很大程度上决定组织形态。蜘蛛真变得像大象一样大，那么它的形态也会变得和大象类似。

                - 亚马逊的Bezos这样比喻：如果2个披萨不够一个团队吃的，那么这个团队就太大了。一般一个互联网公司小产品的团队差不多就是7，8人左右（包含前后端测试交互用研等，可能身兼数职）。

                | 人数            | 复杂度                                |
                |-----------------|---------------------------------------|
                | 5个人的项目组   | 需要沟通的渠道是 5*(5–1)/2 = 10       |
                | 15个人的项目组  | 需要沟通的渠道是15*(15–1)/2 = 105     |
                | 50个人的项目组  | 需要沟通的渠道是50*(50–1)/2 = 1225    |
                | 150个人的项目组 | 需要沟通的渠道是150*(150–1)/2 = 11175 |

            - Dunbar Number（邓巴数）：150个人是人类的维系关系的极限

                | 关系             | 个数      |
                |------------------|-----------|
                | 亲密（intimate） | 朋友: 5   |
                | 信任（trusted）  | 朋友: 15  |
                | 接近（close）    | 朋友: 35  |
                | 临时（casual）   | 朋友: 150 |

                ![image](./Pictures/soft-architecture/Dunbar'Number.avif)

        - 2.时间再多一件事情也不可能做的完美，但总有时间做完一件事情

            - 对于一个巨复杂的系统，我们永远无法考虑周全。Eric Hollnagel认为最好的解决办法是抓主线

                - 有点类似于毛泽东说的《不要四面出击》

            - Eric被一家航空公司请去做安全咨询顾问，复杂保证飞机飞行系统的稳定性和安全性。Eric认为做到安全有两种方式：

                - 1.常规的安全：指的是尽可能多的发现并消除错误的部分，达到绝对安全，这是理想。
                - 2.弹性安全：即使发生错误，只要及时恢复，也能正常工作，这是现实。

                - 对于飞机这样的复杂系统，再牛逼的人也无法考虑到漏洞的方方面面，所以Eric建议放弃打造完美系统的想法，而是通过不断的试飞，发现问题，确保问题发生时，系统能自动复原即可，而不追求飞行系统的绝对正确和安全。

                - 类似于持续集成、敏捷开发：

                    - 对于一个分布式系统，我们几乎永远不可能找到并修复所有的bug，单元测试覆盖1000%也没有用。解决方法不是消灭这些问题，而是容忍这些问题，在问题发生时，能自动回复，微服务组成的系统，每一个微服务都可能挂掉，这是常态，我们只有有足够的冗余和备份即可。即所谓的 弹性设计（Resilience） 或者叫高可用设计（High Availability）。

        - 3.独立自治的子系统减少沟通成本

            - 如果你的团队分成前端团队，Java后台开发团队，DBA团队，运维团队，你的系统就会长成下面的样子

                ![image](./Pictures/soft-architecture/subsystem.avif)

            - 如果你的系统是按照业务边界划分（微服务架构）

                - 定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。

                ![image](./Pictures/soft-architecture/subsystem1.avif)

        - 4.分而治之

            - 人多管不过来啊，找几个经理帮我管，我管经理

            - 每个经理都被赋予一定的职责去做大系统的某一小部分，他们和大系统便有了沟通的边界，所以大的系统也会因此被拆分成一个个小团队负责的小系统（微服务）

### 谁适合微服务？

- 微服务比较适合未来有一定的扩展复杂度，且有很大用户增量预期的应用，说人话就是新兴的互联网公司

    ![image](./Pictures/soft-architecture/microservice.avif)

- [王者荣耀为什么不使用微服务架构？](https://www.zhihu.com/question/359630395/answer/954452799)

    - 游戏的核心在于10 个人之间各种游戏事件的高速网络通信

        - 微服务为了把业务完美拆解，把原来的同一个进程里的模块拆分成不同的服务，显著增加额外的网络开销。

## 微服务架构

- [邱小侠：微服务（Microservice）那点事](https://developer.aliyun.com/article/2764)

    - 分布式：按功能拆分成独立的服务，跑在独立的一般都在独立的虚拟机上

    - API Gateway：提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合

        - 有可能成为单点故障点或者性能的瓶颈。

        ![image](./Pictures/soft-architecture/API-Gateway.avif)

    - 服务之间如何通信？

        ![image](./Pictures/soft-architecture/communication.avif)

        - 同步调用：

            - REST（JAX-RS）
            - RPC（Dubbo）

        - 异步消息调用：

            - 能成为调用之间的缓冲，确保消息积压不会冲垮被调用方

            - 不过需要付出的代价是一致性的减弱，需要接受数据最终一致性

            - 后台服务一般要实现幂等性，因为消息发送出于性能的考虑一般会有重复（保证消息的被收到且仅收到一次对性能是很大的考验）

            - 必须引入一个独立的 broker，如果公司内部没有技术积累，对 broker 分布式管理也是一个很大的挑战。

            | 软件   |
            |--------|
            | Kafka  |
            | Notify |
            | MetaQ  |

    - 负载均衡：每一个服务都是有多个拷贝。一个服务随时可能下线，也可能应对临时访问压力增加新的服务节点。
        - 通过 zookeeper 等类似技术做服务注册信息的分布式管理

            - 服务上线时，服务提供者将自己的服务信息注册到 ZK（或类似框架）
            - 通过心跳维持长链接，实时更新链接信息
            - 服务调用者通过 ZK 寻址，根据可定制算法，找到一个服务，还可以将服务信息缓存在本地以提高性能
            - 当服务下线时，ZK 会发通知给服务客户端

- [腾讯云开发者：日调1000亿，腾讯微服务平台的架构演进](https://cloud.tencent.com/developer/article/1701134)

    - 服务发现：需要一个地方记录 IP

        - 传统架构：通过 IP 和 port 来进行互相调用

        - 微服务架构：使用 K8s 和 docker，每次启动的 IP 也可能会变

            - ServiceB 的每个实例在启动时，会将自身的 IP 和 port 写入到服务发现模块的某个路径，然后 ServiceA 会从这个路径来拉取到想要访问的 ServiceB 的服务提供者的列表。

        - 组件有zookeeper，nacos，Consul等：

            - Consul： 和 Spring 的对接也很成熟，很多中小型公司，特别是比较新的公司很多都会选择 Consul 来作为服务注册发现。
                - 服务注册请求、心跳请求会被翻译成kv，然后存储到server上。
                - 服务发现会将服务注册请求、心跳请求的kv内容合并，然后返回

## 度量方式

- 要以业务价值为导向，而不是研发人员产出为导向

    - 错误例子：以代码量、功能数

    - 正确例子：前置时间（lead time）、周期时间（cycle time）。这些用户推崇的整体质量交付。

## 工程

### 微信

- [腾讯技术工程：月活 12.8 亿的微信是如何防止崩溃的？](https://cloud.tencent.com/developer/article/2010913)

    - 单体服务，一个事件只用一个请求，但微服务下，一个事件可能要请求很多的服务，任何一个服务过载失败，就会造成其他的请求都是无效的。

    - 如何判断过载？

        - 为什么不使用响应时间？因为响应时间是跟服务相关的，很多微服务是链式调用，响应时间是不可控的，也是无法标准化的，很难作为一个统一的判断依据。

        - 为什么不使用 CPU 负载：CPU 负载高不代表服务过载，因为一个服务请求处理及时，CPU 处于高位反而是比较良好的表现。

        - 通常判断过载可以使用吞吐量，延迟，CPU 使用率，丢包率，待处理请求数，请求处理事件等等。

            - 微信使用在请求在队列中的平均等待时间作为判断标准，就是从请求到达，到开始处理的时间。腾讯微服务默认的超时时间是 500ms，通过计算每秒或每 2000 个请求的平均等待时间是否超过 20ms，判断是否过载，这个 20ms 是根据微信后台 5 年摸索出来的门槛值。

    - 过载保护策略：

        - 1.业务优先级

            ![image](./Pictures/soft-architecture/wechat-priority.avif)

        - 2.用户优先级

            > 微信分了几十个业务优先级，每个业务优先级下有 128 个用户优先级，所以总的优先级是几千个。

            - 通过 hash 用户唯一 ID，计算用户优先级，为了防止出现总是打豆豆的现象，hash 函数每小时更换
            - 为啥不采用会话 ID 计算优先级呢？采用会话 ID 在用户重新登录时刷新，用户会养成坏习惯，在服务有问题时就会重新登录，这样无疑进一步加剧了服务的过载情况。

        - 3.自适应优先级调整

### QQ音乐

- [腾讯云开发者：优雅应对故障：QQ音乐怎么做高可用架构体系？](https://cloud.tencent.com/developer/article/2206300)

    - 1.异地双中心：

        - 深圳和上海各有API-Gateway（接入层）：从而实现STGW（腾讯基于 Nginx 自研的支持大规模并发的七层负载均衡服务）

            ![image](./Pictures/soft-architecture/qq-music.avif)

        - 逻辑层：深圳读/写；上海只读，上海的写请求由API网关路由到深圳中心处理

        - 存储层：深圳写入存储，通过同步中心/存储组件同步到上海。同步组件为[Cmongo（腾讯研发的MongoDB）](https://github.com/Tencent/CMONGO)和CKV+（腾讯自研的分布式kv数据库）

            - [CKV+之进化历程](https://cloud.tencent.com/developer/article/1387361)
                - 兼容redis协议
                - 多租户模式
                - CKV+在最终一致的数据同步基础上，引入了基于Raft协议的强一致同步逻辑

    - 2.异地容灾：在API网关上做故障转移，降低客户端参与度。

        ![image](./Pictures/soft-architecture/qq-music1.avif)

        - 1.API网关故障转移：当本地中心API返回失败时（包括触发熔断和限流），API网关把请求路由到异地处理。以此解决API故障的场景。

            - 为防止异地重试流量被压垮，出现双中心雪崩，要有自适应重试方案，在异地成功率下降的时候，取消重试：

                - 引入重试窗口：耗光后，取消重试

        - 2.客户端故障转移：当API网关发生超时的时候，客户单进行异地重试。如果网关有回包，即使API返回失败，客户端也不重试。解决API网关故障的场景。

        - 当双中心的API-Gateway均异常：所有客户端请求冻结一段时间。

    - 3.自适应限流：请求量超出阈值后在主调直接丢弃请求，在集群扩缩容后需要及时更新限流阈值

    - 4.熔断：

        ![image](./Pictures/soft-architecture/qq-music2.avif)

        - 当“统一权限”服务的其中一个依赖服务（比如歌曲权限配置服务）出现故障时，只能被动的等待依赖服务报错或者请求超时，下游连接池会逐渐被耗光，入口请求大量堆积，CPU、内存等资源逐渐耗尽，导致服务宕掉。
        - 而依赖“统一权限”服务的上游服务，也会因为相同的原因出现故障，一系列的级联故障最终会导致整个系统宕掉。

        - 传统熔断器 有三种状态：Closed、Half Open、Open

            - Open状态：拒绝所有请求

            - 进入Closed状态时瞬间会有大量请求，服务端可能还没有完全恢复，会导致熔断器又切换到Open状态，一种比较刚性的熔断策略。

        - SRE熔断器 有两种状态：Closed、Half-Open

            - 根据请求成功率自适应地丢弃请求，尽可能多地让请求成功请求到服务端，是一种更弹性的熔断策略。

            - 熔断器阈值：

                - 正常情况下 requests（窗口时间内请求数） = accepts（正常处理的请求数） 时丢弃概率为0。
                - K：敏感度，K越小丢弃概率越大，一般在1.5-2之间

                - requests不断减少直到 requests 等于 K * accepts 时：熔断器就会打开，并按照概率丢弃请求。

            - QQ音乐采用SRE熔断器

    - 动态超时

        - 微服务架构的演进，超时逐渐被标准化到RPC中

        - 传统超时会设定一个固定的阈值，响应时间超过阈值就返回失败。

        - 微服务基于EMA算法动态调整超时时长。

            - [EMA算法](https://github.com/jiamao/ema-timeout)是综合利用历史上积累到的数据，预测下一个周期内的期望。EMA算法引入“平均超时”的概念，用平均响应时间代替固定超时时间，只要平均响应时间没有超时即可，而不是要求每次都不能超时。

    - 服务分级

        - 每日邮件推送1级服务和2级服务的观测数据

        - 为针对1级服务和2级服务制定SLO（达到某一段时间内的目标数值），签订SLA（无法完成商业承诺，就付出代价）

        - API-Gateway根据服务分级限流，优先确保1级服务通过

        | 等级                                                           | 例子                                         |
        |----------------------------------------------------------------|----------------------------------------------|
        | 1级 ：如果出现故障会导致用户或业务产生重大损失                 | 登录服务、流媒体服务、权限服务、数专服务等。 |
        | 2级 ：如果出现故障会导致用户体验受到影响，但是不会完全无法使用 | 排行榜服务、评论服务等。                     |
        | 3级 ：不容易注意或很难发现                                     | 用户头像服务，弹窗服务等。                   |
        | 4级 ：即使失败，也不会对用户体验造成影响                       | 比如红点服务等。                             |

    - 工具链：在故障触发之前，尽可能多地识别风险，针对性地加固和防范，而不是等着故障发生。

        - 混沌工程：通过注入网络超时等故障，主动找出系统中的脆弱环节

            - QQ音乐使用ChaosMesh结合其他组件打造的混沌工程平台

        - 全链路压测：通过注入流量给系统施加压力的方式，来发现系统的性能瓶颈

        - Prometheus + Grafana做可视化展示

            - 秒级监控：基于Prometheus构建联邦集群，每3秒抓取一次数据，实现了准实时监控。并对活动进行快照采集，记录活动发生时所有微服务的请求峰值

            - 历史数据回溯：当我们需要回溯近一个月甚至一年前的指标趋势时，性能是个极大挑战。由于历史数据的精度要求不高。通过Prometheus联邦进行阶梯降采样，可以永久存放历史数据，同时也极大降低存储成本。
        - Logging

            - ELK（ElasticSearch、Logstash、Kibana）构建日志处理平台

                ![image](./Pictures/soft-architecture/qq-music-Logging.avif)

            - Filebeat 作为日志采集和传送器。Filebeat监视服务日志文件并将日志数据发送到Kafka。Kafka 在Filebeat和Logstash之间做解耦。
            - Logstash 解析多种日志格式并发送给下游。ElasticSearch 存储Logstash处理后的数据，并建立索引以便快速检索。
            - Kibana 是一个基于ElasticSearch查看日志的系统，可以使用查询语法来搜索日志，在查询时制定时间和日期范围或使用正则表达式来查找匹配的字符串。

        - Tracing追踪：一个客户端请求由系统中大量微服务配合完成处理，这增加了定位问题的难度。

            - Tracing在触发第一个调用时生成关联标识Trace ID，我们可以通过RPC把它传递给所有的后续调用，就能关联整条调用链。Tracing还通过Span来表示调用链中的各个调用之间的关系。

            - QQ音乐基于jaeger构建分布式链路追踪系统，实现分布式架构下的事务追踪、性能分析、故障溯源、服务依赖拓扑。

                - 1.jaeger client发送的spans通过jaeger-agent（代理）转发到jaeger-collector。
                - 2.jaeger-collector 接收后，验证和清洗数据后转发至kafka。
                - 3.jaeger-ingester 从kafka消费数据，并存储到ElasticSearch。
                - 4.jaeger-query 封装用于从ElasticSearch中检索traces的APIs。

                ![image](./Pictures/soft-architecture/qq-music-jaeger.avif)

        - profile：基于[conprof](https://github.com/geekgao/conprof)搭建持续性能分析系统

        - Dumps

            - core dumps：在进程崩溃时把进程内存写入一个镜像中以供分析，或者把panic信息写到日志中

                - 在容器环境中实施困难，panic信息写入日志则容易被其他日志冲掉且感知太弱。

            - QQ音乐使用的方式是在RPC框架中以拦截器的方式注入，发生panic后上报到sentry平台。

### 携程

- [腾讯云社区：计算压力倍增，携程度假起价引擎架构演变](https://cloud.tencent.com/developer/inventory/334/article/1625083)

    - 任务队列：旅游产品不像单品售卖，产品价格是由多种资源组成（机票、酒店、火、X等）,任意一项资源价格、库存发生变化，都会导致整包价改变，变量太多。

        - 任务队列在算完机票资源之后，再算酒店，算完酒店后进行单选项资源处理，最终汇总出价格。

        - 1.0版本：

            - 任务队列：

                - 用MySQL做任务队列，并且针对每个任务队列同步到sqlserver。分了2个库，64张表

                - 之后用Redis的根据资源分成多队列，代替mysql

        - 2.0版本：

            - 任务队列：Kafka代替redis

            - 任务生成：我们引入了分布式计算框架Spark，从原有的.net代码体系切换到Java

            - 线路聚合：

                - 航线1北京->上海和航线2上海->北京->上海，进行聚合，从而减少请求

        - 3.0版本：

            - 任务生成：首先是消息对产品进行解析，拿到产品的出发地、出发日期，再结合其他的信息，把这些相关的信息写到分布式文件系统里面，再通过Spark进行不同资源的聚合排序，然后再把它写回到分布式文件系统里面，接着通过某一个job去把这些信息取出来，然后把消息发送出去。

                - HDFS分布式文件系统把任务信息分发到下一步的这一个步骤简化了，在消息发送的时候，直接通过Spark进行消息发送，比如它里面可能有几百个节点，我们这几百个节点同时发送这个消息

            - 数据库：HBase替换MySQL

            - 依然存在的瓶颈问题：价格库存依赖外部的资源。外部资源的变化对系统是黑盒，只能依赖API离线计算，API的调用量也会有限制等。也就是活包

        - 缓存预热：对外的价格日历班期查询是有用到缓存的，整个缓存我们相当于是7×24小时不间断一直在写入，所以其实也不怎么存在预热的问题。

- [腾讯云社区：日均20亿流量：携程机票查询系统的架构升级](https://cloud.tencent.com/developer/article/1624858)

    - 三个独立的数据中心

    - SpringCloud + K8s + AWS云服务

    - AI的应用：

        - 反爬虫：屏蔽掉9%的流量

        - 查询筛选：在聚合服务中找出价值最高实际用户，然后把他们的请求发到引擎当中。对于一些实际价值没有那么高的，更多的是用缓存

        - 智能设置TTL生命周期：TTL与业务密切相关的

            - 缓存一致性例子：刚刚看到一个低价机票，点进去就没有了。这种情况出现的原因可能是什么呢？大家知道，航空公司的低价舱位票，一次可能就只放出来几张，如果是热门航线，可能同时有几百人在查询。所以，几百人都可能会看到这几张票，它就会出现在缓存里边。如果已经有10个人去订了票，其他人看到缓存再点进去，运价就已经失效了。

            - 解决方法：
                - 1.缓存超过固定阈值就强行清除。
                - 2.动态刷新：在达到固定阈值之前，有用户查询就刷新缓存


        ![image](./Pictures/soft-architecture/携程-机票查询-AI应用.avif)

    - 缓存架构：

        - 一级缓存是最终的结果，二级缓存是中间结果

            - 聚合服务需要多个返回结果的话，那么很大程度上都是先读一级缓存，一级缓存没有命中的话，再从二级缓存里面去读中间结果

        ![image](./Pictures/soft-architecture/携程-机票查询-缓存架构.avif)

        - 一级缓存：

            - 使用了Redis
            - 固定的TTL，一般低于5分钟的，一些场景下可能只有几十秒

        - 二级缓存：

            - 一开始使用MongoDB，后来改为Redis
            - 通过AI设定的TTL，使得命中率提升了27%

        - 缓存预热：一个分布式的，可能有一小部分节点，比如要下线或者什么，但是对整个缓存机制来说影响很小，然后这一部分请求又分散到我们的多个服务器上，几乎不会产生太大的抖动的。

    - 负载均衡Pooling：我们有一些计算非常密集的引擎，存在一些耗时长，耗费CPU资源比较多的子任务，同时这些子任务中可能夹杂着一些实时请求，所以这些任务可能会留在线程里边，阻塞整个流程。

        - 把子任务放在queue里，将节点作为worker，总是动态的去取，每次只取一个，计算完了要么把结果返回，要么把中间结果再放回queue。

            - queue基于Redis队列，有的键值里加入了IP地址

                - 为什么不使用消息队列？由于它存在很明显的顺序性，不能够基于键值去读到你所写的，比如你发送了一个子任务，这时候你要定时去拿这个结果，但是你基于其他的消息队列或者内存队列是没法拿到的

            - 如果有任何实时的外部调用，我们就可以把它分成多次，放进queue进行task的整个提交执行和应用结果的返回。

        ![image](./Pictures/soft-architecture/携程-机票查询-负载均衡.avif)

        - Pooling的过载保护：

            - 如果没有过载保护，很容易就会发生滚雪球效应，queue里面的任务越来越多，当系统取到一个任务的时候，实际上它的原请求可能早就已经timeout了。

            - 当流量实在太高的情况下，把等待时间超过某一个阈值的请求全都扔掉。

            ![image](./Pictures/soft-architecture/携程-机票查询-过载保护.avif)
