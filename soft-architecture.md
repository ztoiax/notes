<!-- vim-markdown-toc GFM -->

* [企业文化](#企业文化)
    * [游戏公司Supercell（超级细胞）](#游戏公司supercell超级细胞)
    * [云计算公司 Snowflake](#云计算公司-snowflake)
    * [华为](#华为)
* [开源相关](#开源相关)
* [项目管理](#项目管理)
* [软技能](#软技能)
* [数据中心（IDC）](#数据中心idc)
* [api设计](#api设计)
* [架构](#架构)
    * [架构设计](#架构设计)
        * [腾讯技术工程：谈谈架构设计](#腾讯技术工程谈谈架构设计)
        * [技术琐话：一家中型互联网公司的架构演进之路](#技术琐话一家中型互联网公司的架构演进之路)
    * [架构师](#架构师)
    * [架构安全](#架构安全)
    * [软件开发](#软件开发)
    * [DevOps](#devops)
    * [SRE (Site Reliability Engineering，可靠性工程）](#sre-site-reliability-engineering可靠性工程)
        * [卡瓦邦噶：SRE 的工作介绍](#卡瓦邦噶sre-的工作介绍)
            * [SRE工作分层](#sre工作分层)
            * [部署服务](#部署服务)
            * [Oncall（保证线上服务的正常运行）](#oncall保证线上服务的正常运行)
            * [制定和交付 SLI/SLO](#制定和交付-slislo)
            * [故障复盘](#故障复盘)
            * [容量规划](#容量规划)
            * [用户支持](#用户支持)
            * [有关做项目没有专业团队得不到训练](#有关做项目没有专业团队得不到训练)
            * [有关背锅](#有关背锅)
            * [面试会问什么？](#面试会问什么)
            * [选择大公司还是小公司？](#选择大公司还是小公司)
                * [如何判断一家公司是否靠谱？](#如何判断一家公司是否靠谱)
    * [DDD(领域驱动设计)](#ddd领域驱动设计)
    * [微服务](#微服务)
        * [微服务理论](#微服务理论)
            * [康威定律](#康威定律)
            * [谁适合微服务？](#谁适合微服务)
        * [微服务架构](#微服务架构)
            * [熔断、隔离、重试、降级、超时、限流，高可用架构流量治理核心策略全掌握](#熔断隔离重试降级超时限流高可用架构流量治理核心策略全掌握)
        * [度量方式](#度量方式)
        * [工程](#工程)
            * [微信](#微信)
            * [QQ音乐](#qq音乐)
            * [携程](#携程)
* [客户端架构](#客户端架构)
* [新技术的危害](#新技术的危害)
* [复杂度，熵增，技术债](#复杂度熵增技术债)

<!-- vim-markdown-toc -->

# 企业文化

## 游戏公司Supercell（超级细胞）

- 倒金字塔结构

    > 传统的金字塔型的组织架构是工业革命时代的产物，在流水线一样的工厂里，工作都是标准的，工人们只需日复一日地重复同样的事情，不允许犯任何错误。可是，这种做法，在游戏业甚至是所有创意行业却是行不通的。

    - 全体团队成员都需要具备很强的主动性。那些对他人依赖性强的人不太适合这种工作环境。它使人们意见更好地融合，每个人都像参与到我们正在做的事情中，形成了一种良好、健康的工作环境。

    - CEO埃卡·潘纳宁：自认为是“行业内最没权力的CEO”。他在每个项目中只有两个权力：

        - 1.审批一个团队的组建
        - 2.审批一个游戏是否可以从Beta测试进入全球上线的阶段

    - 决策权掌握在开发团队手中：那些真正参与研发的开发者们就有更多的自由，也能萌发更多的创意，他们做的决定越多，往往也更好更高效，因为决策者是真正接触用户的人。

        - 《部落冲突》的游戏主管伊诺·乔司：“我不是决定事物的人，我会提出我认为存在的问题的地方、可以改进的地方，但我不是做决定的人。团队做决定。我作为协调者，组织团队一起讨论并达成统一意见。我曾经提出过一些想法，被团队完全否决了。”

    - 要做到真正放权，就要容忍失败：失败并不是一件可耻的事情，如果一款游戏证明不具备竞争力，他们就会果敢地砍掉，甚至还会开香槟庆祝。

        - Supercell推出了5款商业化游戏，创作出《卡通农场》、《部落冲突》、《海岛奇兵》和《皇室战争》等大作。而在这些光鲜亮丽的背后，鲜为人知的是，他们砍掉了超过20款游戏。

    - 缺点：

        - 沟通很困难：我们把注意力集中在自己的事情上，没有有效地分享信息。

- 小团队+中台：开发过程中公共和通用的游戏素材和算法整合起来，并积累了非常科学的研发工具和框架体系，构建了一个功能非常强大的中台。这样强大的中台可以支持若干个小团队在短时间内开发出一款新的游戏。

    - 团队小而精：CEO说：“游戏行业竞争太激烈，未来难以预测。你只能尽可能组建最优秀的团队，允许这些团队在最好的工作环境下工作，从而实现成功几率的最大化。归根结底，这几乎是你所能够掌控的唯一一件事情。”

    - 阿里例子：

        - 每个电商业务都会涉及到商品信息，订单，支付，仓储，物流等等这样的通用系统，但各个板块之间数据不能共享，势必造成更大的浪费。

        - 阿里的6大中台（兵种）：

            | 中台     |                                                                                                                         |
            |----------|-------------------------------------------------------------------------------------------------------------------------|
            | 业务中台 | 提供重用服务，例如用户中心、订单中心之类的开箱即用可重用能力，为战场提供了空军支援能力，随叫随到，威力强大             |
            | 数据中台 | 提供数据分析能力，帮助从数据中学习改进，调整方向，为战场提供了海军支援能力                                              |
            | 算法中台 | 提供算法能力，帮助提供更加个性化的服务，增强用户体验，为战场提供了陆军支援能力，随机应变，所向披靡                      |
            | 技术中台 | 提供自建系统部分的技术支撑能力，帮助解决基础设施，分布式数据库等底层技术问题，为前台特种兵提供了精良的武器装备         |
            | 研发中台 | 提供自建系统部分的管理和技术实践支撑能力，帮助快速搭建项目、管理进度、测试、持续集成、持续交付，是前台特种兵的训练基地 |
            | 组织中台 | 为项目提供投资管理、风险管理、资源调度等，是战场的指挥部，战争的大脑，指挥前线，调度后方                                |

    - 腾讯例子：

        - 引擎中台对接的是腾讯以及外部的各大实验室，比如腾讯优图实验室、AILab实验室、XLab实验室等等，还有一些安全平台，证照库等。

        - 业务中台，是指在逻辑层有很多公用的服务，我们不需要每一个模块都去实现，有很多公用的服务可以抽取到业务中台去实现，比如像图像的处理、视频处理、下载代理，计费上报等。

        - 数据中台,因为每个业务都会有很多相关的数据处理，比如说计费、统计、业务报表、质量、分析、收入成本、客户分析对账等等，所以这一块我们统一抽象成了一个数据中台。


- 员工可以跳到别的岗位上：觉得自己的兴趣和才华在别处的员工，工作室允许他们自由地移动到别的部门。

## 云计算公司 Snowflake 

- CEO弗兰克·斯洛特曼 (Frank Slootman) 出版的一本书《Amp it up》

    >“我们的公司是海军陆战队，不是和平队。平静的生活不属于我们。像我们这样的创业公司，每天都要为了生存而与巨头对抗。我们是偏执狂，时时刻刻感到生存受威胁。加入我们，你必须有战斗心态。”

    - 1.加快节奏，时刻要求员工以更快的速度完成工作。
        > 如果你说一周后可以有结果，他就问你为什么不能明天或后天出结果？这倒不是因为着急，而是他要增加所有人的紧迫感。
        > 
        > 公司变大了，就会行动迟缓，不愿意冒险。只有加快节奏，才能让公司始终充满活力，保持兴奋度。
        > 
        > 他说：“要求某人做某事快20%，他们会使用传统策略。如果要求快2,000%，他们将不得不推翻所有基本假设，使用非传统策略，进行重大创新。”

    - 2.要求员工思考一些极端问题，打破传统思维的束缚。
        > 你如何在接下来的六个月内实现你的10年目标？
        > 
        > 如果每周只能工作一天，我们应该如何改变工作方式？
        > 
        > 如果现有的营销渠道都消失了，我们将如何发展新客户？
        > 
        > 产品增加什么特性，可以让价格提高10倍？
        > 
        > 如果你有10倍的资源，会对产品做哪些改变？

    - 3.提出明确的、雄心勃勃的目标，鼓励员工大胆行动。
        > iPod mini 的早期口号是“口袋里有 1,000 首歌曲”，SpaceX 公司的目标是让人类成为“多星球物种”。目标越清晰、越雄心勃勃，传统的惰性思维就越难生存。

    - 4.拒绝平庸的产品。
        > 他采取史蒂夫·乔布斯的标准，产品只有两种，要么是非常棒，要么是一塌糊涂，没有中间等级。
        >
        > 员工开发出新产品和新功能时，他会问：“你兴奋吗？你从心里喜欢它吗？”如果没有得到肯定答复，产品就必须重新调整。

    - 5.一流员工得到高额奖金。
        > 每个季度末，公司都要举行绩效评定，一年要评4次绩效。
        >
        > 绩效分布是一个钟形曲线，高绩效员工总是头部的少数人，可以得到极高的奖金。奖金放在一个奖金池，其他人只能分剩下的奖金，或者根本没有奖金。大多数公司里面，一流员工的薪水，相比他们的贡献都偏低，这不利于激励优秀员工。

    - 6.缩小焦点，他要求员工只关注最重要的事情。
        > “请列出接下来需要解决的100个问题，然后只留下最重要的问题1和问题2，放弃其他98个问题。”
        > 
        > 任何偏离核心使命的事情都会让人分心。对于同一个团队的每个成员，他分别挨个问：“你们团队的优先事项是什么？” 如果答案不一致，他就知道团队不够专注，必须整改。

## 华为

- [一只羊咩咩1995](https://www.bilibili.com/list/watchlater?oid=284344040&bvid=BV1Bc411v7ok)

# 开源相关

- 海尔向一位海外开发者发出律师函，要求他从 GitHub 下架他维护的开源项目：[Home Assistant](https://github.com/Andre0512/hon)

    - 该项目是一个开源智能家电自动化平台，可以让用户控制海尔的智能家电，包括空调、净化器、冰箱等。

- 网易云音乐公司起诉侵权，要求删除。国内的网易云音乐 API 开源项目：[NeteaseCloudMusicApi](https://github.com/Binaryify/NeteaseCloudMusicApi)

    - 该项目是作者用 Node.js 封装的第三方网易云音乐 API，很多网易云音乐的开源客户端都依赖它，目前该项目已删库，仅留下一句：“保护版权,此仓库不再维护”。


# 项目管理

- [腾讯云开发者：项目总延期？需求乱插队？程序员如何做好项目管理](https://cloud.tencent.com/developer/article/2242782)

- 项目管理是「通过别人做成事情」的能力：

    - 例子：汉高祖刘邦有一句经典名言：“夫运筹策帷帐之中，决胜于千里之外，吾不如子房(张良)。镇国家，抚百姓，给馈饟，不绝粮道，吾不如萧何。连百万之军，战必胜，攻必取，吾不如韩信。此三者，皆人杰也，吾能用之，此吾所以取天下也。”正是刘邦具备协调张良、萧何、韩信三人协同工作的能力，才使得其能夺取天下，建立大汉王朝。

- 《项目管理精华》一书将项目管理视为「21 世纪独有的工作」，作者认为每一名知识型工作者都在工作中不知不觉中扮演着「非职业项目经理」的角色。开发者其实就是典型的知识型工作者。

- 《微权力下的项目管理》一书讲到项目经理往往需要有个人魅力去影响他人做事，进而达成目标。项目管理能提升与各类干系人打交道的能力，进而提升一个人在组织内的个人影响力。

- 项目管理的生活的例子：房屋装修。装修工期长，涉及各种材料购置。一次性购置材料会阻碍工人干活，分批购置，又怕丢三落四忙不开；等师傅进场再买，又担心延误工期。除此之外，装修还需要与各类工种打交道，要合理安排各工种工作排序、工期管理。

    - 在装修中，能不能少花点钱，就看一个人“成本管理“做得怎么样；能不能快点住进新房子取决于一个人的“进度管理”；而能不能住的安心，就要看“质量管理”有没有做好。

- 项目管理上的痛点：

    | 痛点问题           |                                                |
    |--------------------|------------------------------------------------|
    | 工作量评估问题     | 工作量评估不准确                               |
    | 进度问题           | 日常杂事或者临时问题打乱排期                   |
    | 外部依赖问题       | 设计/后台等外部资源延期/需求变更，怎么推动解决 |
    | 沟通问题           | 如何让大家对需求的理解保持一致                 |
    | 效率和质量平衡问题 | 怎么既保证开发效率又保证质量                   |

    ![image](./Pictures/soft-architecture/项目管理的好坏.avif)

- 如何做好进度管理：

    - 1.如何做好工作量的评估

        - 做好工作量评估是做好进度管理最关键的一步

        - 1.做好详细需求方案的设计。
            - 在做完后，再通过有开发经验的工作人员评审。

                - 一般经验丰富的开发人员能够通过设计方案发现背后的风险，能够及时将架构设计的不合理、兼容性未考虑等问题提前暴露出来，同时也能更加明确工作量。理论上来说，在完成需求方案评审后，后续的改动很少，整体的工作时长更加可控。

            - 如果开发周期大于一个月，建议分成多个需求迭代，以降低迭代周期，小步快跑。

        - 2.合理拆解，明确职责
        ![image](./Pictures/soft-architecture/项目管理拆解.avif)

            - 最好工作拆解的粒度为一至两天。
                - 太长，就会存在工作量评估不准确、整体项目难以把控的问题。不利于工作的合理分配，不能更好地利用人力资源。
                - 太短，就会导致工作交付的频率过快，开发者的工作之间也会存在着一定的耦合。拆解的粒度太小，会增加一定的沟通成本，得不偿失。

            - 成果作为导向原则
                - 任务拆解应该以可交互的结果作为导向，并且一定要有输出。这个输出应该是完整的，不然这个拆解就拆解得不够透彻，或者说不算一个任务。

            - 责任到人原则
                - 拆解之后的任务项，有且只能有一个负责人。即使许多人都可能在其上工作，也只能由一个人负责，其他人只能是参与者。

            - 任务分层原则
                - 任务拆解的过程也是一个解耦的过程，避免多个任务之间有耦合。拆解的过程应该是自上向下的，从一个大的任务，按照其特性进行任务拆解，不断地拆解成子任务，直到拆解到一至两天的工作量，并且是一个可交付的工作项。

            - h5项目例子：一共有四个大的功能模块，三个开发人员
            ![image](./Pictures/soft-architecture/项目管理拆解-h5例子.avif)

        - 3.工作量评估
            - 在对任务进行拆解后，下一步是对任务进行工作量评估。
            - 工作量评估不准确，就会直接导致该任务项出现问题。
                - 评估的时间偏多，会存在着资源浪费的问题
                - 评估的时间偏少，将直接造成当前任务延期完成，同时阻塞后面模块的开发，损失更大。

            - 自上而下的估算方式：
                - 有类似项目经验的工程师来说较容易评估。
                - 将工作结构从头部向尾部依次分配、传递工作量，直到到达WBS 的最底层。
                - 特点是：
                    - 项目初期信息不足，只能初步分解工作结构，很难将最基本的工作详细内容列出来。
                    - 估算的精度较差。
                    - 估算的工作量小，速度快。

            - 自下而上的估算方式：
                - 先估算各个工作项的工作量，再自下而上的将各个工作量进行汇总，算出总的工作量。
                - 特点是：
                    - 估算的精度高。
                    - 估算的成本较大。
                    - 缺少子工作项之间的工作量估算。

    - 2.如何做好依赖管理

        - 项目延期的常见情况
            - 准备开始开发了，发现设计稿还未就绪。
            - 准备联调的时候，发现我们上下游的技术团队的接口还未就绪。
            - 可以联调的时候，因为上下游的链条很长，出现推诿甩锅。

        - 针对外部依赖问题的解决方法

            - 1.明确责任人和交付时间，避免模糊

                - 当一个事情出现多个负责人的时候，责任的边界就会模糊，就容易互相推诿的情况，这就是责任分散效应。
                - 对于每个依赖项，我们需要明确其责任人，并沟通明确每个人对应依赖的交付时间，把责任人和交付时间提前确定清楚，可以减少很多争议和推诿。

                - 当项目涉及很多团队的时候，可以使用资源依赖列表，当遇到问题时，可以快速查找负责人及其应当交付的时间点。
                - 例子：云游 XX 活动的资源依赖列表
                ![image](./Pictures/soft-architecture/项目管理-资源依赖列表.avif)

            - 2.形成信息对齐机制

                - 确定了接口负责人后，如果不及时进行信息对齐，也会出现跑偏的情况。

                    - 例子：A 项目依赖外部的 sdk的 某个升级版。在最初的对齐方案中，sdk 方承诺不会修改原有的接口调用方式。而实际联调中才发现不仅接口调用方式发生了巨大变化，还有部分被依赖的接口直接在新版本中移除，导致A方需要花费大量时间进行兼容。如果提前对齐而不是等到联调阶段才介入，就能规避上述问题。

                - 信息对齐方式

                    - 1.不定期的非正式沟通
                        - 在里程碑等关键节点通过面对面、电话、企业微信等方式进行信息对齐。对齐内容包括：开发进度、依赖事项进展、技术方案变更等，对于一些关键性的结论，最好有文字落地以用于回溯。

                    - 2.定期的例会机制
                        - 如定期晨会机制。在会议上对齐项目进度，可以提前发现可能存在的风险。记录会议纪要并通过群消息/文档/邮件的形式通知到项目的相关干系人。

                    - 3.项目 owner 机制
                        - 应当确定一个项目 owner，对项目整体负责，把关整体节奏，负责组织会议。把相关信息进行整合，并同步给项目的相关干系人。

                    - 4.求同存异，达成共识

                        - 例子：作为最重要的传统节日，很多业务团队都会针对春节这个时间节点运营、上线活动，作者曾经遇到过在临近提测时，活动仍在被提需要大量变更的情况（运营人员要叠加功能，设计人员则提出更多特效的要求），开发人员如果接受了大量变更，不仅意味着不断加班，更可怕的是会由此带来很大的质量风险，一旦出现严重问题，会得不偿失。
                            - 最后只能是开发人员联合测试人员，跟运营和设计进行了沟通，研发侧认可变更对于提升活动效果有作用，同时也对变更可能带来的延期，以及影响线上质量等风险进行了全面分析评估。双方基于共同的目标做出了协商和让步（既保证活动效果，同时也保证活动正常安全上线）。

                    - 5.情感账户，软性推动

                        - 当项目依赖某个外部团队的人员支持，而这个事情并不是对方当前工作范围内的，并不是对方第一优先级的工作，该怎么办？

                            - 大部分情况，有些开发者会在沟通未果的情况下，通过上升到leader去推动事情落地，这是一种解决方案。

                            - 更优的方案是建立相关依赖方的“情感账户”，借助“情感账户”去软性推动。

                                - 大家都知道银行账户就是把钱存进去，作为储蓄，以备不时之需。“情感账户”里储蓄的是人际关系中不可或缺的信任。经营好「情感账户」，也是经营好一个人与合作伙伴的信任关系。

                                - 在日常工作中多吃亏，让自己的「情感账户」适当“存储”。例如自己曾经抽出休息时间帮助合作伙伴解决问题，当需要对方协助的时候，相信也能得到积极的响应，这也是常说的“吃亏是福"。

    - 3.如何处理意外事项

        - 例子：插入一些高优的需求，或者说发生一些不可控的因素如疫情等等导致人力不足，从而影响项目的进展。

        - 1.需求的变更。
            - 处理方式：

                - 判断需求变更的大小，如果是样式修改等简单变更，半小时能解决的小问题，可以协助快速调整；如果工作量在 0.5 天以上，并且需要依赖第三方接口，则需要将整体的需求重新评估，重新梳理排期，并同步给干系人。 

                - 先保证核心的业务流程不变，高收益的工作量优先处理，保证正常的上线时间，后续有余力再对其它功能点进行迭代优化。

        - 2.高优需求插入
            - 处理方式：
                - 如果被高优需求插入，直接带来的影响是延后当前的工作完成时间。
                - 如果在 0.5 天以内，没有被依赖的下游时，再评估对排期影响不大的情况下是否可以快速响应。并第一时间反馈风险，确保各干系人都有一个心理预期；如果大于 0.5 天的需求，则建议反馈给项目干系人来安排其他人来解决。

        - 3.不可抗力的因素。

            - 例子：开发人员有急事需要请假，又或者因为疫情导致办公效率低下，从而影响项目的进展。

            - 处理方式：
                - 如果是一些身体原因导致办公效率低下。在不影响整体项目交付的情况下，适当的延长完成项目的时间；若影响到整体项目交付的时间，则应该暴露该风险，进行项目计划调整。
                - 如果完全不能投入开发，应该尽早的将此事向上级报备，由上级进行统一的人力调整，交由其他人投入开发。

        - 4.内部依赖延后
            - 处理方式：
                - 将自身的业务流程做好，依赖部分通过模拟的方式解决。
                - 将联调的时间后移，先开发其他的功能模块。
                - 如果已经是最后联调阶段，则需要再次调整交付的时间，同时将该风险同步给相关的干系人。

    - 4.通过流程规范提高质量

        - 1.制定研发流程规范
            - 制定流程有时会让人反感，觉得降低了研发效率。但规范的流程可以大大提升项目的质量，好的流程都是在实践中不断总结出来的，是项目的最佳实践。
            - 尽量将流程变成 CICD 的约束，通过系统来约束、控制，减少其对人的依赖。
            - 当然流程也不是一成不变的，它需要根据我们的具体情况不断调整优化，才能适应当下的需要。
            - 研发团队流程：需求评审、方案设计、需求开发、测试验收、发布上线、项目复盘六个步骤。
            ![image](./Pictures/soft-architecture/项目管理-研发流程.avif)

        - 2.严格执行Code Review

            - code review 的好处不仅仅是能够大大提高代码质量，减少代码 bug，还能从心理上（自己写的代码要给别人审核）让自己更认真严谨些。

        - 3.制定发布清单（checklist）

            - 发布 checklist 一般可以分为服务、机器、流程三部分，通过日常工作中累计容易出错的地方，将其整理收集起来，持续完善。

            参考例子：

            | 提测前                                                                                       |
            |----------------------------------------------------------------------------------------------|
            | 根据前期编写的测试用例进行整体自测                                                           |
            | 根据埋点文档验证埋点，确保埋点中的事件和维度不多报、不漏报、不错报、不重复报、报的时机正确   |
            | 根据设计稿叠图并截图（2+测试机），确保无视觉问题                                             |
            | 确保分支的代码 CR 通过                                                                       |
            | 确保代码已发布到测试环境，并确认页面能够正常访问                                             |
            | 确保创建了提测单，提测单包含测试用例地址、测试范围、测试入口和二维码、终端环境、埋点文档地址 |
            | 确保需求单状态扭转到增量测试中                                                               |

            | bug修复后                                                                                                                   |
            |-----------------------------------------------------------------------------------------------------------------------------|
            | 涉及到功能、逻辑、埋点、样式和交互变更：重新走本次需求逻辑部分的自测、涉及样式的叠图、CR 和发布测试环境流程，确保全流程无误 |
            | 确保bug单状态扭转到已处理，并通知测试同学验证，保证在 1D 之内扭转到已关闭                                                   |
            | 确保需求单状态扭转到待发布                                                                                                  |

            | 发布前                                                     |
            |------------------------------------------------------------|
            | 确保产品体验、设计走查、测试都通过                         |
            | 确保所有代码（功能+bug 修复）都已经通过 CR，合入 master    |
            | 确保正式环境配置文件中的配置都是正式环境的配置             |
            | 如图片有新增和修改，确保图片已经进行过压缩                 |
            | 确认接口监控的数据正常，业务错误码屏蔽正常，不误报         |
            | 上线前和产品运营确认线上配置是否正确，涉及运营资源是否到位 |
            | 和后台、终端确认好发布顺序，并确保按照约定顺序发布         |
            | 确保在群里进行发布周知，提交的发布审批通过才能进行发布     |

            | 发布后                                                                                                |
            |-------------------------------------------------------------------------------------------------------|
            | 待 CDN 生效后，用非公司 wifi 访问页面，确保页面正常，同时确保所有的资源都是正式的 CDN 地址            |
            | 关注告警群消息，关注告警监控平台流量监控是否有较大波动，JS 报错、接口错误率是否有上涨，关注是否有告警 |
            | 发布出现问题，及时在群里周知并回滚，通知leader，并寻求团队成员协助定位排查                            |
            | 发布外网后需要留守至少 30 分钟                                                                        |
            | 确保需求单状态扭转到已交付和已接受                                                                    |

    - 5.管理变更影响
        - 在需求设计阶段提前对变更进行评估、规划，可以确保在对程序最小负面影响的情况下实施这些变更。
        - 通过详细设计评审技术方案
            - 编写技术文档对部分工程师来说是反感的事情，但好的项目质量一定是设计出来的，而不是测试出来的。
            - 所以在正式编码前，详细思考、设计整体方案并编写成技术文档在组内评审，是规避质量风险非常好用的方法，也是非常好的开发习惯。它可大大减少编码阶段的质量风险。

            - 例子：以之前笔者团队为例，我们还整理了团队详细文档模板，把大家做详细设计需要考虑的点都囊括了进去，避免大家遗漏。如性能设计、监控日志设计、安全风险设计、用例设计、容灾设计等，既是模板也是详细设计的 checkList。

# 软技能

- [腾讯云开发者：如何成为优秀工程师之软技能篇](https://zhuanlan.zhihu.com/p/587383325)

- [阿里开发者：六年团队Leader实战秘诀｜程序员最重要的八种软技能](https://developer.aliyun.com/article/933310?spm=a2c6h.14164896.0.0.40ddd46eXOv9U4)

- [腾讯大讲堂：一篇文章入门专利写作（万字干货）](https://cloud.tencent.com/developer/article/2092422?areaSource=&traceId=)

# 数据中心（IDC）

- 德国的防核弹机房

    - 机房处在一个乡下的地方，上空是德国政府规定禁飞区，房子是一米多厚的混凝土墙，门是钢板的，地下每一层要经过好几道铁门可以进去。

    - 在法国有数据备份

    - 两套电力系统

- [任泽平：中国新基建研究报告2022](https://baijiahao.baidu.com/s?id=1732147608499611955&wfr=spider&for=pc)

    - 根据中国信息通信研究院测算，“十四五”期间我国新基建投资将达到10.6万亿，占全社会基础设施投资10％左右；2021-2023年，数据中心产业投资或达1.4万亿元；2020-2025年，5G网络建设投资累计将达到1.2万亿元，带动产业链上下游以及各行业应用投资超过3.5万亿元。

    - 数据中心的产业链：

        - 上游：服务器、交换机、路由器、光模块、配套软件、电力设备以及运营商等

            - 数据中心投资资金的主要流动方向。从投资占比看，服务器投资额占比最大，为69.28％。其次为交换机，占比为8.31％。第三是光模块，占比为8.31％。

            - 我国目前已经建成约500万架，相对2015年的124万架同比增长303％左右。同时，2015-2020年间，我国数据增量年均增速超过30％，预计2021年后仍以每年超过20％的速度新增。

            - 供配电系统占整体IDC系统及机柜投资的46.82％，占整体投资额的6.05％。

        - 中游：互联网及移动互联网、物联网以及工业物联网、IDC、云服务、IAAS、SAAS、数据安全以及数据交换。

        - 下游：智慧出行、智慧家居、泛娱乐、新零售、智慧医疗、金融、电信、工业以及精准营销等行业。根据

    - 东数西算：

        > 将东部大量需要运算的数据（数）通过光纤信息通道传输至西部，并使用西部的算力枢纽进行计算（算）后将结果返回东部供分析研究使用。

        - 目前数字经济产业多集中于东部地区，导致东部对数据中心的需求旺盛，因此大部分数据中心集中在算力成本高昂的东部。而西部对大数据中心的需求较低，数据中心分布少、上架率低。

            - 2020年中华北、华东以及华南三地机柜数量占全国机柜总数量的79％，上架率约在60-70％之间。但东部土地稀缺，生活成本高昂，能源相对稀缺，导致东部算力成本高居不下。与此同时，东北、西北、西南以及华中四地机柜数量只占总机柜数量的25％，上架率约在30-40％之间。

        - 城市中心的算力中心用作“边缘算力”，对一些对网络要求较高的业务如：工业互联网、金融证券、灾害预警、远程医疗、视频通话、人工智能推理等，进行实时低延迟运算。同时，工信部也对全部数据中心的上架率以及PUE（能源使用效率）进行了严格限制，防止了盲目发展。

            - 京津冀、长三角、粤港澳大湾区、成渝、内蒙古、贵州、甘肃、宁夏在内的8个国家算力枢纽节点，同时规划了10个国家数据中心集群。

        - 东数西算 + 特高压：

            - 数据中心电力消耗大，未来对清洁电力需求增强。特高压进行远距离传输比光纤损耗较大，因此“东数西算”相对于“西电东输”能够在保证成本的前提下更好地执行“双碳”目标。

# api设计

- [阿里技术：深度 | API 设计最佳实践的思考](https://developer.aliyun.com/article/701810?spm=a2c6h.12873639.0.0.33e56605iyuCWs)

- [苏三说技术：瞧瞧别人家的API接口，那叫一个优雅](https://juejin.cn/post/7176220436714225721)

# 架构
## 架构设计

### [腾讯技术工程：谈谈架构设计](https://cloud.tencent.com/developer/article/2255693?areaSource=103001.1&traceId=00iu5zGPktoj8ynGnpC4n)

- 模块与组件：模块是逻辑单元，组件是物理单元。
    - 模块：的粒度可大可小， 可以是系统，几个子系统、某个服务，函数， 类，方法、 功能块等等。
    - 组件：可以包括应用服务、数据库、网络、物理机、还可以包括 MQ、容器、Nginx 等技术组件。

- 框架是组件实现的规范：

    - MVC、MVP、MVVM 等，是提供基础功能的产品
    - 开源框架：Ruby on Rails、Spring、Laravel、Django 等。可以拿来直接使用或者在此基础上二次开发。
        - SpringMVC 是 MVC 的开发框架，除了满足 MVC 的规范,Spring 提供了很多基础功能来帮助我们实现功能，包括注解(@Controller 等)、Spring Security、SpringJPA 等很多基础功能。

- 架构设计目的

    - 如果没有架构设计，说明你的系统不够复杂。

        - 随着业务的增长，系统由单体应用渐进演化为分布式和微服务化。系统整体的复杂性越来越高，技术团队可能从一个团队变成多个专业化团队。

    - 架构的本质是管理和解决系统的复杂性，提高效率。管理复杂性：对系统进行有序化重构，不断减少系统的“熵”，使系统不断进化，改善软件质量为目的的内在结构性变化；提高效率：对系统进行有序化重构，以符合当前业务的发展，并可以快速扩展。

    - 无论是何种变化，架构师通过理解业务，全局把控，权衡业务需求和技术实现，选择合适技术，解决关键问题、指导研发落地实施，促进业务发展，提高效率。

        - 没有最优的架构，只有最合适的架构，一切系统设计原则都要以解决业务问题为最终目标，脱离实际业务的技术情怀架构往往会给系统带入大坑，任何不基于业务做异想天开的架构都是耍流氓。

        - 研发人员为了所谓微服务化而拆分，而不是从当前业务考虑。导致系统无序的状态，开发效率低。

            - 例子：一个简单项目拆分成 8 个子服务，问他为什么这么拆分，说微服务化是为了应对以后扩展方便。结果这个项目从 2017 年到现在都没有再修改过，接手人宁愿新开发一个项目也不愿重构。

            - 系统应用服务跟踪问题：由于微服务化后，系统逻辑复杂，服务出现问题后，你很难快速的定位问题和修复。这是我们踩过不少坑，我们使用 dubbo 服务化，系统一旦出现问题，一推人手忙脚乱。

- 架构误区
    - 1.架构专门由架构师来做，业务开发人员无需关注
    - 2.架构师确定了架构蓝图之后任务就结束了
    - 3.不做出完美的架构设计不开工
        - 我们需要的不是一下子造出一辆汽车，而是从单轮车 --> 自行车 --> 摩托车，最后再到汽车。
    - 4.为虚无的未来埋单而过度设计
        - 在创业公司初期，业务场景和需求边界很难把握，产品需要快速迭代和变现，需求频繁更新，这个时候需要的是快速实现。
        - 不要过多考虑未来的扩展，说不定功能做完，效果不好就无用了。
    - 5.一味追随大公司的解决方案
        - 网站在讨论架构决策时，最有说服力的一句话就成了“淘宝就是这么搞的”或者“腾讯 就是这么搞的”。
    - 6.为了技术而技术
        - 技术是为业务而存在的，除此毫无意义。

- 架构方法论

    - 不同架构方法论，定义的架构分类也不同，RUP4+1 架构方法主要是以架构生命周期为视角进行描述，而 TOGAF9 按架构涉及内容维度来描述。

    - 1.RUP4+1 架构视图

        - 1995 年，Philippe Kruchten 在《IEEE Software》上发表了题为《The 4+1 View Model of Architecture》的论文，引起了业界的极大关注，并最终被 RUP 采纳。

        - 用例驱动：在软件生命周期的各个阶段对软件进行建模,从不同视角对系统进行解读，从而形成统一软件过程架构描述。

        - 不同架构视图承载不同的架构设计决策，支持不同的目标和用途

            - 1.逻辑视图：用于描述系统软件功能拆解后的组件关系,组件约束和边界,反映系统整体组成与系统如何构建的过程。关注功能和逻辑层。
            - 2.开发视图：描述系统的模块划分和组成,以及细化到内部包的组成设计,服务于开发人员,反映系统开发实施过程。
            - 3.物理视图：描述软件如何映射到硬件，反映系统在分布方面的设计，系统的组件是如何部署到一组可计算机器节点上,用于指导软件系统的部署实施过程。
            - 4.处理流程视图：用于描述系统软件组件之间的通信时序,数据的输入输出,反映系统的功能流程与数据流程,通常由时序图和流程图表示。关注进程、线程、对象等运行时概念以及相关的并发、同步、通信等问题。

            - 运用 4+1 视图方法：针对不同需求进行架构设计。
            ![image](./Pictures/soft-architecture/架构设计-RUP4+1.avif)

    - 2.TOGAF9

        - TOGAF9 的架构分类：业务架构、应用架构、数据架构、技术架构, 代码架构, 部署架构。
        ![image](./Pictures/soft-architecture/架构设计-TOGAF9.avif)

            - 业务架构是战略，应用架构是战术，技术架构是装备。
            - 应用架构承上启下，一方面承接业务架构的落地，另一方面影响技术选型。熟悉业务，形成业务架构，根据业务架构，做出相应的应用架构，最后技术架构落地实施。

        - 1.业务架构
        ![image](./Pictures/soft-architecture/架构设计-TOGAF9-业务架构.avif)

            - 包括业务规划，业务模块、业务流程，对整个系统的业务进行拆分，对领域模型进行设计，把现实的业务转化成抽象对象。

            - 业务能力定义企业做什么，业务流程定义企业怎么做。业务架构就是对企业的业务流程，进行根本性的再思考和在思考的彻底性再设计，从而获得成本、质量、速度等方面业绩的巨大的改善或提高。

            - 今天面临的业务量有多大，增长走势是什么样，而且解决高并发的过程，一定是一个循序渐进逐步的过程。合理的架构能够提前预见业务发展 1~2 年为宜。

        - 2.产品架构

            - 将这些不同用途的功能模块围绕特定的业务目标进行分类整合。

                - 注重产品功能的枚举、功能模块之间的分界。

            - 功能模块是用户能够完成一个操作的最小粒度的完整功能

                - 例子：一个展示可购买商品的列表页、一个修改用户密码的功能。

                - 确保用户能通过一个功能模块完整的完成一项工作，而不是半个工作。

            - 功能模块之间有直接关系、间接关系：
                - 只有直接关系的功能模块才会被组织到一起，形成一个子系统。
                - 间接关系的模块，会在不同的层级通过直接关系的模块产生联系。

            - 当具有直接关系的功能模块组合成一个子系统后，解决相同问题域的子系统就形成一个功能层级。功能层级按照接近用户实操的距离程度进行从上到下，或者从左至右的划分，这就形成了产品架构的分层。
        - 3.应用架构（剖面架构，也叫逻辑架构图）：

            - 业务架构的每一部分都有应用架构。
            - 应用架构在产品架构的基础上考虑两个事情：
                - 1.子系统间的关系
                - 2.将可复用的组件或模块进行下沉，沉淀到平台层，为业务组件提供统一的支撑。

            - 应用架构定义系统有哪些应用、以及应用之间如何分工和合作。

                - 应用作为独立可部署的单元，为系统划分了明确的边界，深刻影响系统功能组织、代码开发、部署和运维等各方面

            - 应用分层：
                - 1.水平分（横向）：按照功能处理顺序划分应用，比如把系统分为 web 前端/中间服务/后台任务，这是面向业务深度的划分。
                - 2.垂直分（纵向）：按照不同的业务类型划分应用，比如进销存系统可以划分为三个独立的应用，这是面向业务广度的划分。

            - 应用之间的通信：
                - 通信机制：同步调用/异步消息/共享 DB 访问等
                - 数据格式：文本/XML/JSON/二进制等

            - 应用的分，偏向于业务，反映业务架构，应用的合，偏向于技术，影响技术架构。

        - 4.数据架构
            - 数据架构指导数据库的设计. 不仅仅要考虑开发中涉及到的数据库，实体模型，也要考虑物理架构中数据存储的设计。
            ![image](./Pictures/soft-architecture/架构设计-TOGAF9-数据架构.avif)

        - 5.代码架构（开发架构）

            - 代码架构设计不足，就会造成影响全局的架构设计。比如公司内不同的开发团队使用不同的技术栈或者组件，结果公司整体架构设计就会失控。

            - 最好的样本是参考现有《阿里巴巴 Java 开发手册》。

            - 代码架构定义的内容：
                - 1.代码单元: 1、配置设计 2、框架、类库。
                - 2.代码单元组织：1、编码规范，编码的惯例 2、项目模块划分 3、顶层文件结构设计，比如 mvc 设计 4、依赖关系

                ![image](./Pictures/soft-architecture/架构设计-TOGAF9-代码架构.avif)

        - 6.技术架构

            - 应用架构本身只关心需要哪些应用系统，哪些平台来满足业务目标的需求，而不会关心在整个构建过程中你需要使用哪些技术。

            - 架构设计工作中最为困难的工作：需要具备软件和硬件的功能和性能的过硬知识

            - 技术架构考虑的内容：
                - 确定组成应用系统的实际运行组件（lvs，nginx，tomcat，php-fpm 等）。
                - 这些运行组件之间的关系，以及部署到硬件的策略。
                - 系统的高可用、高性能、扩展、安全、伸缩性、简洁等做

        - 7.部署拓扑架构图（实际物理架构图）
            - 主要是运维工程师主要关注的对象。
            - 部署了几个节点，节点之间的关系，服务器的高可用，网路接口和协议等，决定了应用如何运行，运行的性能，可维护性，可扩展性，是所有架构的基础。
            ![image](./Pictures/soft-architecture/架构设计-TOGAF9-拓扑架构.avif)
            ![image](./Pictures/soft-architecture/架构设计-TOGAF9-拓扑架构1.avif)

- 架构级别
    - 金字塔的架构级别：上层级别包含下层：系统级、应用级、模块级、代码级。
    ![image](./Pictures/soft-architecture/架构设计-架构级别-金字塔.avif)

    | 等级   | 内容                                                   |
    |--------|--------------------------------------------------------|
    | 系统级 | 整个系统内各部分的关系以及如何治理：分层               |
    | 应用级 | 单个应用的整体架构，及其与系统内单个应用的关系等       |
    | 模块级 | 应用内部的模块架构，如代码的模块化、数据和状态的管理等 |
    | 代码级 | 从代码级别保障架构实施                                 |

        - 基于架构金字塔，我们有了系统架构的战略设计与战术设计的完美结合：
        | 顶层设计 | 承上启下                                   |
        |----------|--------------------------------------------|
        | 战略设计 | 业务架构用于指导架构师如何进行系统架构设计 |
        | 战术设计 | 应用架构要根据业务架构来设计               |
        | 战术实施 | 应用架构确定以后，就是技术选型             |

- 应用架构演进：随着业务架构不断进化，同时应用架构依托技术架构最终落地。
![image](./Pictures/soft-architecture/架构设计-应用架构演进.avif)

    - 架构演进过程：单体应用 -> 分布式应用服务化 -> 微服务

    - 1.单体应用：

        - 只应用某个简单场景，应用服务支持数据增删改查和简单的逻辑即可
        - 三级架构：前端（Web/手机端）+ 中间业务逻辑层 + 数据库层

        - 非功能性需求的做法：

            - 1.性能需求：使用缓存改善性能
            - 2.并发需求：使用集群改善并发
            - 3.读写分离：数据库地读写分离
            - 4.使用反向代理和 cdn 加速
            - 5.使用分布式文件和分布式数据库

        - 优点：容易部署、测试

        - 缺点：

            - 复杂性高：模块的边界模糊、 依赖关系不清晰、 代码质量参差不齐、 混乱地堆砌在一起。每次功能的变更或缺陷的修复都会导致需要重新部署整个应用，出错率比较高。

            - 可靠性差：某个应用 Bug，例如死循环、内存溢出等， 可能会导致整个应用的崩溃。

            - 扩展能力受限：无法根据业务模块的需要进行伸缩。
                - 有的模块是计算密集型的，它需要强劲的 CPU；有的模块则是 IO 密集型的，需要更大的内存。由于这些模块部署在一起，不得不在硬件的选择上做出妥协。

            - 阻碍技术创新：单体应用往往使用统一的技术平台或方案解决所有的问题， 团队中的每个成员 都必须使用相同的开发语言和框架，要想引入新框架或新技术平台会非常困难。

            - 技术债务：随着时间推移、需求变更和人员更迭，会逐渐形成应用程序的技术债务， 并且越积 越多。“ 不坏不修”， 这在软件开发中非常常见， 在单体应用中这种思想更甚。

    - 2.分布式（微服务）

        - 对系统按照业务功能模块拆分，将各个模块服务化，变成一个分布式系统。

        - 优点：
            - 降低了耦合度：把模块拆分，使用接口通信,降低模块之间的耦合度。
            - 责任清晰：把项目拆分成若干个子项目，不同的团队负责不同的子项目。
            - 扩展方便：增加功能时只需要再增加一个子项目，调用其他系统的接口就可以。
            - 部署方便：可以灵活的进行分布式部署。
            - 提高代码的复用性：Service 层，如果不采用分布式 rest 服务方式架构就会在手机 Wap 商城，微信商城，PC，Android，iOS 每个端都要写一个 Service 层逻辑，开发量大，难以维护一起升级，这时候就可以采用分布式 rest 服务方式，公用一个 service 层。

            - 易于开发和维护：一个微服务只会关注一个特定的业务功能
                - 单个微服务启动较快：单个微服务代码量较少， 所以启动会比较快。
                - 局部修改容易部署：对某个微服务进行修改，只需要重新部署这个服务即可。
                - 技术栈不受限：部分微服务使用 Java 开发，部分微服务使用 Node.js 开发

        - 缺点：
            - 运维要求较高：在单体架构中，只需要保证一个应用的正常运行。而在微服务中，需要保证几十甚至几百个服务服务的正常运行与协作
            - 系统之间的交互要使用远程通信，接口开发增大工作量
            - 如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整。
            - 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复。
                - 尽管可以使用共享库来解决这个问题（例如可以将这个功能封装成公共组件，需要该功能的微服务引用该组件），但共享库在多语言环境下就不一定行得通了。

### [技术琐话：一家中型互联网公司的架构演进之路]()

- 自如租房公司。此文摘自《云原生落地：企业级DevOps实践》一书

- 技术与业务的关系就像汽车

    - 汽车有三大组件：车轮、发动机、方向盘

    - 对应三种技术：技术支持、技术驱动、技术颠覆。95%的企业是技术支持型企业

- 一般都是先追求业务的快速迭代试错，架构一般会滞后于业务的发展，在架构跟不上业务的迭代速度，或有巨大的历史技术债务出现时，技术架构才会进行新一轮的迭代。同时，没有任何一个架构是“银弹”，凡是能够解决当下企业面临的问题的架构就是好架构。

- 好的架构特征：可用性、可靠性、高性能、易维护、可拓展、安全性

- 架构的分类：

    - 1.业务架构：一般是指业务的关键流程、组织形式、信息流。
        - 电商为例，业务架构包括选品、采购、仓储、物流、供应商、订单等一系列的业务板块。核心是定义业务痛点，厘清功能需求和非功能性需求。

    - 2.功能架构：产品具备的细分功能。
        - 电商系统的功能架构可细分为用户管理、登录注册、商品管理、仓库管理、订单管理、购物车管理、支付管理等核心模块。

    - 3.应用架构：根据业务场景设计出应用的层次结构，制定好应用间的调用、交互方式，确保它们能够融合在一起并满足业务需要。
        - 电商系统的应用架构可能有用户中心、权限中心、登录系统、商品中心、搜索引擎、推荐体系、订单系统、交易系统等。应用架构体现的是用什么样的微服务去支持功能的实现。

    - 4.技术架构：实现应用架构的关键技术栈
        - 如Spring Cloud、ZooKeeper、RocketMQ、Redis、MySQL、Elasticsearch等中间件，以及各种核心流程的时序图、状态图等信息。

    - 5.物理架构：从物理视角来看IDC中的物理拓扑关系，如防火墙、Nginx、网络、应用服务器、数据库间的调用和数据流转关系。
        - 如何通过硬件配置硬件和网络来配合软件系统达到可靠性、高可用性、性能、安全性等方面的要求。

- 企业级架构的演变史：单体架构、分布式架构、微服务架构，中台架构

    - 1.单体架构：

        - 在Web应用发展早期，大部分工程都是将所有的服务和功能模块打包到一个单一的应用中，如以War包的形式运行在Tomcat进程中，直接与数据库和文件系统交互。

        - 一般一台服务器、一个应用、一个数据库，就足够支撑起一个单一的业务功能。比如电商业务，登录、下单、商品、库存都在一个单一的应用中进行管理和维护。

        - 随着业务的不断增长，用户的访问越来越多，单一应用对磁盘、CPU、内存、数据库的访问要求也越来越高。一台服务器一个应用的配置开始捉襟见肘，更改任何一个小的功能模块，整个应用都要重新进行编译和部署。

            - 整体的功能耦合性非常大，一个小功能的变动可能会引起整个应用不可用。多种功能的强耦合迫使单体架构走向分布式架构。

    - 2.分布式架构：即将1台服务器分散扩容为N台，分而治之

        - 如何保证用户的请求均匀分散到这N台服务器？倘若用户的流量仍然集中访问其中的某台服务器，这样的分布式架构在本质上与单体架构没有任何区别。要解决这个问题就必须增加一个新模块—负载均衡

        - 从单一架构的大单一职责，拆分出一些大的应用，逐步形成多种服务之间的分布式调用。还是以电商为例，这里可能会拆分出用户服务、订单服务、商品服务、库存服务四大应用，应用之间通过接口进行交互，调用形式可能是REST或者RPC。

        - 优点：
            - 低耦合：有了功能模块的拆分，使用接口进行通信，降低了对数据库的依赖，模块耦合性降低。
            - 职责清晰：把应用拆成若干个子应用后，一般也是由不同团队进行维护的，这样一来，不同团队与应用的职责也就更加清晰了。
            - 稳定性更高：不会因为某一个应用或功能模块出现问题导致整体服务不可用

        - 缺点：系统间的依赖和链路增多，会增加接口开发的工作量，同时增大服务之间的维护成本

    - 3.微服务架构：在分布式架构的基础上对应用架构进行更细粒度的拆分

        - 随着Spring Cloud的普及，微服务架构逐步成为大中型企业的主流架构。

        - 优点：
            - 耦合性进一步降低：模块更独立，功能拆分更加细化，使代码间的耦合以及数据库、中间件的耦合进一步降低。
            - 自治性更强：一个微服务就是一个独立的实体，它可以独立部署、升级，微服务与微服务之间通过REST等标准接口进行通信，微服务只与其上下游有关，各个微服务之间更加独立。
            - 技术独立：各个微服务之间可以用不同的技术栈，服务端应用可以用Java、Go、Python等多种语言实现，数据库可以是MySQL、MongoDB、HBase等不同的类型。
            - 高可用：随着微服务增多、链路增长，异常也会被分散，一个微服务异常可以通过线程池隔离，利用熔断等技术避免故障扩散和雪崩，大大增加了整个系统的高可用性。

        - 缺点：
            - 复杂度高：采用RPC或REST等方式进行交互，需要考虑网络抖动、消息丢失、幂等、分布式事务等问题，代码的逻辑处理更加复杂。
            - 粒度难定义：微服务拆成几个合适？什么样的功能模块需要独立成一个微服务？服务拆分的粒度是不好准确定义的，倘若拆得过粗，不利于服务间解耦；如果拆得过细，则会导致应用爆炸，增加系统的复杂性。
            - 运维复杂度高：微服务的调用关系最终会形成一个大网，故障的定位和排查依托于更加完善的监控报警系统等配套工具。
            - 性能变慢：微服务一般有一个很长的调用链路，链路过长导致整体接口的性能变慢，响应时间（Response Time，RT）会变长。

    - 4.中台架构：本质是进一步提升应用系统的复用性，当组织规模扩大，更多业务场景纷纷涌现时，各部门之间会形成一个个“系统烟囱”。在“系统烟囱”中，重复冗余的功能不断被造出来。
        - 以阿里巴巴为例，淘宝、天猫两个事业部都需要用户管理、商品管理、订单管理等功能，许多业务功能是重复的，如果两个事业部都重复建设，必然会造成极大的资源浪费。

- 自如的技术演进过程
    - 1.2015年之前，自如以资产应用为主，管理房源信息、合同信息、客户信息，为了快速迭代业务，主语言以PHP为主，代码仓库以SVN来管理。到目前为止，老应用还存在部分未下线的功能，但是历史代码已经达到了1GB。
    - 2.2015年到2018年是架构服务化的阶段，这时自如业务蓬勃发展，长租、短租、优品、家装、服务等多条业务线崛起，各个业务线开始构建独立的专属服务，此时Java开始逐步替代PHP，成为新业务线使用的语言。各个服务间开始通过RPC进行通信。这个阶段自如从单体架构迈向了分布式架构，度过爆发性增长的3年。
    - 3.2018年7月，基础平台成立，自如开始对已有的持续交付流程进行重构，引入大量开源技术栈，如Spring Cloud、Nacos、Pinpoint、Graylog、Apollo等，使各个业务线通用的能力得到下沉，同时建设了第二机房，使自如的架构第一次具备了同城灾备的能力。
    - 4.2019年，自如开始搭建DevOps体系，所有应用运维往SRE（Site Reliability Engineer，站点可靠性工程师）方向转型，开始学习编码，准备为Kubernetes落地储备人才。自如建设了大量的平台功能，如网关、监控报警、配置中心、消息队列平台、权限平台、用户中心等，使技术中台已具雏形。

        - 2019年之前，自如某业务线的系统在30天内出现了13次线上故障，基本达到2天一次的故障频率。 发现当时最迫切的问题是中间件

            - 版本问题：各中心使用的MQ、Elasticsearch、Redis版本都极其老旧。以Elasticsearch为例，当时最新版本已经到了6.x，生产集群使用的还是2.x版本

            - 集群耦合太大：数个中心共用一个MQ、一个Redis实例，经常发生业务部门A的队列拥堵导致业务部门B的业务不可用，一个中间件瘫痪，整个公司的业务停转。经排查发现，这个情形与单体架构相似，原因是历史研发人员为了方便，直接复制中间件配置代码

            - 环境问题：代码分支、环境变量、开关配置经常出现测试环境与生产环境不一致等问题；人工参与过多，很多人为问题导致线上代码污染，进而引发故障。


    - 5.2020年，伴随着容器、Kubernetes的广泛传播，自如对持续交付流程做了颠覆性重构，完全改变了之前的发布部署方式，对环境、分支模型都进行了重新定义，成为整个自如的技术演进过程中一个新的里程碑。

    - 自如前台有多条业务线，如业主、租住、家装、客服等，每条业务线有独自的产研团队进行信息系统的构建，下方有三大中台进行支撑。
        ![image](./Pictures/soft-architecture/自如公司的中台架构.avif)

## 架构师

- [腾讯云开发者：优秀程序员，如何提高架构能力？](https://cloud.tencent.com/developer/article/1722323)

    - 架构发展史：

        - 1.演进就是技术编程框架为核心，展开的一系列规划和解耦部分

        - 2.就进入了高并发、分布式，应对大流量的状态。更加注重的是外围基础设施

        - 3.基于数据的应用架构，也就是越来越多的基于数据的挖掘产生新的应用。

    - 架构是随着整个行业的发展和社会需要去发展的：

        - 1.在 2000 年前后是门户、社交时代，PC 互联网蓬勃爆发的年代，有四大门户。互联网主要是新闻内容传递为主。

            - CDN 蓬勃发展
            - 技术上从编译型语言，逐步过度到动态解释性语言的广泛应用
            - 关系型数据库也开始被广泛应用。开始大量应用缓存，弥补关系型数据库存取能力不足的一些场景需求。

        - 2.移动互联网阶段:需要更强的存储和计算能力。云计算，大规模机器开始出现

        - 3.在 IoT 广泛应用之前不会再有指数级终端设备联网，基础工程能力不再是问题。

            - 在大数据、AI 架构方面发展。比如，如何用图数据库解决复杂关系图谱的问题，GPU 集群、弹性计算、机器学习框架都越来越重要。

    - 架构要根据从用户需求出发

        - 架构师关注业务和功能层面的连接

        - 在不同时期抓住用户当时的核心痛点，演进架构，解决掉用户的这些问题，才能成功。

        - 而不是根据已有的技术能力，YY 出产品功能，然后推给用户，可想而知，这样的产品一定会被用户用脚投票，无论背后的技术架构多么巧妙，业务注定会失败。

    - 系统的可用性：根据当月的不可用时间除以当月的总时间

        - 问题：在低峰期和高峰期挂掉十分钟，对业务的影响可能会相差很大

            - 腾讯在内部计算可用性：从请求的角度出发。被拒绝的请求量，加上超时的请求量，然后除以总的请求量

    - 可用性要考虑亚健康：

        - 我们总是假设系统里面的服务器状态是正常的或故障的。没有考虑亚健康：交换机转发能力下降、CPU 有降频、内存在做 ECC 纠错、，硬盘异常导致 IO 延迟陡增

        - 建设全链路的探测和监控，快速地把这些异常的，处于亚健康状态的节点剔除。

    - 长期方案固然要有，但短期方案也非常重要。不一定需要用最理想和技术方案去解决，但可以借鉴架构的思路。

    - 生产架构本质上也是一种架构：

        - 贝壳业务都是在白天去跑，晚上没有多少人去看房子，这个时候晚上做混沌工程，即使系统短时间出问题影响也没有那么大，还有时间修复。

    - 降级方式取决于这个架构师对于业务的了解：在什么条件下熔断什么样的东西对我们的损失是最小的？这件事情反映了一个架构师是不是对技术有非常深刻的了解

        - 做高可用架构的时候首先技术肯定是要好的。只要技术很好，业务场景不了解的话，会带来非常大的问题

    - 接手一个完全陌生领域的业务系统，比从零开始的项目要难：

        - 错误做法：把整个系统的边际和现在的系统逻辑过程看完，然后把业务梳理完，最后自己把这样的业务和技术重新地、完整地设计出一个新的架构，完全全新，基于他自己思想。

            - 问题：这是一个时间的过程，如果是一步到位的话，很容易会翻船。

                - 最理想的那个好到现实的差：其实它的距离感不仅来自于技术的好坏，还有来自于对业务的理解，以及你对团队的理解，包括来自于你对时间和商业成本的考虑。

                - 那么什么才是最好呢？要随着时间的发展去看，前提条件是第一次要让这个系统能够可用，并且达到商业目标，这是最快要做的，剩下的事情就是心中的理想。

    - 接受一个全新项目时：

        - 错误做法：花至少 1 年时间，比如要花一到两个季度调研某个技术，然后再花半年时间去做相应的落地

        - 正确做法：快速地试错，然后先把这个原型搭出来。看看这个是不是用户要的，高可用、高并发、高性能，哪个方面更重要，就投入相应的资源在上面去做相应的演进。

            - 先把整个代码的关键逻辑和分层结构列出来、画出来，弄清楚有哪些模块，模块之间是怎么通讯的，中间件都有哪些，三方服务有哪些等等。之后再去分析风险点，把风险点、呈现的问题和故障列出来，再去设计合理方案。

            - 架构师首先要了解系统现状、业务现状、团队能力现状，再因地制宜。千万不要拿到一个通用解决方案马上就去实施，要去分析自己的业务情况，是不是真的需要高并发、需要低延迟。

    - 如何提升架构能力：

        - linux发展了那么多年到现在架构的精髓依然被应用在非常多的地方，底层核心的东西是不太会变的，一定要去深入理解。

        - 架构的意义在于我们怎么去理解技术的原理，真正深入计算机原理，计算机是什么，存储是什么，为什么今天这样的东西存在，然后去想像这件事情，不停地在这里探索一系列的东西。

        - 要把这个东西尝试着去开源，放到网上让更多的人使用、验证、给你反馈。这个反馈非常重要，总是闭门造车、没有反馈的话架构能力很难提升。

            - 没有用户的话你就做你系统的用户，可以做很多的机器人测试客户端出来，往你的系统发请求

- [腾讯云开发者：大咖们如何评判优秀架构师？](https://cloud.tencent.com/developer/article/1625249)

    - 优秀的架构师要解决一个实际的问题

        - 这只是优秀的程序员，而不是优秀的架构师：Go 语言本身自带垃圾回收机制，很难干涉具体时间点进行垃圾回收，就容易导致系统实时性不足的问题。为了解决这个问题，团队做了很多方案，最后都没法上线，最终决定把 Go 语言的垃圾回收机制关掉。这样导致的内存泄漏，团队负责人竟然不把它算作泄漏，而是对上级重新 “定义” 为“内存增长”，交易关闭的时候重启就好了。

    - 最好的架构师不是具备了多丰富的知识点，他最需要的特质是折中，他可以在任何场景下都给出优雅的设计方案。

        - 不要去过度设计。比如说当前阶段用微服务 1.0 就可以的话，不用再去强行上微服务 2.0，只要架构能够满足当下的业务需求，同时具备未来一段时间的可扩展性就可以了。

         - 腾讯这样的大公司，架构设计上要关注于高并发

         - 对小型团队来说，架构设计更应满足快速迭代、持续交付的特性。

    - 优秀的架构应该满足的关键就是降本增效：是增加了人力和其他成本，还是让人力、运维等降低了，或者让效率提高了？

    - 要具备一个良好的架构认知的思维模型：

        - 在一个比较低级的思维模型里面，你即使学了再多的知识，在我看来也仅仅是低水平的重复。
        - 需要的是更高维度的认知，更高维度的架构设计能力，能够把某个点打穿打透。

    - 架构师要扛起来四门功课：能多打酱油、能和稀泥、肯背黑锅、敢拉仇恨

    - 要搞明白什么地方是重要：

        - 如果时间充裕，架构过程应该在建模、分层、耦合、调用等环节上做到充分论证讨论。

        - 时间紧任务重，横向比较的点，一定要想明白最重要的事情是什么，最重要的目标是什么，可能会有哪些变化？架构师也是一个决策环节，不一定要去做所有不可能完成的任务。

    - 代码写不好，大概率架构设计也不行，因为架构设计的本质还是结构

        - 如果你代码写得好，那么必然具备能做好拆解的前提条件，不然很难说代码写不好的人架构设计能做好。
        - 另外一点，看源码是很好的一点，一些最火的开源项目的源码，社区讨论的 issue，要多去看多去交流，了解别人是怎么做的。

## 架构安全

- 防拖库：个人和住址也要分开存放，用的时候拿到密钥再去组织，密钥也要动态更新，单独被读取只能是一个无法识别的数据片段。

## 软件开发

- [我在 20 年的软件工程师生涯中学到的事情（英文）](https://www.simplethread.com/20-things-ive-learned-in-my-20-years-as-a-software-engineer/)

    - 1.优秀的软件工程师不仅编写代码，还会考虑谁将使用它、为什么使用它、如何使用它。牢记用户需求才能创造良好的用户体验。

    - 2.水平再高的程序员，也会在自己擅长的领域犯错，如果遇到复杂的问题，就更是如此了。始终牢记，最好的代码是没有代码，或者不需要维护的代码。

    - 3.任何软件工程师的主要工作都是交付价值。软件只是达到目的的手段。

    - 4.警惕那些很长时间没有编写任何代码、却在设计系统的人。

    - 5.Bjarne Stroustrup 有一句名言："只有两种计算机语言：人们抱怨的语言和没人使用的语言"。大型系统也是如此，每个系统最终都很糟糕。

    因此，不要太在意代码的优雅和完美，而要持续改进，创建一个可用的系统，让开发者喜欢在其中工作并可以提供价值。

    - 6.10倍程序员是一个愚蠢的神话。我只见过程序员将代码规模增加了10倍，最终结果是你必须修复10倍的bug。

    真正要做的不是找到神话中的10倍程序员，而是要避免出现0.1倍程序员。那些浪费时间、不寻求反馈、不测试代码、不考虑边缘情况等的程序员，必须保证让这样的人远离我们的团队。

    - 7.人们说他们想要创新，但实际上，他们想要通常的只是某种新颖性和业务成功。如果你的创新改变了人们做事的方式，大多数情况下会得到负面反馈。如果你相信你正在做的事情，并知道它真的会改善事情，那么就准备好迎接一场持久战吧。

    - 8.数据是系统中最重要的部分。数据可能会比你的代码寿命更长，保持数据的有序和清洁，避免脏数据，从长远来看，会得到很好的回报。

    - 9.一直存在的旧技术不是恐龙，而是鲨鱼。它们很好地解决了问题，所以一直活到了现在，没有被快速变化的技术浪潮淘汰。

    不要轻易押注新技术，只有在充分理由的情况下才替换正在发挥作用的旧技术。那些老式的技术工具不花哨，也不令人兴奋，但它们可以完成工作，不会给你带来很多个不眠之夜。

    - 10.很多软件工程师除非被问到，否则不会发表意见。不要因为有人没当面发表意见，而认为他们没什么要补充的。有时，会议上嗓门最高的人是我最不想听的人。

    - 11.如果将人们与他们的工作成果分开，他们就会不太关心他们的工作。软件工程师和所有人一样，需要有主人翁的感觉，从头到尾拥有整个流程，直接负责交付价值。

    让一群充满激情的人完全拥有设计、构建和交付软件的所有权，令人惊奇的事情就会发生。

    - 12.面试最好用于了解某人是谁，以及他们对特定专业领域的兴趣程度，对于试图弄清楚他们是否将成为一个优秀的团队成员，那是徒劳的。

    - 13.始终努力构建一个更小的系统。

        - 有很多原因会推动你，去构建一个比原先设想的更大的系统，人类似乎有一种提供更多功能的欲望。你应该抵制这种欲望，在满足设计目标的前提下，始终努力构建一个更小的系统，这样你最终会得到一个比最初设计更好的系统。

## DevOps

- [阮一峰：运维的未来是平台工程](http://www.ruanyifeng.com/blog/2023/03/platform-engineering.html)

    - 编写软件和运行软件，其实是两种不同的技能：前者需要熟悉代码，后者需要熟悉服务器。互联网软件发展起来以后，这两种技能就逐渐分家了。

        - 互联网公司的核心资产和竞争力，更多的是代码，而不是运维。所以，公司也有意愿，把更多的力量投入在开发上，逐步压缩专门的运维团队，积极外包尽可能多的基础设施。

        - 问题：写代码的人不了解服务器环境，管理服务器的人不了解代码在干什么，这样不利于做出优秀的产品，也不利于排查问题。

    - DevOps：它等于 Dev（开发）+ Ops（运维）。开发与运维重新合在一起：编写软件的人也要负责运行软件。
        - 问题：DevOps 实际上没有办法取代运维

            - 越来越复杂的业务，注定了系统和基础设施也越来越复杂，同时还必须稳定可靠。普通的开发工程师，根本不可能做到这一点。他既不了解所有基础设施，也达不到专业运维的系统管理水平。

        - 传统运维的2个职责：

            - 1.构建基础架构：硬件的采购、安装、上架、联网这些工作

            - 2.管理运行环境：保障业务软件的运行。

            - DevOps 出现后：
                - 构建基础架构：这一职责逐渐消失，变成了采购云服务
                - 管理运行环境：这一职责则是转给了 DevOps 工程师
                - 问题：谁负责采购和整合云服务？

    - 平台工程：负责采购和整合云服务

        - 平台工程师：云服务纷繁复杂，各种 API、SDK 和配套工具令人眼花缭乱，即使经验丰富的运维工程师也不容易说清楚。因此，需要有专职人员来做出正确决策，选择一套满足需要的云服务，并且负责编写工具，整合所有采购来的云服务，供业务开发使用。

        - 1.基础设施是外包的，以求成本和开发周期最小化。

        - 2.平台工程师负责整合外包的基础设施，构建成一个平台。

        - 3.开发工程师在该平台上，自主搭建和管理运行环境，自己运行代码。

## SRE (Site Reliability Engineering，可靠性工程）

- SRE 的出发点是可用性是成功的先决条件。


- SLO：定义每个服务的用户可以接受的最低可靠性水平，然后将其作为你的 SLO
    - 例子：在一个月之中，99.9% 的请求延迟有在 300ms 内

        - 为什么不是100%？因为服务越可靠，其运营成本就越高。

- SLA:基于 SLO 制定的商业合约。承诺其 SLO 应在一段时间内达到特定水准，若未达到一段时间内保证的目标则会产生惩罚机制，比如向客户退款，或免费提供客户更长的服务订阅时间等。

    - 超出 SLO 会伤害到整体业务团队，因此服务应努力保持在 SLO 内。

### [卡瓦邦噶：SRE 的工作介绍](https://www.kawabangga.com/posts/4481)

- SRE：用软件解决运维问题。标准化，自动化，可扩展，高可用是主要的工作内容。

- SRE 目前对于招聘来说还是比较困难。一方面，这个岗位需要一定的经验，而应届生一般来说不会有运维复杂软件的经历；

- 最根本的，其实这个岗位寻找的要么是具有运维经验的开发人员，要么是具有软件开发技能的运维工程师。所以比较难以找到合适的人

- 蚂蚁金服有两种 SRE
    - 1.负责稳定性的，就是大家所理解的 SRE；
    - 2.资金安全 SRE，并不负责服务正常运行，而是负责金钱数目正确，对账没有错误，工作内容以开发为主，主要是资金核对平台和核对规则（没有做过，只是个人理解）

        - 某种意义上说，已经不算是 SRE 而是专业领域的开发了

- Netflix （2016年）的模式是谁开发，谁维护。
    - SRE 负责提供技术支持，和咨询服务。
    - Netflix 在全球 170 个国家有服务，Core SREs 只有 5 个人

- 微软有专门的 Game Streaming SRE：负责 XBox 在线游戏的稳定性

#### SRE工作分层

- 不同公司的 SRE 的内容各有偏重，取决于公司要提供什么样的服务

    - 学习网络分层的方式，将 SRE 大致的工作内容从下往上分成 3 个大类：

    - 1.Infrastructure：主要负责最基础的硬件设施，网络，类似于 IaaS，做的事情可参考 DigitalOcean

    - 2.Platform：提供中间件技术，开箱即用的一些服务，类似于 PaaS，做的事情可参考 Heroku, GCP, AWS 等

    - 3.业务 SRE：维护服务，应用，维护业务的正常运行

- 对于一个专业的 SRE 来说，技能也不应该有明显的界限
    - 比如说业务 SRE 也需要掌握一些网络技能
    - Infrastructure SRE 也要写一些代码。
    - 很多工具每一个岗位的人都多少用的到，比如 Ansible/Puppet/SaltStack 这种 IT 自动化工具，或者 Grafana/Prometheus 这种监控工具，只有理解才能用的正确。

- 换个角度讲，对于业务 SRE 来说，虽然基本上不会去管理四层以下的网络，但是如果遇到网络问题，能通过已有的工具和权限排查到交换机问题，去找 Infra SRE 帮忙：“请帮我看下 xx IP 到交换机是否有异常，因为 xxx 显示的结果是 xx”，总比 “我怀疑 xx 有网络问题，请帮忙排查下” 要好一些吧？

- Infrastructure SRE

    - Infrastructure 和 Platform SRE 其实可有可无，这些年商业化的服务其实越来越多了

        - 比如，如果公司选择全部在 AWS 部署自己的服务的话，那么就不需要自己建立 Datacenter，维护网络之类的工作了，只需要几个 AWS 专家即可

        - 如果有的话，工作内容也可大可小。可以从管理购买的 VPS 开始，也可以从采购硬件服务器开始

    - Infrastructure SRE 的工作内容可以这样定义：

        - 每一项既可以是一个很大的团队，也可以只有一个人去对商业化的 Infra 服务。可以使用开源的产品，也可以自己研发

        - 1.负责服务器的采购，预算，CMDB 管理。要知道（能查询到）每一台的负责人是谁，在干什么。这个非常重要，如果做不好，会造成极大的资源浪费。
        - 2.提供可靠软件的部署环境，一般是虚拟机，或者 bare mental。
        - 3.操作系统的版本统一维护，Linux 发行版的版本，Kernel 的版本等。
        - 4.维护机器上的基础软件，比如 NTP，监控代理，其他的一些代理。
        - 5.提供机器的登录方式，权限管理，命令审计。
        - 6.维护一套可观测性的基础设施，比如监控系统，log 系统，trace 系统。
        - 7.维护网络，大公司可能都会自己设计机房内的网络。其中包括：
            - 网络的连通，这个是必要的。对于上层用户（Platform SRE）来说，交付的服务应该是任意两个 IP 是可以 ping 通的，即管理好 3 层以下的网络。
            - NAT 服务
            - DNS 服务
            - 防火墙
            - 4 层负载均衡，7层负载均衡
            - CDN
            - 证书管理

- Platform SRE

    - Infrastructure SRE 维护的是基础设施，Platform SRE 使用他们提供的基础设施建立软件服务，让公司内的开发者可以使用开箱即用的软件服务，比如 Queue，Cache，定时任务，RPC 服务等等

    - RPC 服务：让不同的服务可以互相发现并调用
    - 私有云服务
    - 队列服务，比如 Kafka 或者 RabbitMQ
    - 分布式的 cronjob 服务
    - Cache
    - 网关服务：反向代理的配置
    - 对象存储：s3
    - 其他一些数据库：ES，mongo 等等。一般来说，关系型数据库会有 DBA 来运维，但是 NoSQL 或者图数据库一般由 SRE 维护。
    - 内部的开发环境：
        - SCM 系统，比如自建的 Gitlab
        - CI/CD 系统
        - 镜像系统，比如 Harbor
    - 其他的一些开发工具，比如分布式编译，Sentry 错误管理等等
    - 一些离线计算环境，大数据的服务

- 业务 SRE

    - 有了 Platform SRE 的支持，开发人员写代码就基本上不需要关心部署的问题了。可以专注于开发，使用公司开箱即用的服务。

    - 这一层的 SRE 更加贴近于业务，知道业务是怎么运行的，请求是怎么处理的，依赖了哪些组件。

    - 如果 X 除了问题，可以有哪些降级策略。参与应用的架构设计，提供技术支持。

    - 主要的工作内容有：
        - 参与系统的设计。比如熔断、降级，扩容等策略。
        - 做压测，了解系统的容量。
        - 做容量规划。
        - 业务侧的 Oncall。

#### 部署服务

- 部署分成两种：

    - Day 1：将服务部署上线的那一天

        - Day 1 操作是很难的。换句话说，我们在服务部署之后一直改来改去，还要保证这个服务在一个全新的环境能够可靠的部署起来。部署环境的硬编码，奇奇怪怪的 work around，都会破坏

        - Day 1 的可靠性。之前一家公司，扩容一个新机房的过程简直是噩梦，太多的奇怪配置，hardcode，导致踩过无数个坑才能在一个新的机房部署起来全部的服务。

    - Day 2+：服务部署之后，还会进行很多更新，升级，配置更改，服务迁移等等

        - Day2+ 的工作要做很多次，Day 1 做的很少，在不断的迭代升级之后，还能保证有一个可靠的

        - Day2+ 的操作也不简单，主要要关注稳定性。对于重要的变更操作要设计好变更计划，如何做到灰度测试，如果出了问题应该如何回滚，如何保证回滚可以成功（如何测试回滚）等等。

- 部署的操作最好都是可以追踪的，因为并不是所有会引起问题的操作都会立即引起问题。

    - 比如一个操作当时做完没有什么问题，但是过了 1 个月，偶然的重启或者内存达到了某一个指标触发了问题。

    - 如果能记录操作的话，我们可以回溯之前做过的变更，方便定位问题。现在一般都用 git 来追踪部署过程的变更（gitops）。

#### Oncall（保证线上服务的正常运行）

- 典型的工作流程是：收到告警，检查告警发出的原因，确认线上服务是否有问题，定位到问题，解决问题。

- 收到告警：并不总意味着真正的问题，也有可能告警设置的不合理。告警和监控面板并不是一个静态的配置，它应该是每天都在变化的，时刻在调整的。如果发现没有标志真正线上问题的告警发了出来，就应该修改告警规则。

    - 如果发现当前的监控无法快速定位问题，应该调整监控面板，添加或者删除监控指标。业务在发展，请求量在变化，某些阈值也需要不断地调整。

- 定位问题没有一概而论的方法了，需要根据看到的实时，结合自己的经验，然后做推测，然后使用工具验证自己的推测，然后确定问题的根因。

- SOP（标准操作流程）解决问题的方法论。即：如果出现了这种现象，那么执行那种操作，就可以恢复业务。SOP 文档应该提前制定，并且验证其有效性。

- 需要注意的是上述定位问题、解决问题并没有顺序关系。一个经常犯的错误是，在出现故障的时候，花了很长时间定位到故障的根因，然后再修复。这样花的时间一般会比较长。

    - 正确的做法是先根据现象看现有的 SOP 能否恢复业务。比如说当前错误只发生在某一个节点上，那么就直接下线这个节点，具体的原因后面再排查。恢复当前的故障永远是第一要务。

- 但是恢复操作也要经过测试，比如猜测可以通过重启解决问题的话，可以先重启一台做测试，而不是一次性将所有服务重启。大部分情况是需要临场分析的，是一个紧张又刺激的过程。

    - 故障到底多久恢复算好？出现多少故障是可以容忍的？怎么标志服务的稳定性到底如何？我们使用 SLI/SLO 来衡量这些问题

#### 制定和交付 SLI/SLO

- 维护服务等级协议，听起来像是一个非常简单的事情，只要“设定一个可用率”然后去实现它就好了。然而现实的情况并不是

    - 比如，制定可用率的时候，并不是说我们去“实现4个9”（99.99% 的时间可用）就够了，我们有以下问题要考虑：

- 如何定义这个可用率？比如我们以可用率 > 99.9% 为目标，有一个服务部署了 5 个 Zone, 那么有一个 Zone 挂了，其余的 Zone 是可用的，那么可用率被破坏了吗？这个可用率是每一个 Zone 的还是所有的 Zone 一起计算的？

    - 可用率计算的最小单位是什么？如果 1min 内有 50s 没有达到可用率，那么这一分钟算是 down 还是 up？
    - 可用率的周期是怎么计算的？按照一个月还是一个周？一个周是最近的 7 天还是计算一个自然周？

    - 如何对 SLI 和 SLO 做监控？

    - 如果错误预算即将用完，有什么措施？比如减少发布？如果 SLI 和 SLO 没有达到会怎么样？

- 等等，如果这些问题不考虑清楚的话，那么 SLI 和 SLO 很可能就是没有意义的。SLI/SLO 也适用于对公司内部用户的承诺，让用户对我们的服务有预期，而不能有盲目的信任

    - 比如 Google 在 SLI/SLO 还有预算的时候，会在满足 SLI/SLO 的时候自行对服务做一些破坏，让用户不要对服务有 100% 可用的错误预期。

- SLI/SLO 也会让 SRE 自己对当前服务的稳定性有更好的认识，可以根据此调整运维、变更、发布计划。

#### 故障复盘

故障复盘的唯一目的是减少故障的发生。有几个我目前认为不错的做法。

故障复盘需要有文档记录，包括故障发生的过程，时间线的记录，操作的记录，故障恢复的方法，故障根因的分析，为什么故障会发生的分析。

文档应该隐去所有当事人的姓名对公司的所有人公开。很多公司对故障文档设置查看权限，我觉得没什么道理。有些公司的故障复盘甚至对外也是公开的。

故障在复盘的时候应该将当事人的名字用代码替代，可以营造更好的讨论氛围。

不应该要求所有的故障复盘都产生 Action。之前一家的公司的故障复盘上，因为必须给领导一个“交待”，所以每次都会产生一些措施来预防相同的故障再次发生，比如增加审批流程之类的。

这很扯，让级别很高的领导审批他自己也看不懂的操作，只能让领导更痛苦，也让操作流程变得又臭又长，最后所有人都会忘记这里为什么会有一个审批，但是又没有人敢删掉。你删掉，出了事情你负责。

Blame Free 文化？之前我认为是好的。但是后来发现，有些不按照流程操作导致的问题确实多少应该 Blame 一下，比如下线服务的时候没有检查还没有 tcp 连接就直接下线了，或者操作的时候没有做 canary 就全部操作了，这种不理智的行为导致的故障。但是条条框框又不应该太多，不然活都没法干了。

#### 容量规划

容量规划是一个非常复杂的问题，甚至有一些悖论。容量要提前做好规划，但是容量的规划需要知道业务的扩张速度，扩张速度这种事情又不是提前能计划好的。所以我一直觉得这个事情很难做，也一直没有见过做的很好的例子。

但是至少可以对维护的系统建立一个模型，知道多少机器，多少资源，能容纳多少容量。这样遇到大促之类的活动也能及时估算需要的资源数量

#### 用户支持

- 用户支持也是日常的一部分。包括技术咨询，以及用户要求的线上问题排查。

- 这里就需要提到文档的重要性了。如果没有维护好文档，那么用户就会一遍又一遍问相同的问题。写文档也是一个技术活，优秀的需要很长时间的积累。

- 文档也需要经常更新。我一般会这样，保持这样一种状态：用户可以不需要任何人就从文档中找到他需要的所有答案。

- 如果我发现用户的问题无法从文档中找到，或者难以找到在文档中的什么地方，就会更新文档，或者重新组织文档。如果用户的问题已经从文档中找到，那么就直接发文档给他。

- 如果用户的问题显然是文档看都没有看过（有很多人根本不看文档的，只看文档是谁写的然后径直去问这个人），就直接忽略。

- 优秀的文档应该尽量引入少的专有名词，少使用没有用处的专业词汇描述，只描述具有指导意义的事实，假定用户没有相关的背景知识，列举使用例子，举一些现实会用到的例子而不是强行举例子，明确 Bad Case。等等。这其实是一个很大的话题了，这里就不展开了。

#### 有关做项目没有专业团队得不到训练

- 这方面是听到最多的抱怨。虽然说 SRE 在工作上应该是开发时间和运维时间各 50%
    - 但是真实的情况是，即使 SRE 有一些开发工作，也大部分是面向内部用户，面向公司内部的开发者的。
    - 大部分项目是一些想法，需要去尝试一下行不行，基本上不会有专业的设计资源，PM 资源。
        - 这种项目就需要 SRE 有多方面的技能，包括对产品的理解，清楚地知道它有什么痛点，最好是自己经历过的痛点，然后需要懂设计，管理好开发进度。然而这种人非常少。其实能写中型项目代码的 SRE 就已经非常少了。所以大部分公司内部项目都会做的又难用又复杂。

- 即使是有专业配套 PM （项目经理）和设计，甚至前端资源。基本上也是一个灾难。
    - 我也经历过这样的团队：这种内部项目对标的不是互联网项目，而更像是 toB 的项目。用户 UI 的设计，交互逻辑，操作流程，交付周期等需要的都是另一个领域的知识。
    - 否则的话人越多，也只会徒增沟通成本，拖慢项目进度。

- 回到经常听到的这个抱怨，说在 SRE 的团队没有像开发团队那样有“正规军”，有设计和 PM，大家各司其职，后端开发只要对齐 API 然后实现就好了。大部分的应届生会有这样的幻想，但实际上不是这样。

    - 被搞错的最重要的一点是，学习主要是靠自己的，和别人没有太大的关系。我觉得可能是在一个大团队里面，有很多人一起做一件事情，心里的怀疑和焦虑会少一点，人们会对这样的工作状态感到踏实，误以为是“成长”，自己做所有的工作焦虑更多。

- 事实是，在大团队工作可能学到更多的沟通技能，比如和不同的人对齐不同的阶段工作目标，要想要学到其他的东西还是要靠自己。

    - 比如拿到一个设计，如果照样子去实现了，其实不会学到什么东西。而要去理解为什么这么设计，为什么不那么设计。如果自己去做，思考的过程也基本是这样的，可以怎么设计，选择什么好。都是：思考，选择，尝试，经验，思考……

    - 另一个需要澄清的误区是，模仿并不是学习。在团队中经历了一个设计，如果记住了这个设计，下次碰到类似的问题也用这个设计去解决。这也不能叫做是学习。

- 我见过有在业务部门做过支付的 SRE 写的代码，在内部系统中去实现了订单业务的订单、交易等概念完成一个运维流程，甚至 Model 的名字都没改过。拿着锤子找钉子，会让系统变得更加糟糕和复杂。

    - 总之，工作分的细并不代表工作就会更加专业。一个人身兼数职也可以在每一个方面做得很专业。重要的是不断学习，使用正确的做事方式，向优秀的项目和优秀的开发者学习。

#### 有关背锅

互相甩锅的工作环境无疑是非常糟糕的工作环境。如果相同的团队、或者不同的团队之间需要相互勾心斗角的话，如果工作环境不允许大方承认（SRE 无可避免地会犯一些错误）自己的错误，说明公司营造的氛围有问题。

比如某些公司规定，发生 P1 级别的错误就必须开除一个 Px 级别的员工，发生 P0 级别的错误就必须开除一个 Py 级别的员工一样。如果是这种情况的话，公司实际上是在用一种懒惰地方法通过提高人的压力来提高系统的稳定性。有没有效果不知道，但是确定的是不会有人在这种情况下工作的开心。建议换一份工作。

#### 面试会问什么？

我觉得和后端开发的面试内容基本上差不多。

如果是去应聘的这个岗位所需要的一些技能，比如 K8S，监控系统等，可能也会问一些领域内的知识。

虽说这部分工具性的东西都可以学习，但是如果人家要一个经验丰富的、或者入职就能干活的，那么面试成功的机会就会小很多。

当然，也不必沮丧，这是市场的供需关系决定的，如果对方执意要找符合特定要求的候选人，那么对方的选择的范围也会小很多，不必因为错失了这种机会而后悔没去学习什么工具。话又说回来，技能越多，选择也会越多。

排查错误可能是转行做 SRE 最大的一个门槛，这个需要一些经验。如果没有经验的话，就补足一些操作系统的知识，这样遇到未知的问题也可以通过已知的知识和工具去排查。

做 SRE 需要会写代码吗？会，而且写代码的要求并不会比一个专业的后端开发低。

- 如何转行？

    - 其实难度没有想象的高，毕竟大学里面没有一个叫做 SRE 的专业。SRE 要求的知识也是编写代码、设计系统、了解操作系统和网络等。所以在大学里面将本科的课程好好学好，尝试做（并维护）一些自己的项目，毕业的时候基本上就满足要求了。非科班的人要转行的话，也可以参考大学的课程内容去补足这方面的知识。

    - 需要注意的是，培训班出来的做开发完成业务可能够，但是做 SRE 远远不够。SRE 不仅需要 make things work，还要知道背后的原理。

#### 选择大公司还是小公司？

这属于两种截然不同的工作环境。小公司一般都有一个救火英雄式的人物，在公司的时间比较长，知道所有组件的部署结构，什么都懂。跟着这种人学习会成长很快。

大公司细分领域很多。本文前面列出的内容可能每一项在大公司中都是一个团队，对某个领域可以深入研究。

所以还是看想要做什么了。我个人比较喜欢靠谱的小公司，或者大公司中靠谱的小团队。

##### 如何判断一家公司是否靠谱？

- 对于 SRE 这个职位，我总结了一些判断的技巧。比如可以判断一下对方目前的业务和 SRE 员工的数量是否处于一个“正常”的状态，人数是否在随着业务（机器的数量）现象增长？这是一个不好的迹象。是否 SRE 的数量过多？

- 如果 SRE 人太多，有两个可能的原因：

    - 1.某个领导为了扩大自己的影响力在为一些“不必要的”岗位招人，这样会导致人多事少，大家开始做一些奇奇怪怪的事情，发明奇奇怪怪的需求，以各种各样的方式浪费自己的时间来领公司的工资；

    - 2.这个公司的基础太差，大部分工作都是需要人力运维，导致基本上有多少机器就需要多少人。总之，都不是什么好事情。

- 一些技术比较好的公司，都没有庞大的 SRE 队伍，比如 Instagram, Netflix（现在可能人数不少了），以及一些创业公司，甚至都可以没有专门的 SRE，优秀的 SRE 首先要是开发者，优秀的开发者也离 SRE 不远了。

    - 一些耳熟能详的服务，比如 webarchive 这样的数据量，其实背后也只有几个人在维护。前几年面试了国内的一家公司，在机房遍布全球，业务已经发展的比较庞大（上市了）的时候，SRE 团队也只有 10 个人。

- 另外我比较喜欢问的一个问题是对方关于 AIOps 怎么看。因为我之前搞了两年这个东西，最后得到的结论是，这基本上是个浪费时间、欺骗上层领导的东西。AI 这东西的不可解释性本质上就和运维操作将就因果相违背的。

    - 所以经常喜欢问面试官怎么看这个技术，基本上就可以判断靠不靠谱。当然了，这是我个人的职业阴影导致的后遗症，只能代表个人意见。

- 就说这么多吧，都是一些个人理解，不一定对。写这篇文章感觉自己好像指点江山一样，其实我自己也干了才几年而已，所以本文内容仅供参考。如果有什么问题可以在评论提出，我能回答的话就尽量回答。

## DDD(领域驱动设计)

- [腾讯技术工程：万字长文助你上手软件领域驱动设计 DDD](https://cloud.tencent.com/developer/article/1966457)

    - 数据驱动设计（DDD以前的思维模式）：从技术的维度解决业务问题

        - 针对业务需求进行数据建模：根据业务需求提炼出类，然后通过 ORM 把类映射为表结构，并根据读写性能要求使用范式优化表与表之间的关联关系。

            - 得出的数据模型是对业务需求的直接翻译，并没有蕴含稳定的领域知识/规则。

        - 一旦需求发生变化，数据模型就得发生变化，对应的库表的设计也需要进行调整。
            - 从需求穿透到了数据层，中间并没有稳定的，不易变的层级进行阻隔，最终导致系统响应变化的能力很差。

    - 协同设计：

        - 数据驱动设计例子：由产品同学提出业务需求，研发同学进行技术方案设计，并编程实现。

            > 缺点：无法形成能够消除认知差异的模型。

            - 一：需求可能是易变的、定制化的，而研发同学在缺少行业经验的情况下，往往会选择直译，即根据需求直接转换为数据模型。

            - 二：而研发同学设计的技术方案，涉及很多的技术细节，产品同学无法从中判断是否与自己提出的业务诉求和产品规划相一致，最终形成认知差异。

            - 三：且认知差异会随着迭代不断被放大，最后系统变成一个大泥球。

            ![image](./Pictures/soft-architecture/DDD-协同设计1.avif)

        - 领域驱动（DDD）例子：

            - 领域专家：具有丰富行业经验和领域知识储备的人，他们能够在易变的、定制化的需求中提炼出清晰的边界，稳定的、可复用的领域概念和业务规则，并携手产品和研发共同构建出领域模型。

            - 领域模型是对业务需求的知识表达形式，它不涉及具体的技术细节（但能够指导研发同学进行编程实现），因此消除了产品和研发在需求认知上的鸿沟。

                - 模型的变更意味着需求变更和代码变更，协作围绕模型为中心。

            ![image](./Pictures/soft-architecture/DDD-协同设计2.avif)

    - 领域驱动（DDD）

        - 面对业务需求，先提炼出领域概念，并构建领域模型来表达业务问题，而构建过程中我们应该尽可能避免牵扯技术方案或技术细节。

            - 而编码实现更像是对领域模型的代码翻译，代码（变量名、方法名、类名等）中要求能够表达领域概念，让人见码明义。

        - 系统的复杂性往往并不在技术上，而是来自领域本身、用户的活动或业务服务。当这种领域复杂性在设计中没有得到解决时，基础技术的构思再好也是无济于事。

            - 系统的复杂度体现在三个方面：

                - 1.规模：功能点与功能点之间的的关系
                    - 通过子领域，限界上下文，聚合等模式对问题进行拆分和归类，不断收窄问题域，保证聚合边界内所解决的问题集合足够收敛和可控。

                - 2.结构：是否分层？若分层，每层划分的职责边界是否清晰
                    - 整体架构的基本管理单元是聚合，它是一个完整的、自治的管理单元，当需要进行服务拆分时，可以直接以聚合作为基本单元进行拆分。

                - 3.变化：分离不易变逻辑和易变逻辑，"以不变应万变"
                    - 领域层：不变
                    - 领域层以外的应用层和基础设施层：易变。通过调整该层，实现快速响应需求的变化

        - 微服务架构的兴起，大伙惊奇地发现 DDD 是作为划分“微服务边界”的一把利器，并且 DDD 提及的很多设计理念与微服务架构十分契合，因此 DDD 逐渐被开发者们接受并流行起来。毫不夸张地说，了解和学习 DDD 可以算得上是如今软件行业从业者的一门必修课了。

        - 问题空间和解空间

            - 问题空间：表示的是真实世界，是具体的问题、用户的诉求

                - 例子：学生管理系统（SMS）
                    > 学校需要构建一个学生管理系统（Student Management System, SMS）。
                    > 
                    > 通过这个管理系统，学生可以进行选课，查询成绩，查询绩点。
                    > 
                    > 而老师则可以通过这个系统录入授课课程的成绩。录入的分数会由系统自动换算为绩点，规则如下：若分数>= 90，绩点为4.0；90>= 分数> 80，绩点为3.0；80 >= 分数 > 70，绩点为2.0；70 >= 分数 >= 60，绩点为1.0；成绩< 60，则没有绩点，并邮件通知教务员，由教务员联系学生商榷重修事宜。
                    > 
                    > 成绩录入后的一周内，若出现录入成绩错误的情况，老师可提交修改申请，由教务员审核后即可完成修改。审核完成后系统会通过邮件告知老师审核结果。一周后成绩将锁定，不予修改。成绩锁定后，次日系统会自动计算各年级、各班的学生的总绩点（总绩点由各门课程的学分与其绩点进行加权平均后所得）。
                    > 
                    > 而教务员则可以通过该系统发布可以选修的课程。同时，教务员能够查看到各年级，各班的学生的总绩点排名。

                - 统一语言（ubiquitous language）：全局分析阶段对问题空间进行的梳理和分析，形成统一语言，获取问题空间的价值需求以及业务需求。

                    - 例子：商品的价格（Price）和商品的金额（Amount），它们本质是同一个东西，但是却有不同的术语表示。
                    - 统一语言可以通过词汇表的形式展示，其中词汇表最好还要包含术语对应的英文描述
                    ![image](./Pictures/soft-architecture/DDD-统一语言.avif)

                    - 精炼循环：我们在提炼领域概念的时候会觉得统一语言定义不合理/有歧义，此时我们就会调整统一语言的定义，并重新进行提炼领域概念。领域专家来主导概念提炼、边界划分等宏观设计，原因就在于领域专家的经验和行业洞见来源于过去已经迭代的无数个精炼循环，因此由这些宏观设计推导出来的领域模型，往往都是非常稳定的。

                    - 价值需求分析：

                        - 确定系统范围：确定系统问题空间的边界，明确系统什么该做，什么不该做。结合目标系统当前状态和未来状态进行判断。

                        - 在进行价值需求分析后，我们便能判断是否需要通过 DDD 驱动系统的设计。
                            - 并非任何系统都 DDD，DDD 的核心是解决领域复杂性，若系统逻辑简单，功能不多，引入 DDD 则会得不偿失。在进行价值需求分析后，我们便能判断是否需要通过 DDD 驱动系统的设计。

                    - 业务需求分析：

                        - 业务场景：按阶段性的目标划分业务流程

                            - SMS例子：老师修改成绩就分为了老师“提交申请单”，以及教务员“同意申请单”两个场景。

            - 解空间：则是针对问题空间求解后构建的理念世界，其中包括了解决方案、模型等。

            - 战略设计覆盖了问题空间和解空间，而战术设计则聚焦在解空间上。

        - 限界上下文：

            - 例子电商购物场景：
                - 在进行商品下单后，系统会生成一个订单
                - 在用户付款完成后，系统也会生成一个订单
                - 到了物流派送流程，系统还会生成一个订单。

                - 虽然这三个步骤中的领域概念都叫订单，但是他们的关注点/职责却不同：商品订单关注的是商品详情，支付订单关注的是支付金额和分润情况，物流订单关注的是收货地址。也就是说，商品、支付和物流分别为三个限界上下文，而订单作为统一语言需要在特定的限界上下文内，我们才能够明确其关注点/负责的职责。

            - 业务模块（横向切分）和限界上下文（纵向切分）
            ![image](./Pictures/soft-architecture/DDD-限界上下文.avif)

            - 识别限界上下文的原则：

                - 正交性：如果两个或更多事物中的一个发生变化，不会影响其他事物，这些事物就是正交的。要破坏变化的传递性，就要保证每个限界上下文对外提供的业务服务不能出现雷同。

                - 奥卡姆剃刀原理：“如无必要，勿增实体”。这是避免过度设计的良方

            - 防腐层和开放主机服务都是访问领域模型时建立的一层包装，前者针对发起调用的下游（通过基础设施层体现），后者针对响应请求的上游（通过应用层+远程服务），以避免上下游之间的通信集成将各自的领域模型引入进来，造成彼此之间的强耦合。

                - 防腐层：位于下游，通过它隔离上游上下文发生的变化。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-防腐层.avif)

                - 开放主机服务：让限界上下文可以被当做一组服务访问。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-开放主机服务.avif)

                    - 对于进程内的开放主机服务，称为本地服务（对应 DDD 中的应用服务）。

                    - 对于进程间的开放主机服务，成为远程服务。根据选择的分布式通信技术的不同，又可以定义出类型不同的远程服务：
                        - 面向服务行为，比如基于 RPC，称为提供者（Provider）
                        - 面向服务资源，比如基于 REST，称为资源（Resource）
                        - 面向事件，比如基于消息中间件，称为订阅者（Subscriber）
                        - 面向视图模型，比如基于 MVC，称为控制器（Controller）

                - 发布语言：用于两个限界上下文之间的模型转换。防腐层和开放主机服务操作的对象都不应该是各自的领域模型，这正是引入发布语言的原因。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-发布语言.avif)

                    - 例子：其实云 API 根据我们定义的接口生成对应的 Request 对象和 Response 对象，并集成在云 API 的 SDK 中，这些对象就是发布语言

                - 共享内核：将限界上下文中的领域模型直接暴露给其他限界上下文使用。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-共享内核.avif)

                    - 这会削弱了限界上下文边界的控制力。
                        - 上面我们讲述的防腐层、开放主机服务以及发布语言无不传达一种思想，限界上下文不能直接暴露自己的领域模型或直接访问其他限界上下文的领域模型，一定要有隔离层！

            - 协作不同的限界上下文
                - 这些团队之间具有要么一起成功，要么一起失败的强耦合关系。
                - 要求参与的团队一起做计划、一起提交代码、一起开发和部署，采用持续集成的方式保证两个限界上下文的集成度与一致性，避免因为其中一个团队的修改影响集成点的失败。

                - 客户方/供应方协作模式：

                    > 当一个限界上下文单向地为另一个限界上下文提供服务时，它们对应的团队就形成了客户方/供应方模式。
                    - 客户方作为下游团队，供应方作为上游团队：

                        - 下游团队对上游团队提出的服务
                        - 上游团队提供的服务采用什么样的协议与调用方式
                        - 下游团队针对上游服务的测试策略
                        - 上游团队给下游团队承诺的交付日期
                        - 当上游服务的协议或调用方式发生变更时，如何控制变更

                - 遵奉者协作模式：

                    > 当上游的限界上下文处于强势地位，且上游团队响应不积极时，我们可以采用遵奉者模式。即下游严格遵从上游团队的模型，以消除复杂的转换逻辑。

                    - 可以直接复用上游上下文的模型（好的）
                    - 减少了两个限界上下文之间模型的转换成本（好的）
                    - 使得下游限界上下文对上游产生了模型上的强依赖（坏的）

            - 例子：学生管理系统（SMS）

                | 限界上下文可划分为 |
                |--------------------|
                | 成绩上下文         |
                | 课程上下文         |
                | 审批上下文         |
                | 权限上下文         |
                | 邮件上下文         |

                ![image](./Pictures/soft-architecture/DDD-限界上下文-学生管理系统（SMS）.avif)

            - 微服务：
                - 在日常实践中，都是将限界上下文和微服务的关系进行一一对应的，但这不是绝对的
                - 当我们采用的是 CQRS 架构，领域模型会被分为命令模型和查询模型，虽然它们同属一个限界上下文，但是它们往往是物理隔离的。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-微服务.avif)

        - 大泥球：要避免制造大泥球
            - 越来越多的聚合因为不合理的关联和依赖导致交叉污染
            - 对大泥球的维护牵一发而动全身
                - 没有正交性
            - 强调“个人英雄主义”，只有个别“超人”能够理清逻辑

- [阿里开发者：万字详解｜从软件复杂度的角度去理解DDD]()

## 微服务

### 微服务理论

#### 康威定律

- [邱小侠：微服务架构的理论基础 - 康威定律](https://developer.aliyun.com/article/8611)

    - 康威四大定律：

        - 1.组织的沟通和系统设计之间的紧密联系。对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计。

            - 沟通成本 = n(n-1)/2，沟通成本随着项目或者组织的人员增加呈指数级增长。

                - 博物学家古尔德说：组织体大小很大程度上决定组织形态。蜘蛛真变得像大象一样大，那么它的形态也会变得和大象类似。

                - 亚马逊的Bezos这样比喻：如果2个披萨不够一个团队吃的，那么这个团队就太大了。一般一个互联网公司小产品的团队差不多就是7，8人左右（包含前后端测试交互用研等，可能身兼数职）。

                | 人数            | 复杂度                                |
                |-----------------|---------------------------------------|
                | 5个人的项目组   | 需要沟通的渠道是 5*(5–1)/2 = 10       |
                | 15个人的项目组  | 需要沟通的渠道是15*(15–1)/2 = 105     |
                | 50个人的项目组  | 需要沟通的渠道是50*(50–1)/2 = 1225    |
                | 150个人的项目组 | 需要沟通的渠道是150*(150–1)/2 = 11175 |

            - Dunbar Number（邓巴数）：150个人是人类的维系关系的极限

                | 关系             | 个数      |
                |------------------|-----------|
                | 亲密（intimate） | 朋友: 5   |
                | 信任（trusted）  | 朋友: 15  |
                | 接近（close）    | 朋友: 35  |
                | 临时（casual）   | 朋友: 150 |

                ![image](./Pictures/soft-architecture/Dunbar'Number.avif)

        - 2.时间再多一件事情也不可能做的完美，但总有时间做完一件事情

            - 对于一个巨复杂的系统，我们永远无法考虑周全。Eric Hollnagel认为最好的解决办法是抓主线

                - 有点类似于毛泽东说的《不要四面出击》

            - Eric被一家航空公司请去做安全咨询顾问，复杂保证飞机飞行系统的稳定性和安全性。Eric认为做到安全有两种方式：

                - 1.常规的安全：指的是尽可能多的发现并消除错误的部分，达到绝对安全，这是理想。
                - 2.弹性安全：即使发生错误，只要及时恢复，也能正常工作，这是现实。

                - 对于飞机这样的复杂系统，再牛逼的人也无法考虑到漏洞的方方面面，所以Eric建议放弃打造完美系统的想法，而是通过不断的试飞，发现问题，确保问题发生时，系统能自动复原即可，而不追求飞行系统的绝对正确和安全。

                - 类似于持续集成、敏捷开发：

                    - 对于一个分布式系统，我们几乎永远不可能找到并修复所有的bug，单元测试覆盖1000%也没有用。解决方法不是消灭这些问题，而是容忍这些问题，在问题发生时，能自动回复，微服务组成的系统，每一个微服务都可能挂掉，这是常态，我们只有有足够的冗余和备份即可。即所谓的 弹性设计（Resilience） 或者叫高可用设计（High Availability）。

        - 3.独立自治的子系统减少沟通成本

            - 如果你的团队分成前端团队，Java后台开发团队，DBA团队，运维团队，你的系统就会长成下面的样子

                ![image](./Pictures/soft-architecture/subsystem.avif)

            - 如果你的系统是按照业务边界划分（微服务架构）

                - 定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。

                ![image](./Pictures/soft-architecture/subsystem1.avif)

        - 4.分而治之

            - 人多管不过来啊，找几个经理帮我管，我管经理

            - 每个经理都被赋予一定的职责去做大系统的某一小部分，他们和大系统便有了沟通的边界，所以大的系统也会因此被拆分成一个个小团队负责的小系统（微服务）

#### 谁适合微服务？

- 微服务比较适合未来有一定的扩展复杂度，且有很大用户增量预期的应用，说人话就是新兴的互联网公司

    ![image](./Pictures/soft-architecture/microservice.avif)

- [王者荣耀为什么不使用微服务架构？](https://www.zhihu.com/question/359630395/answer/954452799)

    - 游戏的核心在于10 个人之间各种游戏事件的高速网络通信

        - 微服务为了把业务完美拆解，把原来的同一个进程里的模块拆分成不同的服务，显著增加额外的网络开销。

- 小项目还是别用微服务了，谁用谁难受啊。

    - 这倒不是说搞微服务不好，主要是当项目较小、人手不多的情况下，搞微服务的开发、部署成本太大，一个人同时改几个微服务模块，模块之间还有调用关系，很容易搞的人心力交瘁。

    - 本来应该几个小时能搞好的东西，在微服务的加持下，各服务间来回一调用，弄个两三天一点不成问题啊。

    - 首先说说团队自治。一个人管2、3个模块，确实是自治了，自己治自己。当你一个人负责两个或更多模块的时候，你就能深刻的体会到。

    - 当你同时修改这几个模块的时候，你要在本地将这几个服务启动、调试，如果公司不人道，给你配了台垃圾电脑，那连项目都别想痛痛快快的启动。

- 还有就是工期紧的项目，就不要微服务了。

    - 本来光搞业务就已经很紧张了，结果老板还要催着、赶着，那这种情况下建议还是不要微服务了。
    - 这种项目大多数以业务为主，对架构和性能要求往往没那么高，完全可以单体解决。
    - 如果采用微服务的话， 开发周期加长了不说，后期的维护成本会很大，尤其是不熟悉项目的人做后期维护。

- 网络、部署环境有限制，就不要微服务了
    - 在和朋友聊要不要用微服务的时候，有个朋友说，给国企或者ZF做的项目，能用单体就用单体吧。
    - 他说曾经给某个ZF部门做项目，项目是在自身产品功能上做一些定制化改造，微服务框架，有6、7个服务。
    - 结果甲方那边网络完全是内网环境，系统有指定的国产系统，机器开的每一个端口都要报备、说明，部署有指定的部署平台，连 RPC 调用都有特殊的要求。
    - 每次上线要在外部网络打包，然后用物理设备拷到内网，7、8个包，每一个包走一次部署流程，然后服务间调用是否成功也只能部署完之后才能测试。
    - 本来1天能做完的事儿，3、4天都弄不完，每天都薅头发。

### 微服务架构

- [邱小侠：微服务（Microservice）那点事](https://developer.aliyun.com/article/2764)

    - 分布式：按功能拆分成独立的服务，跑在独立的一般都在独立的虚拟机上

    - API Gateway：提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合

        - 有可能成为单点故障点或者性能的瓶颈。

        ![image](./Pictures/soft-architecture/API-Gateway.avif)

    - 服务之间如何通信？

        ![image](./Pictures/soft-architecture/communication.avif)

        - 同步调用：

            - REST（JAX-RS）
            - RPC（Dubbo）

        - 异步消息调用：

            - 能成为调用之间的缓冲，确保消息积压不会冲垮被调用方

            - 不过需要付出的代价是一致性的减弱，需要接受数据最终一致性

            - 后台服务一般要实现幂等性，因为消息发送出于性能的考虑一般会有重复（保证消息的被收到且仅收到一次对性能是很大的考验）

            - 必须引入一个独立的 broker，如果公司内部没有技术积累，对 broker 分布式管理也是一个很大的挑战。

            | 软件   |
            |--------|
            | Kafka  |
            | Notify |
            | MetaQ  |

    - 负载均衡：每一个服务都是有多个拷贝。一个服务随时可能下线，也可能应对临时访问压力增加新的服务节点。
        - 通过 zookeeper 等类似技术做服务注册信息的分布式管理

            - 服务上线时，服务提供者将自己的服务信息注册到 ZK（或类似框架）
            - 通过心跳维持长链接，实时更新链接信息
            - 服务调用者通过 ZK 寻址，根据可定制算法，找到一个服务，还可以将服务信息缓存在本地以提高性能
            - 当服务下线时，ZK 会发通知给服务客户端

- [腾讯云开发者：日调1000亿，腾讯微服务平台的架构演进](https://cloud.tencent.com/developer/article/1701134)

    - 服务发现：需要一个地方记录 IP

        - 传统架构：通过 IP 和 port 来进行互相调用

        - 微服务架构：使用 K8s 和 docker，每次启动的 IP 也可能会变

            - ServiceB 的每个实例在启动时，会将自身的 IP 和 port 写入到服务发现模块的某个路径，然后 ServiceA 会从这个路径来拉取到想要访问的 ServiceB 的服务提供者的列表。

        - 组件有zookeeper，nacos，Consul等：

            - Consul： 和 Spring 的对接也很成熟，很多中小型公司，特别是比较新的公司很多都会选择 Consul 来作为服务注册发现。
                - 服务注册请求、心跳请求会被翻译成kv，然后存储到server上。
                - 服务发现会将服务注册请求、心跳请求的kv内容合并，然后返回

#### [熔断、隔离、重试、降级、超时、限流，高可用架构流量治理核心策略全掌握](https://cloud.tencent.com/developer/article/2374938)

- 一个完善的架构应该具备3个能力，也就是身体的“三高”：
    - 高性能；
    - 高可用；
    - 易扩展。

- 理解高可用时，通常参考两个关键指标：

    - 平均故障间隔（Mean Time Between Failure，简称 MTBF）：表示两次故障的间隔时间，也就是系统正常运行的平均时间，这个时间越长，说明系统的稳定性越高；

    - 故障恢复时间（Mean Time To Repair，简称 MTTR）：表示系统发生故障后恢复的时间，这个时间越短，说明故障对用户的影响越小。

    - 可用性（Availability）的计算公式：Availability= MTBF / (MTBF + MTTR) * 100%

        - 这个公式反映了一个简单的事实：只有当系统故障间隔时间越长，且恢复时间越短，系统的整体可用性才会更高。

    - 因此，在设计高可用系统时，我们的核心目标是延长 MTBF，同时努力缩短 MTTR，以减少任何潜在故障对服务的影响。

- 流量治理的主要目的包括：
    - 网络性能优化：通过流量分配、负载均衡等技术，确保网络资源的高效利用，减少延迟和避免拥塞；
    - 服务质量保障：确保关键应用和服务的流量优先级，以保障业务关键操作的流畅运行；
    - 故障容错和弹性：在网络或服务出现问题时，通过动态路由和流量重定向等机制，实现故障转移和自我恢复，以维持服务的持续可用性；
    - 安全性：实施流量加密、访问控制和入侵检测等措施，保护网络和数据不受未授权访问或攻击；
    - 成本效益：通过有效管理流量，降低带宽需求和相关成本，同时提高整体系统效率。

- 流量治理的手段：熔断，隔离，重试，降级，超时，限流

- 熔断：微服务系统中，一个服务可能会依赖多个服务，并且有一些服务也依赖于它

    - 问题：
        - 当“媒体中心”服务的其中一个依赖服务出现故障（比如用户服务），媒体中心只能被动地等待依赖服务报错或者请求超时；
        - 下游连接池会被逐渐耗光；
        - 入口请求大量堆积，CPU、内存等资源被逐渐耗尽，最终导致服务宕掉。
        - 而依赖“媒体中心”服务的上游服务，也会因为相同的原因出现故障，一系列的级联故障最终会导致整个系统不可用；
        - 合理的解决方案是引入熔断器和优雅降级，通过尽早失败来避免局部不稳定而导致的整体雪崩。

        ![image](./Pictures/soft-architecture/流量治理-熔断.avif)

    - 解决方法：

        - 1.传统熔断器：当请求失败比率达到一定阈值之后，熔断器开启，并休眠一段时间（由配置决定）。这段休眠期过后，熔断器将处于半开状态，在此状态下将试探性地放过一部分流量，如果这部分流量调用成功后，再次将熔断器关闭，否则熔断器继续保持开启并进入下一轮休眠周期。

            ![image](./Pictures/soft-architecture/流量治理-传统熔断器的请求时序图.avif)

            - 传统熔断器实现 关闭、打开、半开 三个状态；

                - 关闭（Closed）：默认状态。允许请求到达目标服务，同时统计在窗口时间内的成功和失败次数，如果达到错误率阈值将会切换为“打开”状态；

                - 打开（Open）：对应用的请求会立即返回错误响应或执行预设的失败降级逻辑，而不调用目标服务；

                - 半开（Half-Open）：进入“打开”状态会维护一个超时时间，到达超时时间后开始进入该状态，允许应用程序一定数量的请求去调用目标服务。

                    - 熔断器会对成功执行的调用进行计数，达到配置的阈值后会认为目标服务恢复正常，此时熔断器回到“关闭”状态；

                    - 如果有请求出现失败的情况，则回到“打开”状态，并重新启动超时计时器，再给系统一段时间来从故障中恢复。

                ![image](./Pictures/soft-architecture/流量治理-传统熔断器的请求时序图1.avif)

                - 当进入 Open 状态时会拒绝所有请求；进入 Closed 状态时瞬间会有大量请求，这时服务端可能还没有完全恢复，会导致熔断器又切换到 Open 状态；而 Half-Open 状态存在的目的在于实现了服务的自我修复，同时防止正在恢复的服务再次被大量打垮；
                - 所以传统熔断器在实现上过于一刀切，是一种比较刚性的熔断策略。

        - 2.Google SRE 熔断器

            - 是否可以做到在熔断器 Open 状态下（但是后端未 Shutdown）仍然可以放行少部分流量呢？Google SRE 熔断器提供了一种算法：客户端自适应限流（client-side throttling）。

            - 解决的办法就是客户端自行限制请求速度，限制生成请求的数量，超过这个数量的请求直接在本地回复失败，而不会真正发送到服务端。

            - 该算法统计的指标依赖如下两种，每个客户端记录过去两分钟内的以下信息（一般代码中以滑动窗口实现）。
                - requests：客户端请求总量
                - accepts：成功的请求总量 - 被 accepted 的量

            - Google SRE 熔断器的工作流程：
                - 在通常情况下（无错误发生时） requests == accepts ；
                - 当后端出现异常情况时，accepts 的数量会逐渐小于 requests；
                - 当后端持续异常时，客户端可以继续发送请求直到 requests = K∗accepts，一旦超过这个值，客户端就启动自适应限流机制，新产生的请求在本地会被概率（以下称为p）丢弃；

                    - 客户端请求被拒绝的概率（Client request rejection probability，以下简称为 p）：p 基于如下公式计算（其中 K 为倍率 - multiplier，常用的值为 2）。

                        ![image](./Pictures/soft-architecture/客户端请求被拒绝的概率.avif)

                - 当客户端主动丢弃请求时，requests 值会一直增大，在某个时间点会超过 K∗accepts，使 p 计算出来的值大于 0，此时客户端会以此概率对请求做主动丢弃；

                - 当后端逐渐恢复时，accepts 增加，（同时 requests 值也会增加，但是由于 K 的关系，K*accepts的放大倍数更快），使得 (requests − K×accepts) / (requests + 1) 变为负数，从而 p == 0，客户端自适应限流结束。
                - 当 requests − K∗accepts <= 0 时，p == 0，客户端不会主动丢弃请求；
                - 反之， p 会随着 accepts 值的变小而增加，即成功接受的请求数越少，本地丢弃请求的概率就越高。

                - 客户端可以发送请求直到 requests = K∗accepts， 一旦超过限制， 按照 p 进行截流。
                    - 对于后端而言，调整 K 值可以使得自适应限流算法适配不同的服务场景
                    - 降低 K 值会使自适应限流算法更加激进（允许客户端在算法启动时拒绝更多本地请求）；
                    - 增加 K 值会使自适应限流算法变得保守一些（允许服务端在算法启动时尝试接收更多的请求，与上面相反）。

        - 熔断本质上是一种快速失败策略。旨在通过及时中断失败或超时的操作，防止资源过度消耗和请求堆积，从而避免服务因小问题而引发的雪崩效应。

- 隔离：如动静隔离、读写隔离和机房隔离，通过物理或逻辑上分离资源和请求，减少单点故障的影响

    - 微服务系统中，隔离策略是流量治理的关键组成部分，其主要目的是避免单个服务的故障引发整个系统的连锁反应。

    - 通过隔离，系统能够局部化问题，确保单个服务的问题不会影响到其他服务，从而维护整体系统的稳定性和可靠性。

    - 常见的隔离策略：

        - 动静隔离：动静隔离通常是指将系统的动态内容和静态内容分开处理

            - 动态内容
                - 指需要实时计算或从数据库中检索的数据，通常由后端服务提供；
                - 可以通过缓存、数据库优化等方法来提高动态内容的处理速度。

            - 静态内容
                - 指可以直接从文件系统中获取的数据，例如图片、音视频、前端的 CSS、JS 文件等静态资源；
                - 可以存储到 OSS 并通过 CDN 进行访问加速。
                ![image](./Pictures/soft-architecture/流量治理-隔离-动静隔离.avif)

        - 读写隔离：读写隔离通常是指将读操作和写操作分离到不同的服务或实例中处理
            - 大部分的系统里读写操作都是不均衡的，写数据可能远远少于读数据；
            - 读写隔离得以让读服务和写服务独立扩展。
            - DDD中有一种常用的模式：CQRS（Command Query Responsibility Segregation，命令查询职责分离）来实现读写隔离
                - 通过 CQRS 模式，读服务和写服务可以独立地进行扩展；
                - 如果系统的读负载较高，可以增加读服务的实例数量；如果写负载较高，可以增加写服务的实例数量。
                ![image](./Pictures/soft-architecture/流量治理-隔离-读写隔离CQRS模式.avif)

            - 写服务
                - 负责处理所有的写操作，例如创建、更新和删除数据；
                - 通常会有一个或多个数据库或数据存储，用于保存系统的数据。

            - 读服务
                - 负责处理所有的读操作，例如查询和检索数据；
                - 可以有独立的数据库或数据存储，也可以使用缓存来提高查询的性能。

            - 事件驱动
                - 当写服务处理完一个写操作后，通常会发布一个事件，通知读服务数据已经发生变化；
                - 读服务可以监听这些事件，并更新其数据库或缓存，以保证数据的一致性。

        - 核心隔离：核心隔离通常是指将资源按照 “核心业务”与 “非核心业务”进行划分，优先保障“核心业务”的稳定运行AI助手

            - 核心/非核心故障域的差异隔离（机器资源、依赖资源）；
            - 核心业务可以搭建多集群通过冗余资源来提升吞吐和容灾能力；
            - 按照服务的核心程度进行分级。
            - 1级：系统中最关键的服务，如果出现故障会导致用户或业务产生重大损失；
            - 2级：对于业务非常重要，如果出现故障会导致用户体验受到影响，但不会导致系统完全无法使用；
            - 3级：会对用户造成较小的影响，不容易注意或很难发现；
            - 4级：即使失败，也不会对用户体验造成影响。

        - 热点隔离：热点隔离通常是指一种针对高频访问数据（热点数据）的隔离策略

            - 可以帮助微服务系统更高效地处理热点数据的访问请求；
            - 需要有机制来识别和监控热点数据；
                - 分析系统的历史访问记录；
                - 观察系统的监控告警信息等。
            - 将访问频次最高的 Top K 数据缓存起来，可以显著减少对后端存储服务的访问压力，同时提高数据访问的速度；
            - 可以创建一个独立的缓存服务来存储和管理热点数据，实现热点数据的隔离。

        - 用户隔离：用户隔离通常是指按照不同的分组形成不同的服务实例。这样某个服务实例宕机了也只会影响对应分组的用户，而不会影响全部用户

            - 基于 O2-SAAS 系统的租户概念，按照隔离级别的从高到低有如下几种隔离方式：

                - 1.每个租户有独立的服务与数据库
                    - 网关根据 tenant_id 识别出对应的服务实例进行转发
                    ![image](./Pictures/soft-architecture/流量治理-隔离-用户隔离1.avif)

                - 2.每个租户有共享的服务与独立的数据库
                    - 用户服务根据 tenant_id 确定操作哪一个数据库
                    ![image](./Pictures/soft-architecture/流量治理-隔离-用户隔离2.avif)

                - 3.每个租户有共享的服务与数据库
                    - 用户服务根据 tenant_id 确定操作数据库的哪一行记录
                    ![image](./Pictures/soft-architecture/流量治理-隔离-用户隔离3.avif)

        - 进程隔离：进程隔离通常是指系统中每一个进程拥有独立的地址空间，提供操作系统级别的保护区。一个进程出现问题不会影响其他进程的正常运行，一个应用出错也不会对其他应用产生副作用

            - 容器化部署便是进程隔离的最佳实践：

                ![image](./Pictures/soft-architecture/流量治理-隔离-进程隔离.avif)

        - 线程隔离：线程隔离通常是指线程池的隔离，在应用系统内部，将不同请求分类发送给不同的线程池，当某个服务出现故障时，可以根据预先设定的熔断策略阻断线程的继续执行

            ![image](./Pictures/soft-architecture/流量治理-隔离-线程隔离.avif)

            - 如图，接口A 和 接口B 共用相同的线程池，当 接口A 的访问量激增时，接口C 的处理效率就会被影响，进而可能产生雪崩效应；
            - 使用线程隔离机制，可以将 接口A 和 接口B 做一个很好的隔离。

        - 集群隔离：集群隔离通常是指将某些服务单独部署成集群，或对于某些服务进行分组集群管理

            - 具体来说就是每个服务都独立成一个系统，继续拆分模块，将功能微服务化：

            ![image](./Pictures/soft-architecture/流量治理-隔离-集群隔离.avif)

        - 机房隔离：机房隔离通常是指在不同的机房或数据中心部署和运行服务，实现物理层面的隔离

            - 机房隔离的主要目的有两个：
                - 解决数据容量大、计算和 I/O 密集度高的问题。将不同区域的用户隔离到不同的地区，比如将湖北的数据存储在湖北的服务器，浙江的数据存储在浙江的服务器，这种区域化的数据管理能有效地分散流量和系统负载；
                - 增强数据安全性和灾难恢复能力。通过在不同地理位置建立服务的完整副本（包括计算服务和数据存储），系统可以实现异地多活或冷备份。这样，即使一个机房因自然灾害或其他紧急情况受损，其他机房仍能维持服务，确保数据安全和业务连续性。

            ![image](./Pictures/soft-architecture/流量治理-隔离-机房隔离.avif)

- 重试：包括同步和异步重试，以及各种退避机制，帮助在失败时优雅地恢复服务。

    - 如何在不可靠的网络服务中实现可靠的网络通信，这是计算机网络系统中避不开的一个问题

    - 如果重试之后还是不行，说明这个故障不是短时间的故障，而是长时间的故障。那么可以对服务进行熔断降级，后面的请求不再重试，这段时间做降级处理，减少没必要的请求，等服务端恢复了之后再进行请求，这方面的工程实现很多，比如 go-zero 、 sentinel 、hystrix-go。

    - 微服务架构中，一个大系统被拆分成多个小服务，小服务之间大量的 RPC 调用，过程十分依赖网络的稳定性。

        - 网络是脆弱的，随时都可能会出现抖动，此时正在处理中的请求有可能就会失败。场景：O2 Marketing API 服务调用媒体接口拉取数据。

        - 对于网络抖动这种情况，解决的办法之一就是重试。但重试存在风险，它可能会解决故障，也可能会放大故障。

        ![image](./Pictures/soft-architecture/流量治理-重试.avif)

    - 对于网络通信失败的处理一般分为以下几步：
        - 1.感知错误：通过不同的错误码来识别不同的错误，在 HTTP 中 status code 可以用来识别不同类型的错误。
        - 2.重试决策：这一步主要用来减少不必要的重试，比如 HTTP 的 4xx 的错误，通常 4xx 表示的是客户端的错误，这时候客户端不应该进行重试操作，或者在业务中自定义的一些错误也不应该被重试。根据这些规则的判断可以有效的减少不必要的重试次数，提升响应速度。
        - 3.重试策略：重试策略就包含了重试间隔时间，重试次数等。如果次数不够，可能并不能有效的覆盖这个短时间故障的时间段，如果重试次数过多，或者重试间隔太小，又可能造成大量的资源(CPU、内存、线程、网络)浪费。
        - 4.对冲策略：对冲是指在不等待响应的情况主动发送单次调用的多个请求，然后取首个返回的回包。

    - 重试方式

        - 同步重试：
            - 程序在调用下游服务失败的时候重新发起一次；
            - 实现简单，能解决大部分网络抖动问题，是比较常用的一种重试方式。

        - 异步重试：
            - 如果服务追求数据的强一致性，并且希望在下游服务故障的时候不影响上游服务的正常运行，此时可以考虑使用异步重试。
            - 将请求信息丢到消息队列中，由消费者消费请求信息进行重试；
            - 上游服务可以快速响应请求，由消费者异步完成重试。

    - 最大重试次数

        - 无限重试可能会导致系统资源（网络带宽、CPU、内存）的耗尽，甚至引发重试风暴

        - 应评估系统的实际情况和业务需求来设置最大重试次数：
            - 设置过低，可能无法有效地处理该错误；
            - 设置过高，同样可能造成系统资源的浪费。

    - 退避策略
        - 我们知道重试是一个 trade-off 问题：
        - 一方面要考虑到本次请求时长过长而影响到的业务的忍受度；
        - 一方面要考虑到重试对下游服务产生过多请求带来的影响。
        - 退避策略基于重试算法实现。重试算法有多种，思路都是在重试之间加上一个间隔时间

        - 线性间隔（Linear Backoff）
            - 每次重试间隔时间是固定的，比如每 1s 重试一次。

        - 线性间隔+随机时间（Linear Jitter Backoff）

            - 有时候每次重试间隔时间一致可能会导致多个请求在同一时间请求；
            - 加入随机时间可以在线性间隔时间的基础上波动一个百分比的时间。

        - 指数间隔（Exponential Backoff）

            - 间隔时间是指数型递增，例如等待 3s、9s、27s 后重试。

        - 指数间隔+随机时间（Exponential Jitter Backoff）

            - 与 Linear Jitter Backoff 类似，在指数递增的基础上添加一个波动时间。

        - 上面有两种策略都加入了 扰动（jitter），目的是防止 惊群问题 （Thundering Herd Problem） 的发生。

            - 所谓惊群问题当许多进程都在等待被同一事件唤醒的时候，当事件发生后最后只有一个进程能获得处理。其余进程又造成阻塞，这会造成上下文切换的浪费所以加入一个随机时间来避免同一时间同时请求服务端还是很有必要的

        - gRPC 实现

            - gRPC 便是使用了 指数间隔+随机时间 的退避策略进行重试：GRPC Connection Backoff Protocol https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md
            ```
            /* 伪代码 */
            ConnectWithBackoff()
              current_backoff = INITIAL_BACKOFF
              current_deadline = now() + INITIAL_BACKOFF
              while (TryConnect(Max(current_deadline, now() + MIN_CONNECT_TIMEOUT))
                     != SUCCESS)
                SleepUntil(current_deadline)
                current_backoff = Min(current_backoff * MULTIPLIER, MAX_BACKOFF)
                current_deadline = now() + current_backoff +
                  UniformRandom(-JITTER * current_backoff, JITTER * current_backoff)
            ```


            - 关于伪代码中几个参数的说明：
                - INITIAL_BACKOFF：第一次重试等待的间隔；
                - MULTIPLIER：每次间隔的指数因子；
                - JITTER：控制随机的因子；
                - MAX_BACKOFF：等待的最大时长，随着重试次数的增加，我们不希望第N次重试等待的时间变成几十分钟这样不切实际的值；
                - MIN_CONNECT_TIMEOUT：一次成功的请求所需要的时间，即使是正常的请求也会有响应时间，重试时间间隔需要大于这个响应时间才不会出现请求明明已经成功，但却进行重试的操作。

    - 重试风暴

        ![image](./Pictures/soft-architecture/流量治理-重试-重试风暴.avif)

        - 通过一张图来简单介绍下重试风暴：

            - DB 负载过高时，Service C 对 DB 的请求出现失败；

            - 因为配置了重试机制，Service C 对 DB 发起了最多 3 次请求；

            - 链路上为了避免网络抖动，上游的服务均设置了超时重试 3 次的策略；

            - 这样在一次业务请求中，对 DB 的访问可能达到 3^(n) 次。

        - 此时负载高的 DB 便被卷进了重试风暴中，最终很可能导致服务雪崩。

        - 解决方法：

            - 1.限制单点重试

                - 一个服务不能不受限制地重试下游，很容易造成下游服务被打挂；

                - 除了设置最大重试次数，还需要限制重试请求的成功率。

            - 2.引入重试窗口

                - 基于断路器的思想，限制 请求失败/请求成功 的比率，给重试增加熔断功能；

                - 常见的实现方式是引入滑动窗口。

                    ![image](./Pictures/soft-architecture/流量治理-重试-重试风暴-重试窗口.avif)

                    - 内存中为每一类 RPC 调用维护一个滑动窗口，窗口分多个 bucket；
                    - bucket 每秒生成 1 个，记录 1 秒内 RPC 的请求结果数据（成功/失败 次数）；
                    - 新的 bucket 生成时，淘汰最早的一个 bucket；
                    - 新的请求到达该 RPC 服务并且失败时，根据窗口内 失败/成功 比率以及失败次数是否超过阈值来判断是否可以重试。比如阈值设置 0.1，即失败率超过 10% 时不进行重试。

            - 3.限制链路重试

                - 多级链路中如果每层都配置重试可能导致调用量指数级扩大；
                - 核心是限制每层都发生重试，理想情况下只有最下游服务发生重试；
                - Google SRE 中指出了 Google 内部使用特殊错误码的方式来实现。

                - 关于 Google SRE 的实现方式，大致细节如下：

                    - 统一约定一个特殊的 status code ，它表示：调用失败，但别重试；
                    - 任何一级重试失败后，生成该 status code 并返回给上层；
                    - 上层收到该 status code 后停止对这个下游的重试，并将错误码再传给自己的上层。

                - 该方法可以有效避免重试风暴，但请求链路上需要上下游服务约定好重试状态码并耦合对于的逻辑，一般需要在框架层面上做出约束。

    - 对冲策略

        - 有时候我们接口只是偶然会出问题，并且我们的下游服务并不在乎多请求几次，那么我们可以考虑对冲策略AI助手

        - 对冲是指在不等待响应的情况下主动发送单次调用的多个请求，然后取首个返回的回包

        - 请求流程

            - 第一次正常的请求正常发出；
            - 在等待固定时间间隔后，没有收到正确的响应，第二个对冲请求会被发出；
            - 再等待固定时间间隔后，没有收到任何前面两个请求的正确响应，第三个会被发出；
            - 一直重复以上流程直到发出的对冲请求数量达到配置的最大次数；
            - 一旦收到正确响应，所有对冲请求都会被取消，响应会被返回给应用层。

        - 与普通重试的区别

            - 对冲在超过指定时间没有响应就会直接发起请求，而重试则必须要服务端响应后才会发起请求。所以对冲更像是比较激进的重试策略。

            - 使用对冲的时候需要注意一点是，因为下游服务可能会做负载均衡策略，所以要求请求的下游服务一般是要求幂等的，能够在多次并发请求中是安全的，并且是符合预期的。

            - 普通重试时序图：
                ![image](./Pictures/soft-architecture/流量治理-重试-对冲策略-普通重试时序图.avif)

            - 普通重试时序图：
                ![image](./Pictures/soft-architecture/流量治理-重试-对冲策略-对冲重试时序图.avif)

- 降级：区分自动和手动降级，作为服务负载过重时的应急措施

    - 降级是从系统功能角度出发，人为或自动地将某些不重要的功能停掉或者简化，以降低系统负载，这部分释放的资源可以去支撑更核心的功能
        ![image](./Pictures/soft-architecture/流量治理-降级.avif)
        - 目的是为了提升系统的可用性，同时要寻找到用户体验与降级成本的平衡点；
        - 降级属于有损操作。简而言之，弃卒保帅。

    - 与限流的区别
        - 降级依靠牺牲一部分功能或体验保住容量，而限流则是依靠牺牲一部分流量来保住容量。
        - 一般来说，限流的通用性会更强一些，因为每个服务理论上都可以设置限流，但并不是每个服务都能降级，比如O2 系统中的登录服务和用户服务，就不可能被降级（没有这两个服务，用户都没法使用系统了）。

    - 以 O2 系统举例，有以下几类降级策略：

        ![image](./Pictures/soft-architecture/流量治理-降级-降级策略.avif)

    - 虽说故障是不可避免的，要达到绝对高可用一般都是使用冗余+自动故障转移，这个时候其实也不需要降级措施了。

        - 但是这样带来的成本较高，而且可用性、成本、用户体验3者本身之间是需要权衡的，一般来说他们之前会是这样的关系：

        ![image](./Pictures/soft-architecture/流量治理-降级-成本与用户体验关系.avif)

    - 执行降级

        ![image](./Pictures/soft-architecture/流量治理-降级-执行降级.avif)

    - 自动降级
        - 适合触发条件明确可控的场景，比如请求调用失败次数大于一定的阈值，服务接口超时等情况；
        - 对于一些旁路服务，服务负载过高也可以直接触发自动降级。

    - 手动降级
        - 降级操作都是有损的，部分情况下需要根据对业务的影响程度进行手动降级；
        - 通常需要先制定降级的分级策略，影响面由浅至深。

    - 降级的策略还是比较丰富的，因此需要从多个角度去化简
        - 首先，将一部分判断条件简单的降级通过自动化手段去实现；
        - 其次，根据对业务的影响程度，对降级进行分级，达到有层次的降级效果；
        - 最后，通过高频演练，确保降级的有效性。

- 超时：通过精细的策略来避免长时间等待和资源浪费

    - 超时是一件很容易被忽视的事情
        - 早期架构发展阶段，大家或多或少有过遗漏设置超时或者超时设置太长导致系统被拖慢甚至挂起的经历
        - 随着微服务架构的演进，超时逐渐被标准化到 RPC 中，并可通过微服务治理平台快捷调整超时参数
        - 传统超时会设定一个固定的阈值，响应时间超过阈值就返回失败。在网络短暂抖动的情况下，响应时间增加很容易产生大规模的成功率波动
        - 服务的响应时间并不是恒定的，在某些长尾条件下可能需要更多的计算时间，为了有足够的时间等待这种长尾请求响应，我们需要把超时设置足够长，但超时设置太长又会增加风险，超时的准确设置经常困扰我们

    - 超时策略

        - 目前业内常用的超时策略有：
        - 固定超时时间；
        - EMA 动态超时。

    - 超时控制

        ![image](./Pictures/soft-architecture/流量治理-超时-超时控制.avif)
        - 超时控制的本质是 fail fast，良好的超时控制可以尽快清空高延迟的请求，尽快释放资源避免请求堆积。

    - 服务间超时传递

        - 一个请求可能由一系列 RPC 调用组成，每个服务在开始处理请求前应检查是否还有足够的剩余时间处理，也就是应该在每个服务间传递超时时间。

        ![image](./Pictures/soft-architecture/流量治理-超时-服务间超时传递.avif)

        - 如果都使用每个 RPC 服务设置的固定超时时间，这里以上图为例
            - A -> B，设置的超时时间为 3s；
            - B 处理耗时为 2s，并继续请求 C；
            - 如果使用了超时传递那么 C 的超时时间应该为 1s，这里不采用所以超时时间为配置的 3s；
            - C 继续执行耗时为 2s，此时最上层（A）设置的超时时间已截止；
            - C -> D的请求对 A 来说已经失去了意义。

    - 进程内超时传递

        ![image](./Pictures/soft-architecture/流量治理-超时-进程内超时传递.avif)

        - 上图流程如下：
            - 一个进程内串行调用了 MySQL、Redis 和 Service B，设置总的请求时间为 3s；
            - 请求 MySQL 耗时 1s 后再请求 Redis，这时的超时时间为 2s，Redis 执行耗时 500 ms；
            - 再请求 Service B，这时超时时间为 1.5s。

        - 由于每个组件或服务都会在配置文件中配置固定的超时时间，使用时应该取实际剩余时间与配置的超时时间中的最小值。

        - Context 实现超时传递

            ![image](./Pictures/soft-architecture/流量治理-超时-进程内超时传递context实现.avif)

    - EMA动态超时

        - 如果我们的微服务系统对这种短暂的时延上涨具备足够的容忍能力，可以考虑基于 EMA 算法动态调整超时时长。

        - EMA 算法引入“平均超时”的概念，用平均响应时间代替固定超时时间，只要平均响应时间没有超时即可，而不是要求每次请求都不能超时。

        - 算法实现

            ![image](./Pictures/soft-architecture/流量治理-超时-EMA动态超时.avif)

            - 当平均响应时间（EMA）大于超时时间限制（Thwm），说明平均情况表现很差，动态超时时长（Tdto）就会趋近于超时时间限制（Thwm），降低弹性；

            - 当平均响应时间（EMA）小于超时时间限制（Thwm），说明平均情况表现很好，动态超时时长（Tdto）就可以超出超时时间限制（Thwm），但会低于最大弹性时间（Tmax），具备一定的弹性。

            - 算法实现参考：https://github.com/jiamao/ema-timeout

        - 总而言之：
            - 总体情况不能超标；
            - 平均情况表现越好，弹性越大；
            - 平均情况表现越差，弹性越小。


        - 适用条件
            - 固定业务逻辑，循环执行；
            - 程序大部分时间在等待响应，而不是 CPU 计算或者处理 I/O 中断；
            - 服务是串行处理模式，容易受异常、慢请求阻塞；
            - 响应时间不宜波动过大；
            - 服务可以接受有损。

        - 使用方法：EMA 动态超时根据业务的请求链路有两种用法：

            - 1.用于非关键路径：Thwm 设置的相对小，当非关键路径频繁耗时增加甚至超时时，降低超时时间，减少非关键路径异常带来的资源消耗，提升服务吞吐量。

            - 2.用于关键路径：Thwm 设置的相对大，用于长尾请求耗时比较多的场景，提高关键路径成功率。

    - 一般超时时间会在链路上传递，避免上游已经超时，下游继续浪费资源请求的情况。

    - 这个传递的超时时间一般是没有考虑网络耗时或不同服务器的时钟不一致的，所以会存在一定的偏差。
    - 超时策略的选择：剩余资源 = 资源容量 - QPS 单次请求消耗资源请求持续时长 – 资源释放所需时长


        |      | 固定超时                                         | EMA动态超时                  |
        |------|--------------------------------------------------|------------------------------|
        | 优点 | 稳定                                             | 可以根据耗时动态调整超时时间 |
        | 缺点 | 如果某个服务一直出问题超时，会导致服务吞吐量降低 | 服务有损                     |

        - 关键路径选择固定超时；
        - 非关键路径开启 EMA 动态超时，防止一直出问题导致服务耗时增加、吞吐量降低。

    - 超时时间的选择
        - 合理的设置超时可以减少服务资源消耗、避免长时间阻塞、降低服务过载的概率；
        - 超时时间过长容易引起降级失效、系统崩溃；
        - 超时时间过短因⽹络抖动⽽告警频繁，造成服务不稳定。

    - 如何选择合适的超时阈值？超时时间选择需要考虑的几个点：
        - 被调服务的重要性；
        - 被调服务的耗时 P99、P95、P50、平均值；
        - 网络波动；
        - 资源消耗；
        - 用户体验。

- 限流：包括客户端和服务端限流，确保系统在高负载下仍能稳定运行

    - 在客户端限流中，由于请求方和被请求方的关系明确，通常采用较为简单的限流策略，如结合分布式限流和固定的限流阈值。

    - 客户端的限流阈值可被视作被调用方对主调方的配额。

    - 合理设定限流阈值的方法包括：
        - 容量评估：通过单机压测确定服务的单机容量模型，并与下游服务协商以了解他们的限流阈值
        - 容量规划：根据日常运行、运营活动和节假日等不同场景，提前进行容量评估和规划
        - 全链路压测：通过模拟真实场景的压测，评估现有限流值的合理性

    - 在限流算法方面，大家也都已经耳熟能详。像滑动窗口、漏桶和令牌桶均是常用的限流算法。

        - 这些算法各有特点，能有效管理客户端的请求流量，保障系统的稳定运行。

        - 这里笔者简单梳理了一张常用的限流算法的思维导图，主要阐述每个算法的局限性，需要根据实际应用场景选择合适的算法：
            ![image](./Pictures/soft-architecture/流量治理-限流-限流算法.avif)

    - 服务端限流：在通过主动丢弃或延迟处理部分请求，以应对系统过载的情况。

    - 服务端限流实现的两个关键点：

        - 1.如何判断系统是否过载
            - 常用的判断依据包括：
            - 资源使用率；
            - 请求成功率；
            - 响应时间；
            - 请求排队时间，

        - 2.过载时如何选择要丢弃的请求
            - 常用的判断依据包括：
                - 按照主调方（客户端）的重要性来划分优先级；
                - 根据用户的重要性进行区分。

        - 关于服务端限流在业界内的实践应用，笔者这里整理了两个示例：

            - 开源的 Sentinel 采用类似 TCP BBR 的限流方法。它基于利特尔法则，计算时间窗口内的最大成功请求数 （MaxPass） 和最小响应时间（MinRt）。当 CPU 使用率超过 80% 时，根据 MaxPass 和 MinRt 计算窗口内理论上可以通过的最大请求量，进而确定每秒的最大请求数。如果当前处理中的请求数超过此计算值，则进行请求丢弃。

            - 微信后台则使用请求的平均排队时间作为系统过载的判断标准。当平均等待时间超过 20 毫秒时，它会以一定的降速因子来过滤部分请求。相反，如果判断平均等待时间低于 20 毫秒，则会逐渐提高请求的通过率。这种“快速降低，缓慢提升”的策略有助于防止服务的大幅波动。

### 度量方式

- 要以业务价值为导向，而不是研发人员产出为导向

    - 错误例子：以代码量、功能数

    - 正确例子：前置时间（lead time）、周期时间（cycle time）。这些用户推崇的整体质量交付。

### 工程

#### 微信

- [腾讯技术工程：月活 12.8 亿的微信是如何防止崩溃的？](https://cloud.tencent.com/developer/article/2010913)

    - 单体服务，一个事件只用一个请求，但微服务下，一个事件可能要请求很多的服务，任何一个服务过载失败，就会造成其他的请求都是无效的。

    - 如何判断过载？

        - 为什么不使用响应时间？因为响应时间是跟服务相关的，很多微服务是链式调用，响应时间是不可控的，也是无法标准化的，很难作为一个统一的判断依据。

        - 为什么不使用 CPU 负载：CPU 负载高不代表服务过载，因为一个服务请求处理及时，CPU 处于高位反而是比较良好的表现。

        - 通常判断过载可以使用吞吐量，延迟，CPU 使用率，丢包率，待处理请求数，请求处理事件等等。

            - 微信使用在请求在队列中的平均等待时间作为判断标准，就是从请求到达，到开始处理的时间。腾讯微服务默认的超时时间是 500ms，通过计算每秒或每 2000 个请求的平均等待时间是否超过 20ms，判断是否过载，这个 20ms 是根据微信后台 5 年摸索出来的门槛值。

    - 过载保护策略：

        - 1.业务优先级

            ![image](./Pictures/soft-architecture/wechat-priority.avif)

        - 2.用户优先级

            > 微信分了几十个业务优先级，每个业务优先级下有 128 个用户优先级，所以总的优先级是几千个。

            - 通过 hash 用户唯一 ID，计算用户优先级，为了防止出现总是打豆豆的现象，hash 函数每小时更换
            - 为啥不采用会话 ID 计算优先级呢？采用会话 ID 在用户重新登录时刷新，用户会养成坏习惯，在服务有问题时就会重新登录，这样无疑进一步加剧了服务的过载情况。

        - 3.自适应优先级调整

#### QQ音乐

- [腾讯云开发者：优雅应对故障：QQ音乐怎么做高可用架构体系？](https://cloud.tencent.com/developer/article/2206300)

    - 1.异地双中心：

        - 深圳和上海各有API-Gateway（接入层）：从而实现STGW（腾讯基于 Nginx 自研的支持大规模并发的七层负载均衡服务）

            ![image](./Pictures/soft-architecture/qq-music.avif)

        - 逻辑层：深圳读/写；上海只读，上海的写请求由API网关路由到深圳中心处理

        - 存储层：深圳写入存储，通过同步中心/存储组件同步到上海。同步组件为[Cmongo（腾讯研发的MongoDB）](https://github.com/Tencent/CMONGO)和CKV+（腾讯自研的分布式kv数据库）

            - [CKV+之进化历程](https://cloud.tencent.com/developer/article/1387361)
                - 兼容redis协议
                - 多租户模式
                - CKV+在最终一致的数据同步基础上，引入了基于Raft协议的强一致同步逻辑

    - 2.异地容灾：在API网关上做故障转移，降低客户端参与度。

        ![image](./Pictures/soft-architecture/qq-music1.avif)

        - 1.API网关故障转移：当本地中心API返回失败时（包括触发熔断和限流），API网关把请求路由到异地处理。以此解决API故障的场景。

            - 为防止异地重试流量被压垮，出现双中心雪崩，要有自适应重试方案，在异地成功率下降的时候，取消重试：

                - 引入重试窗口：耗光后，取消重试

        - 2.客户端故障转移：当API网关发生超时的时候，客户单进行异地重试。如果网关有回包，即使API返回失败，客户端也不重试。解决API网关故障的场景。

        - 当双中心的API-Gateway均异常：所有客户端请求冻结一段时间。

    - 3.自适应限流：请求量超出阈值后在主调直接丢弃请求，在集群扩缩容后需要及时更新限流阈值

    - 4.熔断：

        ![image](./Pictures/soft-architecture/qq-music2.avif)

        - 当“统一权限”服务的其中一个依赖服务（比如歌曲权限配置服务）出现故障时，只能被动的等待依赖服务报错或者请求超时，下游连接池会逐渐被耗光，入口请求大量堆积，CPU、内存等资源逐渐耗尽，导致服务宕掉。
        - 而依赖“统一权限”服务的上游服务，也会因为相同的原因出现故障，一系列的级联故障最终会导致整个系统宕掉。

        - 传统熔断器 有三种状态：Closed、Half Open、Open

            - Open状态：拒绝所有请求

            - 进入Closed状态时瞬间会有大量请求，服务端可能还没有完全恢复，会导致熔断器又切换到Open状态，一种比较刚性的熔断策略。

        - SRE熔断器 有两种状态：Closed、Half-Open

            - 根据请求成功率自适应地丢弃请求，尽可能多地让请求成功请求到服务端，是一种更弹性的熔断策略。

            - 熔断器阈值：

                - 正常情况下 requests（窗口时间内请求数） = accepts（正常处理的请求数） 时丢弃概率为0。
                - K：敏感度，K越小丢弃概率越大，一般在1.5-2之间

                - requests不断减少直到 requests 等于 K * accepts 时：熔断器就会打开，并按照概率丢弃请求。

            - QQ音乐采用SRE熔断器

    - 动态超时

        - 微服务架构的演进，超时逐渐被标准化到RPC中

        - 传统超时会设定一个固定的阈值，响应时间超过阈值就返回失败。

        - 微服务基于EMA算法动态调整超时时长。

            - [EMA算法](https://github.com/jiamao/ema-timeout)是综合利用历史上积累到的数据，预测下一个周期内的期望。EMA算法引入“平均超时”的概念，用平均响应时间代替固定超时时间，只要平均响应时间没有超时即可，而不是要求每次都不能超时。

    - 服务分级

        - 每日邮件推送1级服务和2级服务的观测数据

        - 为针对1级服务和2级服务制定SLO（达到某一段时间内的目标数值），签订SLA（无法完成商业承诺，就付出代价）

        - API-Gateway根据服务分级限流，优先确保1级服务通过

        | 等级                                                           | 例子                                         |
        |----------------------------------------------------------------|----------------------------------------------|
        | 1级 ：如果出现故障会导致用户或业务产生重大损失                 | 登录服务、流媒体服务、权限服务、数专服务等。 |
        | 2级 ：如果出现故障会导致用户体验受到影响，但是不会完全无法使用 | 排行榜服务、评论服务等。                     |
        | 3级 ：不容易注意或很难发现                                     | 用户头像服务，弹窗服务等。                   |
        | 4级 ：即使失败，也不会对用户体验造成影响                       | 比如红点服务等。                             |

    - 工具链：在故障触发之前，尽可能多地识别风险，针对性地加固和防范，而不是等着故障发生。

        - 混沌工程：通过注入网络超时等故障，主动找出系统中的脆弱环节

            - QQ音乐使用ChaosMesh结合其他组件打造的混沌工程平台

        - 全链路压测：通过注入流量给系统施加压力的方式，来发现系统的性能瓶颈

        - Prometheus + Grafana做可视化展示

            - 秒级监控：基于Prometheus构建联邦集群，每3秒抓取一次数据，实现了准实时监控。并对活动进行快照采集，记录活动发生时所有微服务的请求峰值

            - 历史数据回溯：当我们需要回溯近一个月甚至一年前的指标趋势时，性能是个极大挑战。由于历史数据的精度要求不高。通过Prometheus联邦进行阶梯降采样，可以永久存放历史数据，同时也极大降低存储成本。
        - Logging

            - ELK（ElasticSearch、Logstash、Kibana）构建日志处理平台

                ![image](./Pictures/soft-architecture/qq-music-Logging.avif)

            - Filebeat 作为日志采集和传送器。Filebeat监视服务日志文件并将日志数据发送到Kafka。Kafka 在Filebeat和Logstash之间做解耦。
            - Logstash 解析多种日志格式并发送给下游。ElasticSearch 存储Logstash处理后的数据，并建立索引以便快速检索。
            - Kibana 是一个基于ElasticSearch查看日志的系统，可以使用查询语法来搜索日志，在查询时制定时间和日期范围或使用正则表达式来查找匹配的字符串。

        - Tracing追踪：一个客户端请求由系统中大量微服务配合完成处理，这增加了定位问题的难度。

            - Tracing在触发第一个调用时生成关联标识Trace ID，我们可以通过RPC把它传递给所有的后续调用，就能关联整条调用链。Tracing还通过Span来表示调用链中的各个调用之间的关系。

            - QQ音乐基于jaeger构建分布式链路追踪系统，实现分布式架构下的事务追踪、性能分析、故障溯源、服务依赖拓扑。

                - 1.jaeger client发送的spans通过jaeger-agent（代理）转发到jaeger-collector。
                - 2.jaeger-collector 接收后，验证和清洗数据后转发至kafka。
                - 3.jaeger-ingester 从kafka消费数据，并存储到ElasticSearch。
                - 4.jaeger-query 封装用于从ElasticSearch中检索traces的APIs。

                ![image](./Pictures/soft-architecture/qq-music-jaeger.avif)

        - profile：基于[conprof](https://github.com/geekgao/conprof)搭建持续性能分析系统

        - Dumps

            - core dumps：在进程崩溃时把进程内存写入一个镜像中以供分析，或者把panic信息写到日志中

                - 在容器环境中实施困难，panic信息写入日志则容易被其他日志冲掉且感知太弱。

            - QQ音乐使用的方式是在RPC框架中以拦截器的方式注入，发生panic后上报到sentry平台。

#### 携程

- [腾讯云社区：计算压力倍增，携程度假起价引擎架构演变](https://cloud.tencent.com/developer/inventory/334/article/1625083)

    - 任务队列：旅游产品不像单品售卖，产品价格是由多种资源组成（机票、酒店、火、X等）,任意一项资源价格、库存发生变化，都会导致整包价改变，变量太多。

        - 任务队列在算完机票资源之后，再算酒店，算完酒店后进行单选项资源处理，最终汇总出价格。

        - 1.0版本：

            - 任务队列：

                - 用MySQL做任务队列，并且针对每个任务队列同步到sqlserver。分了2个库，64张表

                - 之后用Redis的根据资源分成多队列，代替mysql

        - 2.0版本：

            - 任务队列：Kafka代替redis

            - 任务生成：我们引入了分布式计算框架Spark，从原有的.net代码体系切换到Java

            - 线路聚合：

                - 航线1北京->上海和航线2上海->北京->上海，进行聚合，从而减少请求

        - 3.0版本：

            - 任务生成：首先是消息对产品进行解析，拿到产品的出发地、出发日期，再结合其他的信息，把这些相关的信息写到分布式文件系统里面，再通过Spark进行不同资源的聚合排序，然后再把它写回到分布式文件系统里面，接着通过某一个job去把这些信息取出来，然后把消息发送出去。

                - HDFS分布式文件系统把任务信息分发到下一步的这一个步骤简化了，在消息发送的时候，直接通过Spark进行消息发送，比如它里面可能有几百个节点，我们这几百个节点同时发送这个消息

            - 数据库：HBase替换MySQL

            - 依然存在的瓶颈问题：价格库存依赖外部的资源。外部资源的变化对系统是黑盒，只能依赖API离线计算，API的调用量也会有限制等。也就是活包

        - 缓存预热：对外的价格日历班期查询是有用到缓存的，整个缓存我们相当于是7×24小时不间断一直在写入，所以其实也不怎么存在预热的问题。

- [腾讯云社区：日均20亿流量：携程机票查询系统的架构升级](https://cloud.tencent.com/developer/article/1624858)

    - 三个独立的数据中心

    - SpringCloud + K8s + AWS云服务

    - AI的应用：

        - 反爬虫：屏蔽掉9%的流量

        - 查询筛选：在聚合服务中找出价值最高实际用户，然后把他们的请求发到引擎当中。对于一些实际价值没有那么高的，更多的是用缓存

        - 智能设置TTL生命周期：TTL与业务密切相关的

            - 缓存一致性例子：刚刚看到一个低价机票，点进去就没有了。这种情况出现的原因可能是什么呢？大家知道，航空公司的低价舱位票，一次可能就只放出来几张，如果是热门航线，可能同时有几百人在查询。所以，几百人都可能会看到这几张票，它就会出现在缓存里边。如果已经有10个人去订了票，其他人看到缓存再点进去，运价就已经失效了。

            - 解决方法：
                - 1.缓存超过固定阈值就强行清除。
                - 2.动态刷新：在达到固定阈值之前，有用户查询就刷新缓存


        ![image](./Pictures/soft-architecture/携程-机票查询-AI应用.avif)

    - 缓存架构：

        - 一级缓存是最终的结果，二级缓存是中间结果

            - 聚合服务需要多个返回结果的话，那么很大程度上都是先读一级缓存，一级缓存没有命中的话，再从二级缓存里面去读中间结果

        ![image](./Pictures/soft-architecture/携程-机票查询-缓存架构.avif)

        - 一级缓存：

            - 使用了Redis
            - 固定的TTL，一般低于5分钟的，一些场景下可能只有几十秒

        - 二级缓存：

            - 一开始使用MongoDB，后来改为Redis
            - 通过AI设定的TTL，使得命中率提升了27%

        - 缓存预热：一个分布式的，可能有一小部分节点，比如要下线或者什么，但是对整个缓存机制来说影响很小，然后这一部分请求又分散到我们的多个服务器上，几乎不会产生太大的抖动的。

    - 负载均衡Pooling：我们有一些计算非常密集的引擎，存在一些耗时长，耗费CPU资源比较多的子任务，同时这些子任务中可能夹杂着一些实时请求，所以这些任务可能会留在线程里边，阻塞整个流程。

        - 把子任务放在queue里，将节点作为worker，总是动态的去取，每次只取一个，计算完了要么把结果返回，要么把中间结果再放回queue。

            - queue基于Redis队列，有的键值里加入了IP地址

                - 为什么不使用消息队列？由于它存在很明显的顺序性，不能够基于键值去读到你所写的，比如你发送了一个子任务，这时候你要定时去拿这个结果，但是你基于其他的消息队列或者内存队列是没法拿到的

            - 如果有任何实时的外部调用，我们就可以把它分成多次，放进queue进行task的整个提交执行和应用结果的返回。

        ![image](./Pictures/soft-architecture/携程-机票查询-负载均衡.avif)

        - Pooling的过载保护：

            - 如果没有过载保护，很容易就会发生滚雪球效应，queue里面的任务越来越多，当系统取到一个任务的时候，实际上它的原请求可能早就已经timeout了。

            - 当流量实在太高的情况下，把等待时间超过某一个阈值的请求全都扔掉。

            ![image](./Pictures/soft-architecture/携程-机票查询-过载保护.avif)

# 客户端架构

- [B站PC客户端-架构设计](https://www.bilibili.com/read/cv22750308?spm_id_from=333.999.0.0)

    - Electron = Chromium + nodejs + nativeAPI（系统对话框、系统托盘、系统菜单、剪切板等）

    - Electron运行时：主进程 (Main Process)  + 渲染进程(Render Process)
        - 主进程： NodeJs 和原生 API
        - 渲染进程：前端技术
        - 主进程和渲染进程之间通过 IPC 进行通信
        ![image](./Pictures/soft-architecture/electron-runtime.avif)

    - B站的Electron方案：

        - 渲染进程和主进程都是基于 TypeScript 进行开发的

            - 主进程和渲染进程的中间，设计了一个 common 共享层，用来实现 Ts 类型和常量的共享。

        - 主进程： NodeJs + NestJs + Esbuild

            - NestJs：是一个受 Angular 启发的 NodeJS 后端框架，风格有点像 SpringBoot

                - 结合 OOP (Object Oriented Programming)、FP (Functional Programming) 和 FRP (Functional Reactive Programming) 等编程范式，能够开发出高可测、好拓展、松耦合、易维护的应用。

            - Esbuild：使用 go 语言实现的 js 极速打包工具

        - 渲染进程：Vue3 + Vite2 + TypeScript

            - 并且还应用了B站自研的 Vue3 组件库 vivid-ui、函数库 @bilibili/b-utils 和样式库 @bilibili/b-style 等工具库。

        - 根据业务功能，结合框架和技术栈的整体架构：

            - 渲染进程：
                - 账号登录、大会员充值、直播间和开播页都是使用 webview 嵌 WEB 页的方式接入的
                - 其它业务模块均为本地应用页面

                - 渲染层是基于 Vue 开发的 SPA 应用，主窗口和播放窗口在打开时会有一个比较耗时的加载过程，我们专门针对窗口创建和打开过程做了优化。
                    - 1.在启动时（首次打开主窗口），会先创建一个隐藏的主窗口，加载一个相对简单的开屏页。主窗口和开屏页显示之后，在主窗口开屏页下方加载和渲染比较大的主页面。

                    - 2.主页面渲染完成时，调用主进程 mainWindowReady 接口，并关闭盖在主页面上面的开屏页。主进程收到 mainWindowReady 后，创建一个隐藏的播放窗口。

                    - 3.当用户点击播放视频时，显示已渲染好的播放窗口，并加载和播放视频。关闭主窗口和播放窗口时，只将窗口隐藏并不真实销毁窗口实例，当再次打开或播放视频时，就可以快速打开窗口，提升用户体验。

                    ![image](./Pictures/soft-architecture/b-architecture-窗口优化.avif)

                - “节能模式”：渲染进程占用资源比较大，如果用户长时间未使用又没有关闭的话就会造成资源浪费，当 APP 隐藏到托盘超过一定时间未点开后会进入到此模式
                    - 会杀掉主窗口和播放窗口对应的渲染进程，释放资源占用。
                    - 再次打开时，由于没有 APP 初始化的任务，速度会比冷启动时要快很多。

            - 主进程：

                - 本地日志、本地存储和下载 SDK 都是引入的模块，其它各个模块和服务之间通过依赖注入和 rxjs 主题订阅的方式实现相互调用

                - 一个窗口页面其实本质上就是一个 HTML 页面。
                    - 主页面都是从由主进程创建的本地服务器上拉取的 Local 页面，因此断网的情况也能响应
                    - 首页、动态网络强相关的页面，在断网时会显示失败提示
                    - 离线缓存、设置等功能都能正常使用。

            - JSB 则由主进程通过 preload 的方式注入到渲染进程各页面的 window 对象中，渲染进程不论是外嵌还是本地页面都能访问到 JSB 对象实现和主进程通信。

            ![image](./Pictures/soft-architecture/b-architecture-electron.avif)

                - 主要包含 7 个常跓进程：
                    - 1 个浏览器 (Browser) 进程
                    - 1 个 GPU 进程
                    - 1 个网络服务 (Network Service) 进程
                    - 1 个音频服务 (Audio Service) 进程
                    - 3 个页面 (Tab) 进程。
                    - 通过主进程 app.getAppMetrics()方法获取 APP 各进程的 CPU 和内存数据统计

        - 开发平台工具
            - Fawkes 平台打包构建
            - 北极星进行数据上报并在观远建立数据报表
            - 魔镜平台进行自动化巡检测试
            - 在 info.bilibili.co（企业微信） 上建有专门的产品和开发文档，开发方面也有明确的代码规范要求
            ![image](./Pictures/soft-architecture/b-architecture-开发平台工具.avif)

        - 构建都基于 NPM Script， 由于构建产物也是 js 代码，很容易被人拿去套壳、植入或篡改。

            - 对构建包进行加密处理：实现了一套使用结合代码混淆、对称加密、字节码处理、WASM 解密和啥希校验的组合式客户端加密防破解方案。

                - 在打 Release 包时，会把构建生成的代码先进行混淆、压缩处理，再将主进程主程序代码使用 AES-256 对称加密生成 / app/main/.biliapp 文件，将解密和执行入口使用字节码处理，最后计算出 APP 的哈希值。

                - 当 PC 客户端启动时，会先根据操作系统和系统架构找到对应字节码入口、解密并运行主程序、主程序中校验 APP 的哈希值，在确定运行环境安全后再正常启动程序。

                ![image](./Pictures/soft-architecture/b-architecture-防破解.avif)

        - 增量更新：

            - 基于 electron-builder 进行打包，Mac 的安装窗口通过 electron-builder 配置可以直接生成，Windows 的专属一键三连安装程序则是使用 NSIS + QT 独立开发的。
                ![image](./Pictures/soft-architecture/b-architecture-打包.avif)

            - 前期版本基于 electron-updater 进行升级更新。在 1.9.x 版本之后，只需对 app.asar 代码包进行更新而不是包含框架的完整安装包

        - 双窗口模式：

            - 主窗口和播放窗口是独立的，类似爱奇艺和腾讯视频，可以让用户一边播放视频一边刷动态、逛空间、看消息。

            - PC客户端对比WEB：

                - 播放质量：PC 客户端的首帧和 VV 卡顿率会优于 WEB，主要原因为能更多预载，单实例，编码支持统一

                - 百分钟卡顿率和错误率：PC 客户端相对 WEB 来说要略高一些，新平台有更多 case 需要处理，此项会略高但重试机制尽量不影响体验。

                - PC 客户端的播放器技术：

                    - 直接用上了WEB 强大的 Nano 播放器，拥有了高级弹幕、播放设置、播放器快捷键等功能。

                    - 还将 UGC 和 OGV 播放器集成在同一个播放窗口，让视频类型切换更加顺畅，还可以通过前进后退播放历史纪录。

# 新技术的危害

- 企业软件的成本，只有20%是早期的开发成本，剩下的80%都是后期的维护和更新成本。

- 很多的新技术，看上去可以节省前面20%的开发成本，但可能大大增加后面80%的维护成本。

- 没有一种技术是完美的，每个工具决策都是一种权衡。

- [On Endings: Why & How We Retired Elm at Culture Amp](https://kevinyank.com/posts/on-endings-why-how-we-retired-elm-at-culture-amp/)

    > 在自豪地宣传Elm作为构建Web UI的首选语言四年后，Culture Amp公司决定放弃它。

    - Elm是Web应用程序语言。它编译为JavaScript，可以在任何Web浏览器中运行，但作为一种基于ML的函数式编程语言，它看起来像Haskell -也就是说，几乎不像JavaScript。JavaScript充满了括号和花括号；Elm的杂乱程度要低得多

    - 回顾Elm在Culture Amp的表现。我们使用Elm构建的部分产品在第一次生产部署时就可以不出错运行。Elm本身非常稳定，具有讽刺意味的是，这种稳定性实际上在几个场合对我们不利，已经有很多年没有人看过它了，而构建它的团队经常完全忘记它是如何工作的！！值得庆幸的是，Elm的简单性使得代码简单易读。

    - Elm吸引了一些我们最好的工程师，他们很想在“那种会考虑Elm的地方”工作。与此同时同时Culture Amp避免雇佣纯粹专注于技术的工程师。

        - 作为一家产品公司，我们希望雇佣那些对我们的产品及其使命感到兴奋的人，以及那些乐于在必要时学习新东西以取得进展的人。当有人在采访中告诉我们，他们对在这里工作感到兴奋，因为他们喜欢函数式编程（比如），我们认为这表明他们可能并不适合。由于这种动机的不匹配，我们不止一次选择不雇佣候选人，多年来有一两次我希望我们能更严格地遵守这条路线

    - Elm+React：易于入门，难以维护

        - 一些团队使用React进行构建，而另一些团队使用Elm进行构建。两者导入同样的CSS模块（Sass编写），这种方法一开始取得了很大的成功。因此有能力和信心为组件的两个版本做出更改，以保持它们的同步。但在2018年，这种情况开始发生变化，保持组件的两个版本同步变得越来越困难。

        - 我们收购了另一家公司，该公司的整个代码库都是用React编写的，而其团队对Elm一无所知。一夜之间，我们从一家写了等量的Elm和React的公司，变成了一家写了75% React的公司。

        - 而且TypeScript已经发展到足够强大（并且对开发人员足够友好），可以平衡Elm

    - 最后做出改变

- [GraphQL: From Excitement to Deception](https://betterprogramming.pub/graphql-from-excitement-to-deception-f81f7c95b7cf)
    - GraphQL宣称的优点
        - 1.一次请求，多个资源
        - 2.数据的精确提取：可以对数据进行选择，从而减少网络传输的数据辆
        - 3.强类型

    - 我们的移动团队大力提倡GraphQL。桌面前端团队也喜欢类型的概念。我们在2019年采用了REST API。该团队投入时间为GraphQL构建新的端点。我们选择了Apollo库，它提供React.js、Kotlin和Swift客户端。

    - 我们很快部署了第一个端点，并且GraphQL和REST API可以共存于同一个app上。我们开始增加更多端点，2020年我们增加了50多个端点。

    - 但过了2年，我们发现了问题
        - GraphQL虽然让客户端代码变得简单，但性能比不上REST API

- [Why I regret using Ionic for app development](https://mhamri.com/why-i-regret-using-ionic-for-app-development-c8b21b88d83a)

# 复杂度，熵增，技术债

- [腾讯云开发者：对抗复杂度的圣杯战争：软件架构究竟该如何设计？](https://cloud.tencent.com/developer/article/2373773)

- [腾讯云开发者：99%的程序员容易忽视的“系统”健康问题](https://cloud.tencent.com/developer/article/2361561)

- [腾讯云开发：鹅厂万人热议｜如何理解业务系统的复杂性？](https://cloud.tencent.com/developer/article/2273369)

    - 为什么用户规模或者营收规模不增加，事情反而越来越多呢？

        - 由于业务规模停滞或者下滑，产品侧不得不做更多的事情来止住颓势甚至想要以此力挽狂澜。

        - 要么是不断地拓展产品的边界，在一个应用里加入更多的功能，也就是所谓的交付更多的用户价值，从而吸引更多潜在用户

        - 要么是不断地优化现有功能，例如通过排版来从心理学角度提高用户停留时长和点击率，亦或是进一步优化产品的交互流程，也就是所谓的提升用户体验，从而提升口碑，稳固用户基本盘。

    - 降本增效：

        - 降本：更精细化地使用服务器和存储资源，投入更多精力去关注云上账单，该省的省。在需求的技术评审环节加上成本预估，让那些提极低的 ROI 需求的产品经理知难而退。
            - 就是减少不必要的浪费。
            - 这种减少浪费的降本手段在短期很有用，但很快就会达到收益天花板。更大的收益还是要提升效率，但增效相关的工作，也许你感知到的是寥寥无几。

        - 增效：工程效能（EP）（利用各种好用的开发工具）提升写代码、构建服务以及协同开发的效率。
            - 拥有可以极速处理几百 G 大仓的代码托管平台
            - 拥有高度可配置的流水线来自动化一些日常繁琐的构建任务
            - 有良好设计的 RPC 开发框架
            - 有先进的可观测平台……

        - 这一切的一切，最终目标或许大家也经常听到——让程序员可以专注于业务的开发。

            - 但问题是，在整个软件的开发中，到底是业务开发工作量的占比高，还是非业务开发工作量占比高？

    - 《人月神话》的作者 Fred P. Brooks 的文章 《没有银弹：软件工程的本质性与附属性工作》 中提到：

        - Essential Complexity 是说软件要实现某种功能，而这种功能本身内在就具有复杂性。

        - Accidental Complexity 则代表了程序员在用代码实现功能时，由于各种软硬件等的限制以及人和人的沟通不畅而额外引入的工程上的复杂性。

        -  Essential Complexity 就是不可避免的。即使你消除了所有的Accidental Complexity，Essence Complexity 依然存在。

        - 回到上面的问题：工程效能（EP）和各种中台为开发者提供工具和服务，其实就是在尽量减少 Accidental Complexity。然后让大家可以专注于业务本身的开发，也就是 Essence Complexity。

        - 二八法则在软件开发中：Accident Complexity 是八还是 Essence Complexity是八？

            - 如果 Essence Complexity 是八。那我们一直只在 EP 上做文章，是否有点“隔靴搔痒”？

                - 无数现实中的例子，由于业务建模的不合理、由于需求的仓促上线、由于接口设计的不合理、由于各种无谓的耦合……建立在最牛的基础设施之上的业务系统，一段时间之后又将变成一座废山。代码看得令人眩晕，改功能不知道去哪里改，不知道会影响哪些功能，不知道需要改动的点是否都被覆盖到了，改个小功能要改无数的地方……

                    - 不管基础设施多么优秀，业务代码依然是废山。所以只靠工具提效是远远不够的，还需要关注业务本身，Essential Complexity。

    - 功能之间隐蔽增加的耦合

        - 相信绝大部分开发者在项目一开始的时候，都有一颗“整洁架构”的心，都希望把代码写好。尤其是项目一开始，需求做的飞快，每天几千行代码也不在话下。

            - 大家会关注函数的颗粒度，会关注模块的划分和职责是否单一，也会关注单元测试情况和代码的可测性。即使这样，随着时间推移，大家还是会发现代码改起来越来越痛苦——总会牵一发而动全身，或者明明是修改功能 A，却不得不关注功能B是否受影响。这是为什么呢？

                - 答案就是——耦合。因为 Essential Complexity的存在。如果某个功能本来就需要多个模块共同参与，不论你怎么分解这些模块，只有把它们“集成”到一起，才能实现有意义的功能。把它们集成到一起，A 依赖于 B、B 又依赖 C、C 又会反馈给 A，这不就是耦合吗？

                - 例子：社区类应用有一天，产品经理希望做一个新功能，叫作“名片系统”。简单来说就是，它允许用户自定义自己头像后展示哪些名片或者标签（可以有多个），以突显身份特征

                    ![image](./Pictures/soft-architecture/耦合-社交类应用.avif)

                    - 这个需求其实初看起来没有多复杂，闭上眼睛琢磨大概就能想到。

                        - 这里的重点不是要去不同的系统查数据麻烦，重点是这里引入了新的耦合。

                    - 但是再深入想一想，你就会发现其实并没有想象的那么简单。如果没有意识到由 Essential Complexity 引入的耦合，开发者很可能在排期的时候少估算了天数，最后不得不需要用各种“责任感”、“Ownership”这种精神力量通过加班来尽量保证不 delay。

                - 例子：我们想把App上部分优质的内容分享到微信

                    - 大部分手机App都是用原生的方式开发，例如 IOS 用 Swift/OC、Android用 Java/KT。但微信中只能分享 H5 的 Web 页面。

                    - 这就意味着同样一个需求，除了要用原生做一遍，还需要用 H5 再做一遍。不仅如此，由于分享到微信的H5 页面，用户打开后肯定都是没有登录态，因此还需要让 H5 依赖的后台接口支持无登录态调用。
                    - 有些接口逻辑强依赖于用户登录态怎么办？例如查看资讯详情的接口，接口内部除了要返回资讯内容，还要记录用户的浏览记录，还需要给资讯的浏览量+1。如果你没有关注资讯的作者，可能头像旁边要展示一个关注按钮……这些都需要依赖于用户的登录态才能完成。因此在没有登录态的情况下，就必须阉割一部分现有功能。
                        - 那要怎么阉割呢？在原接口中各种 if else？太 bad taste 了，不仅代码乱成一锅粥，统一的鉴权网关也很难处理。最好就是新开接口专门处理来自 H5 的调用，把它当成另一个独立的需求，而不是强行和之前的接口逻辑写在一起。

                            - 但这还不够，还有很多问题，例如像文章浏览量这种数据怎么处理？没有登录态，就没法对浏览量进行去重。如果每次请求都累加，就会被灰产利用来刷数据。如果不累加，似乎对作者又不太公平？这可能会导致产品侧需要同时记录有效浏览量和无登录态浏览量，这又是一个新需求了。

    - 这是发生在作者身上的真实故事，一个满腔热血，熟读《整洁架构》《重构》《设计模式》《领域驱动》 《演进式架构》的人，从零开始开发系统，却依然避免不了旧代码走向腐化，成了后人口中的废山始作俑者。

        - 有个机会从零开始负责一个公司重量级的运营系统的开发，内心非常的激动。终于可以按照自己工作之余看书学到的最佳实践方法来构建项目了，这下要让所有人刮目相看。开发过程中，也是恪尽职守，每天晚饭后都花至少1个小时拉着团队另外几个开发人员做 Code Review，经常还争执得面红耳赤，对 Bad Taste 坚决抵制。

        - 项目整体推进得很顺利，上线后取得了很大的成功，只是后来由于组织架构变动，去了另一个团队，不再负责那个项目了。不过本人一直觉得，自己给接盘方打下了一个非常好的基础，对方一定会感谢自己……直到一年后的某天，和一个同事无意间聊起来，他们就负责了我之前的那个项目（他不知道我之前负责那个项目）。本以为能从他那得到些正向的评价，结果全是吐槽，诸如代码看不懂、风格奇葩、扩展困难等等。最后补了一句，后来实在受不了，他们重写了。

        - 腐化是不可避免核心原因：架构设计和模块抽象只能面向当下，它天然是短视的或者说是有局限性的。这种局限性即使是最优秀的架构师也是无法逾越的。

    - 两个常见的开发模式：
        - 1.瀑布流式开发（上个世纪比较传统的开发模式）：
            - 甲方提需求，我要做一个什么样的软件，它要包含哪些功能 。软件公司作为乙方，来承接甲方的需求。它首先需要有人去调研甲方的需求，具象化每个功能点，然后形成最终的需求文档和性能要求文档。当甲方对需求认可并签字后，就进入了架构师的设计阶段。
            - 这个阶段架构师能够看到所有的需求，他拥有全局的视角，然后进行架构设计、方案设计和模块的拆分。最后根据架构师的设计，开发部门就分模块进行开发。
            - 开发完成之后进入测试阶段，测试完成后再交给甲方去验收，验收通过就正式交付。

            - 缺点：
                - 开发方式周期很长，动辄就是以6 个月甚至 1 年起步，很多大项目甚至要 3 年以上。但商场如战场，形势瞬息万变，等你做出来，黄花菜都凉了，再好的软件又有什么用呢？

                - 任何一个环节出问题，都会导致后续环节出问题：甲方验收时：“当初说的做 XXX，但是你们做出来是 YYY，根本不是我要的，不满足需求”。这又会涉及大量的返工，进一步让项目延期。

        - 2.敏捷开发：小步快跑，先做最重要的部分。

            - 现在互联网公司基本上都是快节奏的发布，做App 都是先发 MVP 版本（最初可用版），然后再持续优化。每个迭代，产品经理都是只提几个有限的需求，开发也只开发这几个需求就上线。然后就进入不断堆功能的小步快跑阶段，缝缝补补又一年。产品经理也会用各种方式尝试去识别功能的收益，埋点、报表、同比环比等等。

            - 优点：它能够快速捕捉市场机会，让自己活下来，活下来才有机会谈成本，再找到性价比高的地方去优化。

            - 缺点：做技术方案设计时，能拿到的信息仅仅是宏大视图中的小小一角，根本没有全貌，并不能像瀑布流开发那样拿到产品的整体视图。仅仅凭借这一点点信息，再牛的架构师设计出来的方案也是有局限性的
                - 这也是为什么前面说架构设计和模块抽象只能面向当下，它天然是短视的。这不是人的问题，这是开发方式的问题。


