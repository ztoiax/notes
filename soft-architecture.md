
<!-- mtoc-start -->

* [企业文化](#企业文化)
  * [云计算公司 Snowflake](#云计算公司-snowflake)
  * [华为](#华为)
* [it历史](#it历史)
* [开源相关](#开源相关)
* [项目管理](#项目管理)
* [软技能](#软技能)
* [数据中心（IDC）](#数据中心idc)
* [api设计](#api设计)
* [架构](#架构)
  * [架构设计](#架构设计)
    * [腾讯技术工程：谈谈架构设计](#腾讯技术工程谈谈架构设计)
    * [技术琐话：一家中型互联网公司的架构演进之路](#技术琐话一家中型互联网公司的架构演进之路)
  * [架构师](#架构师)
  * [架构安全](#架构安全)
  * [软件开发](#软件开发)
  * [DevOps](#devops)
  * [SRE (Site Reliability Engineering，可靠性工程）](#sre-site-reliability-engineering可靠性工程)
    * [SRE roadmap](#sre-roadmap)
    * [卡瓦邦噶：SRE 的工作介绍](#卡瓦邦噶sre-的工作介绍)
      * [SRE工作分层](#sre工作分层)
      * [部署服务](#部署服务)
      * [Oncall（保证线上服务的正常运行）](#oncall保证线上服务的正常运行)
      * [制定和交付 SLI/SLO](#制定和交付-slislo)
      * [故障复盘](#故障复盘)
      * [容量规划](#容量规划)
      * [用户支持](#用户支持)
      * [有关做项目没有专业团队得不到训练](#有关做项目没有专业团队得不到训练)
      * [有关背锅](#有关背锅)
      * [面试会问什么？](#面试会问什么)
      * [选择大公司还是小公司？](#选择大公司还是小公司)
        * [如何判断一家公司是否靠谱？](#如何判断一家公司是否靠谱)
    * [争议](#争议)
  * [DDD(领域驱动设计)](#ddd领域驱动设计)
  * [中台](#中台)
    * [游戏公司Supercell（超级细胞）](#游戏公司supercell超级细胞)
    * [36氪：中台，我信了你的邪 | 深氪](#36氪中台我信了你的邪--深氪)
      * [不是IT问题，而是组织问题](#不是it问题而是组织问题)
      * [反思中台](#反思中台)
  * [微服务](#微服务)
    * [微服务理论](#微服务理论)
      * [康威定律](#康威定律)
      * [谁适合微服务？](#谁适合微服务)
    * [微服务架构](#微服务架构)
      * [熔断、隔离、重试、降级、超时、限流，高可用架构流量治理核心策略全掌握](#熔断隔离重试降级超时限流高可用架构流量治理核心策略全掌握)
    * [单元化架构](#单元化架构)
      * [腾讯技术工程：腾讯云单元化架构体系介绍](#腾讯技术工程腾讯云单元化架构体系介绍)
        * [技术架构发展历程](#技术架构发展历程)
        * [大型微服务系统面临的问题](#大型微服务系统面临的问题)
        * [腾讯云单元化架构体系](#腾讯云单元化架构体系)
          * [什么是单元化架构](#什么是单元化架构)
          * [与微服务架构的区别](#与微服务架构的区别)
          * [单元化架构优势](#单元化架构优势)
          * [单元化架构的挑战](#单元化架构的挑战)
          * [腾讯云单元化架构TCUA](#腾讯云单元化架构tcua)
    * [度量方式](#度量方式)
    * [工程](#工程)
      * [携程](#携程)
* [并发架构](#并发架构)
  * [异步架构](#异步架构)
* [防崩溃](#防崩溃)
  * [容灾架构](#容灾架构)
    * [主流容灾架构对比](#主流容灾架构对比)
      * [同城灾备](#同城灾备)
      * [同城双活](#同城双活)
      * [异地双活](#异地双活)
      * [异地多活](#异地多活)
  * [腾讯技术工程：月活 12.8 亿的微信是如何防止崩溃的？](#腾讯技术工程月活-128-亿的微信是如何防止崩溃的)
  * [腾讯云开发者：优雅应对故障：QQ音乐怎么做高可用架构体系？](#腾讯云开发者优雅应对故障qq音乐怎么做高可用架构体系)
* [客户端架构](#客户端架构)
* [电商架构](#电商架构)
  * [二马读书：秒杀，这是我见过最最实用的技术方案](#二马读书秒杀这是我见过最最实用的技术方案)
* [新技术的危害](#新技术的危害)
* [复杂度，熵增，技术债](#复杂度熵增技术债)
* [管理问题](#管理问题)

<!-- mtoc-end -->

# 企业文化

## 云计算公司 Snowflake

- CEO弗兰克·斯洛特曼 (Frank Slootman) 出版的一本书《Amp it up》

    >“我们的公司是海军陆战队，不是和平队。平静的生活不属于我们。像我们这样的创业公司，每天都要为了生存而与巨头对抗。我们是偏执狂，时时刻刻感到生存受威胁。加入我们，你必须有战斗心态。”

    - 1.加快节奏，时刻要求员工以更快的速度完成工作。
        > 如果你说一周后可以有结果，他就问你为什么不能明天或后天出结果？这倒不是因为着急，而是他要增加所有人的紧迫感。
        > 
        > 公司变大了，就会行动迟缓，不愿意冒险。只有加快节奏，才能让公司始终充满活力，保持兴奋度。
        > 
        > 他说：“要求某人做某事快20%，他们会使用传统策略。如果要求快2,000%，他们将不得不推翻所有基本假设，使用非传统策略，进行重大创新。”

    - 2.要求员工思考一些极端问题，打破传统思维的束缚。
        > 你如何在接下来的六个月内实现你的10年目标？
        > 
        > 如果每周只能工作一天，我们应该如何改变工作方式？
        > 
        > 如果现有的营销渠道都消失了，我们将如何发展新客户？
        > 
        > 产品增加什么特性，可以让价格提高10倍？
        > 
        > 如果你有10倍的资源，会对产品做哪些改变？

    - 3.提出明确的、雄心勃勃的目标，鼓励员工大胆行动。
        > iPod mini 的早期口号是“口袋里有 1,000 首歌曲”，SpaceX 公司的目标是让人类成为“多星球物种”。目标越清晰、越雄心勃勃，传统的惰性思维就越难生存。

    - 4.拒绝平庸的产品。
        > 他采取史蒂夫·乔布斯的标准，产品只有两种，要么是非常棒，要么是一塌糊涂，没有中间等级。
        >
        > 员工开发出新产品和新功能时，他会问：“你兴奋吗？你从心里喜欢它吗？”如果没有得到肯定答复，产品就必须重新调整。

    - 5.一流员工得到高额奖金。
        > 每个季度末，公司都要举行绩效评定，一年要评4次绩效。
        >
        > 绩效分布是一个钟形曲线，高绩效员工总是头部的少数人，可以得到极高的奖金。奖金放在一个奖金池，其他人只能分剩下的奖金，或者根本没有奖金。大多数公司里面，一流员工的薪水，相比他们的贡献都偏低，这不利于激励优秀员工。

    - 6.缩小焦点，他要求员工只关注最重要的事情。
        > “请列出接下来需要解决的100个问题，然后只留下最重要的问题1和问题2，放弃其他98个问题。”
        > 
        > 任何偏离核心使命的事情都会让人分心。对于同一个团队的每个成员，他分别挨个问：“你们团队的优先事项是什么？” 如果答案不一致，他就知道团队不够专注，必须整改。

## 华为

- [一只羊咩咩1995](https://www.bilibili.com/list/watchlater?oid=284344040&bvid=BV1Bc411v7ok)

# it历史

- [文化纵横：很多人为小红书欢呼, 却误解了“中国平台海外用”现象的本质](https://mp.weixin.qq.com/s/wpaNxrIVHfX7o45-ly6UFw)
    > 美国是原发性创新，中国是组合式创新，并在进入下一个阶段，成功出海（如tiktok、小红书、Temu、SHEIN，威胁美国这位师傅。

- [支付进阶之路：一文看懂收单支付40年的风起云涌](https://mp.weixin.qq.com/s/2yXk51nYFlwAcPvFQzNTBg)

- [K哥爬虫：这家准上市公司，曾因爬虫违法，CEO被捕判刑！](https://mp.weixin.qq.com/s/d6QuQWNVawBNMOLT8Bb8SA)
    > 车来了

# 开源相关

- 海尔向一位海外开发者发出律师函，要求他从 GitHub 下架他维护的开源项目：[Home Assistant](https://github.com/Andre0512/hon)

    - 该项目是一个开源智能家电自动化平台，可以让用户控制海尔的智能家电，包括空调、净化器、冰箱等。

- 网易云音乐公司起诉侵权，要求删除。国内的网易云音乐 API 开源项目：[NeteaseCloudMusicApi](https://github.com/Binaryify/NeteaseCloudMusicApi)

    - 该项目是作者用 Node.js 封装的第三方网易云音乐 API，很多网易云音乐的开源客户端都依赖它，目前该项目已删库，仅留下一句：“保护版权,此仓库不再维护”。


# 项目管理

- [腾讯云开发者：项目总延期？需求乱插队？程序员如何做好项目管理](https://cloud.tencent.com/developer/article/2242782)

- 项目管理是「通过别人做成事情」的能力：

    - 例子：汉高祖刘邦有一句经典名言：“夫运筹策帷帐之中，决胜于千里之外，吾不如子房(张良)。镇国家，抚百姓，给馈饟，不绝粮道，吾不如萧何。连百万之军，战必胜，攻必取，吾不如韩信。此三者，皆人杰也，吾能用之，此吾所以取天下也。”正是刘邦具备协调张良、萧何、韩信三人协同工作的能力，才使得其能夺取天下，建立大汉王朝。

- 《项目管理精华》一书将项目管理视为「21 世纪独有的工作」，作者认为每一名知识型工作者都在工作中不知不觉中扮演着「非职业项目经理」的角色。开发者其实就是典型的知识型工作者。

- 《微权力下的项目管理》一书讲到项目经理往往需要有个人魅力去影响他人做事，进而达成目标。项目管理能提升与各类干系人打交道的能力，进而提升一个人在组织内的个人影响力。

- 项目管理的生活的例子：房屋装修。装修工期长，涉及各种材料购置。一次性购置材料会阻碍工人干活，分批购置，又怕丢三落四忙不开；等师傅进场再买，又担心延误工期。除此之外，装修还需要与各类工种打交道，要合理安排各工种工作排序、工期管理。

    - 在装修中，能不能少花点钱，就看一个人“成本管理“做得怎么样；能不能快点住进新房子取决于一个人的“进度管理”；而能不能住的安心，就要看“质量管理”有没有做好。

- 项目管理上的痛点：

    | 痛点问题           |                                                |
    |--------------------|------------------------------------------------|
    | 工作量评估问题     | 工作量评估不准确                               |
    | 进度问题           | 日常杂事或者临时问题打乱排期                   |
    | 外部依赖问题       | 设计/后台等外部资源延期/需求变更，怎么推动解决 |
    | 沟通问题           | 如何让大家对需求的理解保持一致                 |
    | 效率和质量平衡问题 | 怎么既保证开发效率又保证质量                   |

    ![image](./Pictures/soft-architecture/项目管理的好坏.avif)

- 如何做好进度管理：

    - 1.如何做好工作量的评估

        - 做好工作量评估是做好进度管理最关键的一步

        - 1.做好详细需求方案的设计。
            - 在做完后，再通过有开发经验的工作人员评审。

                - 一般经验丰富的开发人员能够通过设计方案发现背后的风险，能够及时将架构设计的不合理、兼容性未考虑等问题提前暴露出来，同时也能更加明确工作量。理论上来说，在完成需求方案评审后，后续的改动很少，整体的工作时长更加可控。

            - 如果开发周期大于一个月，建议分成多个需求迭代，以降低迭代周期，小步快跑。

        - 2.合理拆解，明确职责
        ![image](./Pictures/soft-architecture/项目管理拆解.avif)

            - 最好工作拆解的粒度为一至两天。
                - 太长，就会存在工作量评估不准确、整体项目难以把控的问题。不利于工作的合理分配，不能更好地利用人力资源。
                - 太短，就会导致工作交付的频率过快，开发者的工作之间也会存在着一定的耦合。拆解的粒度太小，会增加一定的沟通成本，得不偿失。

            - 成果作为导向原则
                - 任务拆解应该以可交互的结果作为导向，并且一定要有输出。这个输出应该是完整的，不然这个拆解就拆解得不够透彻，或者说不算一个任务。

            - 责任到人原则
                - 拆解之后的任务项，有且只能有一个负责人。即使许多人都可能在其上工作，也只能由一个人负责，其他人只能是参与者。

            - 任务分层原则
                - 任务拆解的过程也是一个解耦的过程，避免多个任务之间有耦合。拆解的过程应该是自上向下的，从一个大的任务，按照其特性进行任务拆解，不断地拆解成子任务，直到拆解到一至两天的工作量，并且是一个可交付的工作项。

            - h5项目例子：一共有四个大的功能模块，三个开发人员
            ![image](./Pictures/soft-architecture/项目管理拆解-h5例子.avif)

        - 3.工作量评估
            - 在对任务进行拆解后，下一步是对任务进行工作量评估。
            - 工作量评估不准确，就会直接导致该任务项出现问题。
                - 评估的时间偏多，会存在着资源浪费的问题
                - 评估的时间偏少，将直接造成当前任务延期完成，同时阻塞后面模块的开发，损失更大。

            - 自上而下的估算方式：
                - 有类似项目经验的工程师来说较容易评估。
                - 将工作结构从头部向尾部依次分配、传递工作量，直到到达WBS 的最底层。
                - 特点是：
                    - 项目初期信息不足，只能初步分解工作结构，很难将最基本的工作详细内容列出来。
                    - 估算的精度较差。
                    - 估算的工作量小，速度快。

            - 自下而上的估算方式：
                - 先估算各个工作项的工作量，再自下而上的将各个工作量进行汇总，算出总的工作量。
                - 特点是：
                    - 估算的精度高。
                    - 估算的成本较大。
                    - 缺少子工作项之间的工作量估算。

    - 2.如何做好依赖管理

        - 项目延期的常见情况
            - 准备开始开发了，发现设计稿还未就绪。
            - 准备联调的时候，发现我们上下游的技术团队的接口还未就绪。
            - 可以联调的时候，因为上下游的链条很长，出现推诿甩锅。

        - 针对外部依赖问题的解决方法

            - 1.明确责任人和交付时间，避免模糊

                - 当一个事情出现多个负责人的时候，责任的边界就会模糊，就容易互相推诿的情况，这就是责任分散效应。
                - 对于每个依赖项，我们需要明确其责任人，并沟通明确每个人对应依赖的交付时间，把责任人和交付时间提前确定清楚，可以减少很多争议和推诿。

                - 当项目涉及很多团队的时候，可以使用资源依赖列表，当遇到问题时，可以快速查找负责人及其应当交付的时间点。
                - 例子：云游 XX 活动的资源依赖列表
                ![image](./Pictures/soft-architecture/项目管理-资源依赖列表.avif)

            - 2.形成信息对齐机制

                - 确定了接口负责人后，如果不及时进行信息对齐，也会出现跑偏的情况。

                    - 例子：A 项目依赖外部的 sdk的 某个升级版。在最初的对齐方案中，sdk 方承诺不会修改原有的接口调用方式。而实际联调中才发现不仅接口调用方式发生了巨大变化，还有部分被依赖的接口直接在新版本中移除，导致A方需要花费大量时间进行兼容。如果提前对齐而不是等到联调阶段才介入，就能规避上述问题。

                - 信息对齐方式

                    - 1.不定期的非正式沟通
                        - 在里程碑等关键节点通过面对面、电话、企业微信等方式进行信息对齐。对齐内容包括：开发进度、依赖事项进展、技术方案变更等，对于一些关键性的结论，最好有文字落地以用于回溯。

                    - 2.定期的例会机制
                        - 如定期晨会机制。在会议上对齐项目进度，可以提前发现可能存在的风险。记录会议纪要并通过群消息/文档/邮件的形式通知到项目的相关干系人。

                    - 3.项目 owner 机制
                        - 应当确定一个项目 owner，对项目整体负责，把关整体节奏，负责组织会议。把相关信息进行整合，并同步给项目的相关干系人。

                    - 4.求同存异，达成共识

                        - 例子：作为最重要的传统节日，很多业务团队都会针对春节这个时间节点运营、上线活动，作者曾经遇到过在临近提测时，活动仍在被提需要大量变更的情况（运营人员要叠加功能，设计人员则提出更多特效的要求），开发人员如果接受了大量变更，不仅意味着不断加班，更可怕的是会由此带来很大的质量风险，一旦出现严重问题，会得不偿失。
                            - 最后只能是开发人员联合测试人员，跟运营和设计进行了沟通，研发侧认可变更对于提升活动效果有作用，同时也对变更可能带来的延期，以及影响线上质量等风险进行了全面分析评估。双方基于共同的目标做出了协商和让步（既保证活动效果，同时也保证活动正常安全上线）。

                    - 5.情感账户，软性推动

                        - 当项目依赖某个外部团队的人员支持，而这个事情并不是对方当前工作范围内的，并不是对方第一优先级的工作，该怎么办？

                            - 大部分情况，有些开发者会在沟通未果的情况下，通过上升到leader去推动事情落地，这是一种解决方案。

                            - 更优的方案是建立相关依赖方的“情感账户”，借助“情感账户”去软性推动。

                                - 大家都知道银行账户就是把钱存进去，作为储蓄，以备不时之需。“情感账户”里储蓄的是人际关系中不可或缺的信任。经营好「情感账户」，也是经营好一个人与合作伙伴的信任关系。

                                - 在日常工作中多吃亏，让自己的「情感账户」适当“存储”。例如自己曾经抽出休息时间帮助合作伙伴解决问题，当需要对方协助的时候，相信也能得到积极的响应，这也是常说的“吃亏是福"。

    - 3.如何处理意外事项

        - 例子：插入一些高优的需求，或者说发生一些不可控的因素如疫情等等导致人力不足，从而影响项目的进展。

        - 1.需求的变更。
            - 处理方式：

                - 判断需求变更的大小，如果是样式修改等简单变更，半小时能解决的小问题，可以协助快速调整；如果工作量在 0.5 天以上，并且需要依赖第三方接口，则需要将整体的需求重新评估，重新梳理排期，并同步给干系人。 

                - 先保证核心的业务流程不变，高收益的工作量优先处理，保证正常的上线时间，后续有余力再对其它功能点进行迭代优化。

        - 2.高优需求插入
            - 处理方式：
                - 如果被高优需求插入，直接带来的影响是延后当前的工作完成时间。
                - 如果在 0.5 天以内，没有被依赖的下游时，再评估对排期影响不大的情况下是否可以快速响应。并第一时间反馈风险，确保各干系人都有一个心理预期；如果大于 0.5 天的需求，则建议反馈给项目干系人来安排其他人来解决。

        - 3.不可抗力的因素。

            - 例子：开发人员有急事需要请假，又或者因为疫情导致办公效率低下，从而影响项目的进展。

            - 处理方式：
                - 如果是一些身体原因导致办公效率低下。在不影响整体项目交付的情况下，适当的延长完成项目的时间；若影响到整体项目交付的时间，则应该暴露该风险，进行项目计划调整。
                - 如果完全不能投入开发，应该尽早的将此事向上级报备，由上级进行统一的人力调整，交由其他人投入开发。

        - 4.内部依赖延后
            - 处理方式：
                - 将自身的业务流程做好，依赖部分通过模拟的方式解决。
                - 将联调的时间后移，先开发其他的功能模块。
                - 如果已经是最后联调阶段，则需要再次调整交付的时间，同时将该风险同步给相关的干系人。

    - 4.通过流程规范提高质量

        - 1.制定研发流程规范
            - 制定流程有时会让人反感，觉得降低了研发效率。但规范的流程可以大大提升项目的质量，好的流程都是在实践中不断总结出来的，是项目的最佳实践。
            - 尽量将流程变成 CICD 的约束，通过系统来约束、控制，减少其对人的依赖。
            - 当然流程也不是一成不变的，它需要根据我们的具体情况不断调整优化，才能适应当下的需要。
            - 研发团队流程：需求评审、方案设计、需求开发、测试验收、发布上线、项目复盘六个步骤。
            ![image](./Pictures/soft-architecture/项目管理-研发流程.avif)

        - 2.严格执行Code Review

            - code review 的好处不仅仅是能够大大提高代码质量，减少代码 bug，还能从心理上（自己写的代码要给别人审核）让自己更认真严谨些。

        - 3.制定发布清单（checklist）

            - 发布 checklist 一般可以分为服务、机器、流程三部分，通过日常工作中累计容易出错的地方，将其整理收集起来，持续完善。

            参考例子：

            | 提测前                                                                                       |
            |----------------------------------------------------------------------------------------------|
            | 根据前期编写的测试用例进行整体自测                                                           |
            | 根据埋点文档验证埋点，确保埋点中的事件和维度不多报、不漏报、不错报、不重复报、报的时机正确   |
            | 根据设计稿叠图并截图（2+测试机），确保无视觉问题                                             |
            | 确保分支的代码 CR 通过                                                                       |
            | 确保代码已发布到测试环境，并确认页面能够正常访问                                             |
            | 确保创建了提测单，提测单包含测试用例地址、测试范围、测试入口和二维码、终端环境、埋点文档地址 |
            | 确保需求单状态扭转到增量测试中                                                               |

            | bug修复后                                                                                                                   |
            |-----------------------------------------------------------------------------------------------------------------------------|
            | 涉及到功能、逻辑、埋点、样式和交互变更：重新走本次需求逻辑部分的自测、涉及样式的叠图、CR 和发布测试环境流程，确保全流程无误 |
            | 确保bug单状态扭转到已处理，并通知测试同学验证，保证在 1D 之内扭转到已关闭                                                   |
            | 确保需求单状态扭转到待发布                                                                                                  |

            | 发布前                                                     |
            |------------------------------------------------------------|
            | 确保产品体验、设计走查、测试都通过                         |
            | 确保所有代码（功能+bug 修复）都已经通过 CR，合入 master    |
            | 确保正式环境配置文件中的配置都是正式环境的配置             |
            | 如图片有新增和修改，确保图片已经进行过压缩                 |
            | 确认接口监控的数据正常，业务错误码屏蔽正常，不误报         |
            | 上线前和产品运营确认线上配置是否正确，涉及运营资源是否到位 |
            | 和后台、终端确认好发布顺序，并确保按照约定顺序发布         |
            | 确保在群里进行发布周知，提交的发布审批通过才能进行发布     |

            | 发布后                                                                                                |
            |-------------------------------------------------------------------------------------------------------|
            | 待 CDN 生效后，用非公司 wifi 访问页面，确保页面正常，同时确保所有的资源都是正式的 CDN 地址            |
            | 关注告警群消息，关注告警监控平台流量监控是否有较大波动，JS 报错、接口错误率是否有上涨，关注是否有告警 |
            | 发布出现问题，及时在群里周知并回滚，通知leader，并寻求团队成员协助定位排查                            |
            | 发布外网后需要留守至少 30 分钟                                                                        |
            | 确保需求单状态扭转到已交付和已接受                                                                    |

    - 5.管理变更影响
        - 在需求设计阶段提前对变更进行评估、规划，可以确保在对程序最小负面影响的情况下实施这些变更。
        - 通过详细设计评审技术方案
            - 编写技术文档对部分工程师来说是反感的事情，但好的项目质量一定是设计出来的，而不是测试出来的。
            - 所以在正式编码前，详细思考、设计整体方案并编写成技术文档在组内评审，是规避质量风险非常好用的方法，也是非常好的开发习惯。它可大大减少编码阶段的质量风险。

            - 例子：以之前笔者团队为例，我们还整理了团队详细文档模板，把大家做详细设计需要考虑的点都囊括了进去，避免大家遗漏。如性能设计、监控日志设计、安全风险设计、用例设计、容灾设计等，既是模板也是详细设计的 checkList。

# 软技能

- [腾讯云开发者：如何成为优秀工程师之软技能篇](https://zhuanlan.zhihu.com/p/587383325)

- [阿里开发者：六年团队Leader实战秘诀｜程序员最重要的八种软技能](https://developer.aliyun.com/article/933310?spm=a2c6h.14164896.0.0.40ddd46eXOv9U4)

- [腾讯大讲堂：一篇文章入门专利写作（万字干货）](https://cloud.tencent.com/developer/article/2092422?areaSource=&traceId=)

# 数据中心（IDC）

- 德国的防核弹机房

    - 机房处在一个乡下的地方，上空是德国政府规定禁飞区，房子是一米多厚的混凝土墙，门是钢板的，地下每一层要经过好几道铁门可以进去。

    - 在法国有数据备份

    - 两套电力系统

- [任泽平：中国新基建研究报告2022](https://baijiahao.baidu.com/s?id=1732147608499611955&wfr=spider&for=pc)

    - 根据中国信息通信研究院测算，“十四五”期间我国新基建投资将达到10.6万亿，占全社会基础设施投资10％左右；2021-2023年，数据中心产业投资或达1.4万亿元；2020-2025年，5G网络建设投资累计将达到1.2万亿元，带动产业链上下游以及各行业应用投资超过3.5万亿元。

    - 数据中心的产业链：

        - 上游：服务器、交换机、路由器、光模块、配套软件、电力设备以及运营商等

            - 数据中心投资资金的主要流动方向。从投资占比看，服务器投资额占比最大，为69.28％。其次为交换机，占比为8.31％。第三是光模块，占比为8.31％。

            - 我国目前已经建成约500万架，相对2015年的124万架同比增长303％左右。同时，2015-2020年间，我国数据增量年均增速超过30％，预计2021年后仍以每年超过20％的速度新增。

            - 供配电系统占整体IDC系统及机柜投资的46.82％，占整体投资额的6.05％。

        - 中游：互联网及移动互联网、物联网以及工业物联网、IDC、云服务、IAAS、SAAS、数据安全以及数据交换。

        - 下游：智慧出行、智慧家居、泛娱乐、新零售、智慧医疗、金融、电信、工业以及精准营销等行业。根据

    - 东数西算：

        > 将东部大量需要运算的数据（数）通过光纤信息通道传输至西部，并使用西部的算力枢纽进行计算（算）后将结果返回东部供分析研究使用。

        - 目前数字经济产业多集中于东部地区，导致东部对数据中心的需求旺盛，因此大部分数据中心集中在算力成本高昂的东部。而西部对大数据中心的需求较低，数据中心分布少、上架率低。

            - 2020年中华北、华东以及华南三地机柜数量占全国机柜总数量的79％，上架率约在60-70％之间。但东部土地稀缺，生活成本高昂，能源相对稀缺，导致东部算力成本高居不下。与此同时，东北、西北、西南以及华中四地机柜数量只占总机柜数量的25％，上架率约在30-40％之间。

        - 城市中心的算力中心用作“边缘算力”，对一些对网络要求较高的业务如：工业互联网、金融证券、灾害预警、远程医疗、视频通话、人工智能推理等，进行实时低延迟运算。同时，工信部也对全部数据中心的上架率以及PUE（能源使用效率）进行了严格限制，防止了盲目发展。

            - 京津冀、长三角、粤港澳大湾区、成渝、内蒙古、贵州、甘肃、宁夏在内的8个国家算力枢纽节点，同时规划了10个国家数据中心集群。

        - 东数西算 + 特高压：

            - 数据中心电力消耗大，未来对清洁电力需求增强。特高压进行远距离传输比光纤损耗较大，因此“东数西算”相对于“西电东输”能够在保证成本的前提下更好地执行“双碳”目标。

# api设计

- [阿里技术：深度 | API 设计最佳实践的思考](https://developer.aliyun.com/article/701810?spm=a2c6h.12873639.0.0.33e56605iyuCWs)

- [苏三说技术：瞧瞧别人家的API接口，那叫一个优雅](https://juejin.cn/post/7176220436714225721)

# 架构
## 架构设计

### [腾讯技术工程：谈谈架构设计](https://cloud.tencent.com/developer/article/2255693?areaSource=103001.1&traceId=00iu5zGPktoj8ynGnpC4n)

- 模块与组件：模块是逻辑单元，组件是物理单元。
    - 模块：的粒度可大可小， 可以是系统，几个子系统、某个服务，函数， 类，方法、 功能块等等。
    - 组件：可以包括应用服务、数据库、网络、物理机、还可以包括 MQ、容器、Nginx 等技术组件。

- 框架是组件实现的规范：

    - MVC、MVP、MVVM 等，是提供基础功能的产品
    - 开源框架：Ruby on Rails、Spring、Laravel、Django 等。可以拿来直接使用或者在此基础上二次开发。
        - SpringMVC 是 MVC 的开发框架，除了满足 MVC 的规范,Spring 提供了很多基础功能来帮助我们实现功能，包括注解(@Controller 等)、Spring Security、SpringJPA 等很多基础功能。

- 架构设计目的

    - 如果没有架构设计，说明你的系统不够复杂。

        - 随着业务的增长，系统由单体应用渐进演化为分布式和微服务化。系统整体的复杂性越来越高，技术团队可能从一个团队变成多个专业化团队。

    - 架构的本质是管理和解决系统的复杂性，提高效率。管理复杂性：对系统进行有序化重构，不断减少系统的“熵”，使系统不断进化，改善软件质量为目的的内在结构性变化；提高效率：对系统进行有序化重构，以符合当前业务的发展，并可以快速扩展。

    - 无论是何种变化，架构师通过理解业务，全局把控，权衡业务需求和技术实现，选择合适技术，解决关键问题、指导研发落地实施，促进业务发展，提高效率。

        - 没有最优的架构，只有最合适的架构，一切系统设计原则都要以解决业务问题为最终目标，脱离实际业务的技术情怀架构往往会给系统带入大坑，任何不基于业务做异想天开的架构都是耍流氓。

        - 研发人员为了所谓微服务化而拆分，而不是从当前业务考虑。导致系统无序的状态，开发效率低。

            - 例子：一个简单项目拆分成 8 个子服务，问他为什么这么拆分，说微服务化是为了应对以后扩展方便。结果这个项目从 2017 年到现在都没有再修改过，接手人宁愿新开发一个项目也不愿重构。

            - 系统应用服务跟踪问题：由于微服务化后，系统逻辑复杂，服务出现问题后，你很难快速的定位问题和修复。这是我们踩过不少坑，我们使用 dubbo 服务化，系统一旦出现问题，一推人手忙脚乱。

- 架构误区
    - 1.架构专门由架构师来做，业务开发人员无需关注
    - 2.架构师确定了架构蓝图之后任务就结束了
    - 3.不做出完美的架构设计不开工
        - 我们需要的不是一下子造出一辆汽车，而是从单轮车 --> 自行车 --> 摩托车，最后再到汽车。
    - 4.为虚无的未来埋单而过度设计
        - 在创业公司初期，业务场景和需求边界很难把握，产品需要快速迭代和变现，需求频繁更新，这个时候需要的是快速实现。
        - 不要过多考虑未来的扩展，说不定功能做完，效果不好就无用了。
    - 5.一味追随大公司的解决方案
        - 网站在讨论架构决策时，最有说服力的一句话就成了“淘宝就是这么搞的”或者“腾讯 就是这么搞的”。
    - 6.为了技术而技术
        - 技术是为业务而存在的，除此毫无意义。

- 架构方法论

    - 不同架构方法论，定义的架构分类也不同，RUP4+1 架构方法主要是以架构生命周期为视角进行描述，而 TOGAF9 按架构涉及内容维度来描述。

    - 1.RUP4+1 架构视图

        - 1995 年，Philippe Kruchten 在《IEEE Software》上发表了题为《The 4+1 View Model of Architecture》的论文，引起了业界的极大关注，并最终被 RUP 采纳。

        - 用例驱动：在软件生命周期的各个阶段对软件进行建模,从不同视角对系统进行解读，从而形成统一软件过程架构描述。

        - 不同架构视图承载不同的架构设计决策，支持不同的目标和用途

            - 1.逻辑视图：用于描述系统软件功能拆解后的组件关系,组件约束和边界,反映系统整体组成与系统如何构建的过程。关注功能和逻辑层。
            - 2.开发视图：描述系统的模块划分和组成,以及细化到内部包的组成设计,服务于开发人员,反映系统开发实施过程。
            - 3.物理视图：描述软件如何映射到硬件，反映系统在分布方面的设计，系统的组件是如何部署到一组可计算机器节点上,用于指导软件系统的部署实施过程。
            - 4.处理流程视图：用于描述系统软件组件之间的通信时序,数据的输入输出,反映系统的功能流程与数据流程,通常由时序图和流程图表示。关注进程、线程、对象等运行时概念以及相关的并发、同步、通信等问题。

            - 运用 4+1 视图方法：针对不同需求进行架构设计。
            ![image](./Pictures/soft-architecture/架构设计-RUP4+1.avif)

    - 2.TOGAF9

        - TOGAF9 的架构分类：业务架构、应用架构、数据架构、技术架构, 代码架构, 部署架构。
        ![image](./Pictures/soft-architecture/架构设计-TOGAF9.avif)

            - 业务架构是战略，应用架构是战术，技术架构是装备。
            - 应用架构承上启下，一方面承接业务架构的落地，另一方面影响技术选型。熟悉业务，形成业务架构，根据业务架构，做出相应的应用架构，最后技术架构落地实施。

        - 1.业务架构
        ![image](./Pictures/soft-architecture/架构设计-TOGAF9-业务架构.avif)

            - 包括业务规划，业务模块、业务流程，对整个系统的业务进行拆分，对领域模型进行设计，把现实的业务转化成抽象对象。

            - 业务能力定义企业做什么，业务流程定义企业怎么做。业务架构就是对企业的业务流程，进行根本性的再思考和在思考的彻底性再设计，从而获得成本、质量、速度等方面业绩的巨大的改善或提高。

            - 今天面临的业务量有多大，增长走势是什么样，而且解决高并发的过程，一定是一个循序渐进逐步的过程。合理的架构能够提前预见业务发展 1~2 年为宜。

        - 2.产品架构

            - 将这些不同用途的功能模块围绕特定的业务目标进行分类整合。

                - 注重产品功能的枚举、功能模块之间的分界。

            - 功能模块是用户能够完成一个操作的最小粒度的完整功能

                - 例子：一个展示可购买商品的列表页、一个修改用户密码的功能。

                - 确保用户能通过一个功能模块完整的完成一项工作，而不是半个工作。

            - 功能模块之间有直接关系、间接关系：
                - 只有直接关系的功能模块才会被组织到一起，形成一个子系统。
                - 间接关系的模块，会在不同的层级通过直接关系的模块产生联系。

            - 当具有直接关系的功能模块组合成一个子系统后，解决相同问题域的子系统就形成一个功能层级。功能层级按照接近用户实操的距离程度进行从上到下，或者从左至右的划分，这就形成了产品架构的分层。
        - 3.应用架构（剖面架构，也叫逻辑架构图）：

            - 业务架构的每一部分都有应用架构。
            - 应用架构在产品架构的基础上考虑两个事情：
                - 1.子系统间的关系
                - 2.将可复用的组件或模块进行下沉，沉淀到平台层，为业务组件提供统一的支撑。

            - 应用架构定义系统有哪些应用、以及应用之间如何分工和合作。

                - 应用作为独立可部署的单元，为系统划分了明确的边界，深刻影响系统功能组织、代码开发、部署和运维等各方面

            - 应用分层：
                - 1.水平分（横向）：按照功能处理顺序划分应用，比如把系统分为 web 前端/中间服务/后台任务，这是面向业务深度的划分。
                - 2.垂直分（纵向）：按照不同的业务类型划分应用，比如进销存系统可以划分为三个独立的应用，这是面向业务广度的划分。

            - 应用之间的通信：
                - 通信机制：同步调用/异步消息/共享 DB 访问等
                - 数据格式：文本/XML/JSON/二进制等

            - 应用的分，偏向于业务，反映业务架构，应用的合，偏向于技术，影响技术架构。

        - 4.数据架构
            - 数据架构指导数据库的设计. 不仅仅要考虑开发中涉及到的数据库，实体模型，也要考虑物理架构中数据存储的设计。
            ![image](./Pictures/soft-architecture/架构设计-TOGAF9-数据架构.avif)

        - 5.代码架构（开发架构）

            - 代码架构设计不足，就会造成影响全局的架构设计。比如公司内不同的开发团队使用不同的技术栈或者组件，结果公司整体架构设计就会失控。

            - 最好的样本是参考现有《阿里巴巴 Java 开发手册》。

            - 代码架构定义的内容：
                - 1.代码单元: 1、配置设计 2、框架、类库。
                - 2.代码单元组织：1、编码规范，编码的惯例 2、项目模块划分 3、顶层文件结构设计，比如 mvc 设计 4、依赖关系

                ![image](./Pictures/soft-architecture/架构设计-TOGAF9-代码架构.avif)

        - 6.技术架构

            - 应用架构本身只关心需要哪些应用系统，哪些平台来满足业务目标的需求，而不会关心在整个构建过程中你需要使用哪些技术。

            - 架构设计工作中最为困难的工作：需要具备软件和硬件的功能和性能的过硬知识

            - 技术架构考虑的内容：
                - 确定组成应用系统的实际运行组件（lvs，nginx，tomcat，php-fpm 等）。
                - 这些运行组件之间的关系，以及部署到硬件的策略。
                - 系统的高可用、高性能、扩展、安全、伸缩性、简洁等做

        - 7.部署拓扑架构图（实际物理架构图）
            - 主要是运维工程师主要关注的对象。
            - 部署了几个节点，节点之间的关系，服务器的高可用，网路接口和协议等，决定了应用如何运行，运行的性能，可维护性，可扩展性，是所有架构的基础。
            ![image](./Pictures/soft-architecture/架构设计-TOGAF9-拓扑架构.avif)
            ![image](./Pictures/soft-architecture/架构设计-TOGAF9-拓扑架构1.avif)

- 架构级别
    - 金字塔的架构级别：上层级别包含下层：系统级、应用级、模块级、代码级。
    ![image](./Pictures/soft-architecture/架构设计-架构级别-金字塔.avif)

    | 等级   | 内容                                                   |
    |--------|--------------------------------------------------------|
    | 系统级 | 整个系统内各部分的关系以及如何治理：分层               |
    | 应用级 | 单个应用的整体架构，及其与系统内单个应用的关系等       |
    | 模块级 | 应用内部的模块架构，如代码的模块化、数据和状态的管理等 |
    | 代码级 | 从代码级别保障架构实施                                 |

        - 基于架构金字塔，我们有了系统架构的战略设计与战术设计的完美结合：
        | 顶层设计 | 承上启下                                   |
        |----------|--------------------------------------------|
        | 战略设计 | 业务架构用于指导架构师如何进行系统架构设计 |
        | 战术设计 | 应用架构要根据业务架构来设计               |
        | 战术实施 | 应用架构确定以后，就是技术选型             |

- 应用架构演进：随着业务架构不断进化，同时应用架构依托技术架构最终落地。
![image](./Pictures/soft-architecture/架构设计-应用架构演进.avif)

    - 架构演进过程：单体应用 -> 分布式应用服务化 -> 微服务

    - 1.单体应用：

        - 只应用某个简单场景，应用服务支持数据增删改查和简单的逻辑即可
        - 三级架构：前端（Web/手机端）+ 中间业务逻辑层 + 数据库层

        - 非功能性需求的做法：

            - 1.性能需求：使用缓存改善性能
            - 2.并发需求：使用集群改善并发
            - 3.读写分离：数据库地读写分离
            - 4.使用反向代理和 cdn 加速
            - 5.使用分布式文件和分布式数据库

        - 优点：容易部署、测试

        - 缺点：

            - 复杂性高：模块的边界模糊、 依赖关系不清晰、 代码质量参差不齐、 混乱地堆砌在一起。每次功能的变更或缺陷的修复都会导致需要重新部署整个应用，出错率比较高。

            - 可靠性差：某个应用 Bug，例如死循环、内存溢出等， 可能会导致整个应用的崩溃。

            - 扩展能力受限：无法根据业务模块的需要进行伸缩。
                - 有的模块是计算密集型的，它需要强劲的 CPU；有的模块则是 IO 密集型的，需要更大的内存。由于这些模块部署在一起，不得不在硬件的选择上做出妥协。

            - 阻碍技术创新：单体应用往往使用统一的技术平台或方案解决所有的问题， 团队中的每个成员 都必须使用相同的开发语言和框架，要想引入新框架或新技术平台会非常困难。

            - 技术债务：随着时间推移、需求变更和人员更迭，会逐渐形成应用程序的技术债务， 并且越积 越多。“ 不坏不修”， 这在软件开发中非常常见， 在单体应用中这种思想更甚。

    - 2.分布式（微服务）

        - 对系统按照业务功能模块拆分，将各个模块服务化，变成一个分布式系统。

        - 优点：
            - 降低了耦合度：把模块拆分，使用接口通信,降低模块之间的耦合度。
            - 责任清晰：把项目拆分成若干个子项目，不同的团队负责不同的子项目。
            - 扩展方便：增加功能时只需要再增加一个子项目，调用其他系统的接口就可以。
            - 部署方便：可以灵活的进行分布式部署。
            - 提高代码的复用性：Service 层，如果不采用分布式 rest 服务方式架构就会在手机 Wap 商城，微信商城，PC，Android，iOS 每个端都要写一个 Service 层逻辑，开发量大，难以维护一起升级，这时候就可以采用分布式 rest 服务方式，公用一个 service 层。

            - 易于开发和维护：一个微服务只会关注一个特定的业务功能
                - 单个微服务启动较快：单个微服务代码量较少， 所以启动会比较快。
                - 局部修改容易部署：对某个微服务进行修改，只需要重新部署这个服务即可。
                - 技术栈不受限：部分微服务使用 Java 开发，部分微服务使用 Node.js 开发

        - 缺点：
            - 运维要求较高：在单体架构中，只需要保证一个应用的正常运行。而在微服务中，需要保证几十甚至几百个服务服务的正常运行与协作
            - 系统之间的交互要使用远程通信，接口开发增大工作量
            - 如果修改某一个微服务的 API，可能所有使用了该接口的微服务都需要做调整。
            - 重复劳动：很多服务可能都会使用到相同的功能，而这个功能并没有达到分解为一个微服务的程度，这个时候，可能各个服务都会开发这一功能，从而导致代码重复。
                - 尽管可以使用共享库来解决这个问题（例如可以将这个功能封装成公共组件，需要该功能的微服务引用该组件），但共享库在多语言环境下就不一定行得通了。

### [技术琐话：一家中型互联网公司的架构演进之路]()

- 自如租房公司。此文摘自《云原生落地：企业级DevOps实践》一书

- 技术与业务的关系就像汽车

    - 汽车有三大组件：车轮、发动机、方向盘

    - 对应三种技术：技术支持、技术驱动、技术颠覆。95%的企业是技术支持型企业

- 一般都是先追求业务的快速迭代试错，架构一般会滞后于业务的发展，在架构跟不上业务的迭代速度，或有巨大的历史技术债务出现时，技术架构才会进行新一轮的迭代。同时，没有任何一个架构是“银弹”，凡是能够解决当下企业面临的问题的架构就是好架构。

- 好的架构特征：可用性、可靠性、高性能、易维护、可拓展、安全性

- 架构的分类：

    - 1.业务架构：一般是指业务的关键流程、组织形式、信息流。
        - 电商为例，业务架构包括选品、采购、仓储、物流、供应商、订单等一系列的业务板块。核心是定义业务痛点，厘清功能需求和非功能性需求。

    - 2.功能架构：产品具备的细分功能。
        - 电商系统的功能架构可细分为用户管理、登录注册、商品管理、仓库管理、订单管理、购物车管理、支付管理等核心模块。

    - 3.应用架构：根据业务场景设计出应用的层次结构，制定好应用间的调用、交互方式，确保它们能够融合在一起并满足业务需要。
        - 电商系统的应用架构可能有用户中心、权限中心、登录系统、商品中心、搜索引擎、推荐体系、订单系统、交易系统等。应用架构体现的是用什么样的微服务去支持功能的实现。

    - 4.技术架构：实现应用架构的关键技术栈
        - 如Spring Cloud、ZooKeeper、RocketMQ、Redis、MySQL、Elasticsearch等中间件，以及各种核心流程的时序图、状态图等信息。

    - 5.物理架构：从物理视角来看IDC中的物理拓扑关系，如防火墙、Nginx、网络、应用服务器、数据库间的调用和数据流转关系。
        - 如何通过硬件配置硬件和网络来配合软件系统达到可靠性、高可用性、性能、安全性等方面的要求。

- 企业级架构的演变史：单体架构、分布式架构、微服务架构，中台架构

    - 1.单体架构：

        - 在Web应用发展早期，大部分工程都是将所有的服务和功能模块打包到一个单一的应用中，如以War包的形式运行在Tomcat进程中，直接与数据库和文件系统交互。

        - 一般一台服务器、一个应用、一个数据库，就足够支撑起一个单一的业务功能。比如电商业务，登录、下单、商品、库存都在一个单一的应用中进行管理和维护。

        - 随着业务的不断增长，用户的访问越来越多，单一应用对磁盘、CPU、内存、数据库的访问要求也越来越高。一台服务器一个应用的配置开始捉襟见肘，更改任何一个小的功能模块，整个应用都要重新进行编译和部署。

            - 整体的功能耦合性非常大，一个小功能的变动可能会引起整个应用不可用。多种功能的强耦合迫使单体架构走向分布式架构。

    - 2.分布式架构：即将1台服务器分散扩容为N台，分而治之

        - 如何保证用户的请求均匀分散到这N台服务器？倘若用户的流量仍然集中访问其中的某台服务器，这样的分布式架构在本质上与单体架构没有任何区别。要解决这个问题就必须增加一个新模块—负载均衡

        - 从单一架构的大单一职责，拆分出一些大的应用，逐步形成多种服务之间的分布式调用。还是以电商为例，这里可能会拆分出用户服务、订单服务、商品服务、库存服务四大应用，应用之间通过接口进行交互，调用形式可能是REST或者RPC。

        - 优点：
            - 低耦合：有了功能模块的拆分，使用接口进行通信，降低了对数据库的依赖，模块耦合性降低。
            - 职责清晰：把应用拆成若干个子应用后，一般也是由不同团队进行维护的，这样一来，不同团队与应用的职责也就更加清晰了。
            - 稳定性更高：不会因为某一个应用或功能模块出现问题导致整体服务不可用

        - 缺点：系统间的依赖和链路增多，会增加接口开发的工作量，同时增大服务之间的维护成本

    - 3.微服务架构：在分布式架构的基础上对应用架构进行更细粒度的拆分

        - 随着Spring Cloud的普及，微服务架构逐步成为大中型企业的主流架构。

        - 优点：
            - 耦合性进一步降低：模块更独立，功能拆分更加细化，使代码间的耦合以及数据库、中间件的耦合进一步降低。
            - 自治性更强：一个微服务就是一个独立的实体，它可以独立部署、升级，微服务与微服务之间通过REST等标准接口进行通信，微服务只与其上下游有关，各个微服务之间更加独立。
            - 技术独立：各个微服务之间可以用不同的技术栈，服务端应用可以用Java、Go、Python等多种语言实现，数据库可以是MySQL、MongoDB、HBase等不同的类型。
            - 高可用：随着微服务增多、链路增长，异常也会被分散，一个微服务异常可以通过线程池隔离，利用熔断等技术避免故障扩散和雪崩，大大增加了整个系统的高可用性。

        - 缺点：
            - 复杂度高：采用RPC或REST等方式进行交互，需要考虑网络抖动、消息丢失、幂等、分布式事务等问题，代码的逻辑处理更加复杂。
            - 粒度难定义：微服务拆成几个合适？什么样的功能模块需要独立成一个微服务？服务拆分的粒度是不好准确定义的，倘若拆得过粗，不利于服务间解耦；如果拆得过细，则会导致应用爆炸，增加系统的复杂性。
            - 运维复杂度高：微服务的调用关系最终会形成一个大网，故障的定位和排查依托于更加完善的监控报警系统等配套工具。
            - 性能变慢：微服务一般有一个很长的调用链路，链路过长导致整体接口的性能变慢，响应时间（Response Time，RT）会变长。

    - 4.中台架构：本质是进一步提升应用系统的复用性，当组织规模扩大，更多业务场景纷纷涌现时，各部门之间会形成一个个“系统烟囱”。在“系统烟囱”中，重复冗余的功能不断被造出来。
        - 以阿里巴巴为例，淘宝、天猫两个事业部都需要用户管理、商品管理、订单管理等功能，许多业务功能是重复的，如果两个事业部都重复建设，必然会造成极大的资源浪费。

- 自如的技术演进过程
    - 1.2015年之前，自如以资产应用为主，管理房源信息、合同信息、客户信息，为了快速迭代业务，主语言以PHP为主，代码仓库以SVN来管理。到目前为止，老应用还存在部分未下线的功能，但是历史代码已经达到了1GB。
    - 2.2015年到2018年是架构服务化的阶段，这时自如业务蓬勃发展，长租、短租、优品、家装、服务等多条业务线崛起，各个业务线开始构建独立的专属服务，此时Java开始逐步替代PHP，成为新业务线使用的语言。各个服务间开始通过RPC进行通信。这个阶段自如从单体架构迈向了分布式架构，度过爆发性增长的3年。
    - 3.2018年7月，基础平台成立，自如开始对已有的持续交付流程进行重构，引入大量开源技术栈，如Spring Cloud、Nacos、Pinpoint、Graylog、Apollo等，使各个业务线通用的能力得到下沉，同时建设了第二机房，使自如的架构第一次具备了同城灾备的能力。
    - 4.2019年，自如开始搭建DevOps体系，所有应用运维往SRE（Site Reliability Engineer，站点可靠性工程师）方向转型，开始学习编码，准备为Kubernetes落地储备人才。自如建设了大量的平台功能，如网关、监控报警、配置中心、消息队列平台、权限平台、用户中心等，使技术中台已具雏形。

        - 2019年之前，自如某业务线的系统在30天内出现了13次线上故障，基本达到2天一次的故障频率。 发现当时最迫切的问题是中间件

            - 版本问题：各中心使用的MQ、Elasticsearch、Redis版本都极其老旧。以Elasticsearch为例，当时最新版本已经到了6.x，生产集群使用的还是2.x版本

            - 集群耦合太大：数个中心共用一个MQ、一个Redis实例，经常发生业务部门A的队列拥堵导致业务部门B的业务不可用，一个中间件瘫痪，整个公司的业务停转。经排查发现，这个情形与单体架构相似，原因是历史研发人员为了方便，直接复制中间件配置代码

            - 环境问题：代码分支、环境变量、开关配置经常出现测试环境与生产环境不一致等问题；人工参与过多，很多人为问题导致线上代码污染，进而引发故障。


    - 5.2020年，伴随着容器、Kubernetes的广泛传播，自如对持续交付流程做了颠覆性重构，完全改变了之前的发布部署方式，对环境、分支模型都进行了重新定义，成为整个自如的技术演进过程中一个新的里程碑。

    - 自如前台有多条业务线，如业主、租住、家装、客服等，每条业务线有独自的产研团队进行信息系统的构建，下方有三大中台进行支撑。
        ![image](./Pictures/soft-architecture/自如公司的中台架构.avif)

## 架构师

- [腾讯云开发者：优秀程序员，如何提高架构能力？](https://cloud.tencent.com/developer/article/1722323)

    - 架构发展史：

        - 1.演进就是技术编程框架为核心，展开的一系列规划和解耦部分

        - 2.就进入了高并发、分布式，应对大流量的状态。更加注重的是外围基础设施

        - 3.基于数据的应用架构，也就是越来越多的基于数据的挖掘产生新的应用。

    - 架构是随着整个行业的发展和社会需要去发展的：

        - 1.在 2000 年前后是门户、社交时代，PC 互联网蓬勃爆发的年代，有四大门户。互联网主要是新闻内容传递为主。

            - CDN 蓬勃发展
            - 技术上从编译型语言，逐步过度到动态解释性语言的广泛应用
            - 关系型数据库也开始被广泛应用。开始大量应用缓存，弥补关系型数据库存取能力不足的一些场景需求。

        - 2.移动互联网阶段:需要更强的存储和计算能力。云计算，大规模机器开始出现

        - 3.在 IoT 广泛应用之前不会再有指数级终端设备联网，基础工程能力不再是问题。

            - 在大数据、AI 架构方面发展。比如，如何用图数据库解决复杂关系图谱的问题，GPU 集群、弹性计算、机器学习框架都越来越重要。

    - 架构要根据从用户需求出发

        - 架构师关注业务和功能层面的连接

        - 在不同时期抓住用户当时的核心痛点，演进架构，解决掉用户的这些问题，才能成功。

        - 而不是根据已有的技术能力，YY 出产品功能，然后推给用户，可想而知，这样的产品一定会被用户用脚投票，无论背后的技术架构多么巧妙，业务注定会失败。

    - 系统的可用性：根据当月的不可用时间除以当月的总时间

        - 问题：在低峰期和高峰期挂掉十分钟，对业务的影响可能会相差很大

            - 腾讯在内部计算可用性：从请求的角度出发。被拒绝的请求量，加上超时的请求量，然后除以总的请求量

    - 可用性要考虑亚健康：

        - 我们总是假设系统里面的服务器状态是正常的或故障的。没有考虑亚健康：交换机转发能力下降、CPU 有降频、内存在做 ECC 纠错、，硬盘异常导致 IO 延迟陡增

        - 建设全链路的探测和监控，快速地把这些异常的，处于亚健康状态的节点剔除。

    - 长期方案固然要有，但短期方案也非常重要。不一定需要用最理想和技术方案去解决，但可以借鉴架构的思路。

    - 生产架构本质上也是一种架构：

        - 贝壳业务都是在白天去跑，晚上没有多少人去看房子，这个时候晚上做混沌工程，即使系统短时间出问题影响也没有那么大，还有时间修复。

    - 降级方式取决于这个架构师对于业务的了解：在什么条件下熔断什么样的东西对我们的损失是最小的？这件事情反映了一个架构师是不是对技术有非常深刻的了解

        - 做高可用架构的时候首先技术肯定是要好的。只要技术很好，业务场景不了解的话，会带来非常大的问题

    - 接手一个完全陌生领域的业务系统，比从零开始的项目要难：

        - 错误做法：把整个系统的边际和现在的系统逻辑过程看完，然后把业务梳理完，最后自己把这样的业务和技术重新地、完整地设计出一个新的架构，完全全新，基于他自己思想。

            - 问题：这是一个时间的过程，如果是一步到位的话，很容易会翻船。

                - 最理想的那个好到现实的差：其实它的距离感不仅来自于技术的好坏，还有来自于对业务的理解，以及你对团队的理解，包括来自于你对时间和商业成本的考虑。

                - 那么什么才是最好呢？要随着时间的发展去看，前提条件是第一次要让这个系统能够可用，并且达到商业目标，这是最快要做的，剩下的事情就是心中的理想。

    - 接受一个全新项目时：

        - 错误做法：花至少 1 年时间，比如要花一到两个季度调研某个技术，然后再花半年时间去做相应的落地

        - 正确做法：快速地试错，然后先把这个原型搭出来。看看这个是不是用户要的，高可用、高并发、高性能，哪个方面更重要，就投入相应的资源在上面去做相应的演进。

            - 先把整个代码的关键逻辑和分层结构列出来、画出来，弄清楚有哪些模块，模块之间是怎么通讯的，中间件都有哪些，三方服务有哪些等等。之后再去分析风险点，把风险点、呈现的问题和故障列出来，再去设计合理方案。

            - 架构师首先要了解系统现状、业务现状、团队能力现状，再因地制宜。千万不要拿到一个通用解决方案马上就去实施，要去分析自己的业务情况，是不是真的需要高并发、需要低延迟。

    - 如何提升架构能力：

        - linux发展了那么多年到现在架构的精髓依然被应用在非常多的地方，底层核心的东西是不太会变的，一定要去深入理解。

        - 架构的意义在于我们怎么去理解技术的原理，真正深入计算机原理，计算机是什么，存储是什么，为什么今天这样的东西存在，然后去想像这件事情，不停地在这里探索一系列的东西。

        - 要把这个东西尝试着去开源，放到网上让更多的人使用、验证、给你反馈。这个反馈非常重要，总是闭门造车、没有反馈的话架构能力很难提升。

            - 没有用户的话你就做你系统的用户，可以做很多的机器人测试客户端出来，往你的系统发请求

- [腾讯云开发者：大咖们如何评判优秀架构师？](https://cloud.tencent.com/developer/article/1625249)

    - 优秀的架构师要解决一个实际的问题

        - 这只是优秀的程序员，而不是优秀的架构师：Go 语言本身自带垃圾回收机制，很难干涉具体时间点进行垃圾回收，就容易导致系统实时性不足的问题。为了解决这个问题，团队做了很多方案，最后都没法上线，最终决定把 Go 语言的垃圾回收机制关掉。这样导致的内存泄漏，团队负责人竟然不把它算作泄漏，而是对上级重新 “定义” 为“内存增长”，交易关闭的时候重启就好了。

    - 最好的架构师不是具备了多丰富的知识点，他最需要的特质是折中，他可以在任何场景下都给出优雅的设计方案。

        - 不要去过度设计。比如说当前阶段用微服务 1.0 就可以的话，不用再去强行上微服务 2.0，只要架构能够满足当下的业务需求，同时具备未来一段时间的可扩展性就可以了。

         - 腾讯这样的大公司，架构设计上要关注于高并发

         - 对小型团队来说，架构设计更应满足快速迭代、持续交付的特性。

    - 优秀的架构应该满足的关键就是降本增效：是增加了人力和其他成本，还是让人力、运维等降低了，或者让效率提高了？

    - 要具备一个良好的架构认知的思维模型：

        - 在一个比较低级的思维模型里面，你即使学了再多的知识，在我看来也仅仅是低水平的重复。
        - 需要的是更高维度的认知，更高维度的架构设计能力，能够把某个点打穿打透。

    - 架构师要扛起来四门功课：能多打酱油、能和稀泥、肯背黑锅、敢拉仇恨

    - 要搞明白什么地方是重要：

        - 如果时间充裕，架构过程应该在建模、分层、耦合、调用等环节上做到充分论证讨论。

        - 时间紧任务重，横向比较的点，一定要想明白最重要的事情是什么，最重要的目标是什么，可能会有哪些变化？架构师也是一个决策环节，不一定要去做所有不可能完成的任务。

    - 代码写不好，大概率架构设计也不行，因为架构设计的本质还是结构

        - 如果你代码写得好，那么必然具备能做好拆解的前提条件，不然很难说代码写不好的人架构设计能做好。
        - 另外一点，看源码是很好的一点，一些最火的开源项目的源码，社区讨论的 issue，要多去看多去交流，了解别人是怎么做的。

## 架构安全

- 防拖库：个人和住址也要分开存放，用的时候拿到密钥再去组织，密钥也要动态更新，单独被读取只能是一个无法识别的数据片段。

## 软件开发

- [我在 20 年的软件工程师生涯中学到的事情（英文）](https://www.simplethread.com/20-things-ive-learned-in-my-20-years-as-a-software-engineer/)

    - 1.优秀的软件工程师不仅编写代码，还会考虑谁将使用它、为什么使用它、如何使用它。牢记用户需求才能创造良好的用户体验。

    - 2.水平再高的程序员，也会在自己擅长的领域犯错，如果遇到复杂的问题，就更是如此了。始终牢记，最好的代码是没有代码，或者不需要维护的代码。

    - 3.任何软件工程师的主要工作都是交付价值。软件只是达到目的的手段。

    - 4.警惕那些很长时间没有编写任何代码、却在设计系统的人。

    - 5.Bjarne Stroustrup 有一句名言："只有两种计算机语言：人们抱怨的语言和没人使用的语言"。大型系统也是如此，每个系统最终都很糟糕。

    因此，不要太在意代码的优雅和完美，而要持续改进，创建一个可用的系统，让开发者喜欢在其中工作并可以提供价值。

    - 6.10倍程序员是一个愚蠢的神话。我只见过程序员将代码规模增加了10倍，最终结果是你必须修复10倍的bug。

    真正要做的不是找到神话中的10倍程序员，而是要避免出现0.1倍程序员。那些浪费时间、不寻求反馈、不测试代码、不考虑边缘情况等的程序员，必须保证让这样的人远离我们的团队。

    - 7.人们说他们想要创新，但实际上，他们想要通常的只是某种新颖性和业务成功。如果你的创新改变了人们做事的方式，大多数情况下会得到负面反馈。如果你相信你正在做的事情，并知道它真的会改善事情，那么就准备好迎接一场持久战吧。

    - 8.数据是系统中最重要的部分。数据可能会比你的代码寿命更长，保持数据的有序和清洁，避免脏数据，从长远来看，会得到很好的回报。

    - 9.一直存在的旧技术不是恐龙，而是鲨鱼。它们很好地解决了问题，所以一直活到了现在，没有被快速变化的技术浪潮淘汰。

    不要轻易押注新技术，只有在充分理由的情况下才替换正在发挥作用的旧技术。那些老式的技术工具不花哨，也不令人兴奋，但它们可以完成工作，不会给你带来很多个不眠之夜。

    - 10.很多软件工程师除非被问到，否则不会发表意见。不要因为有人没当面发表意见，而认为他们没什么要补充的。有时，会议上嗓门最高的人是我最不想听的人。

    - 11.如果将人们与他们的工作成果分开，他们就会不太关心他们的工作。软件工程师和所有人一样，需要有主人翁的感觉，从头到尾拥有整个流程，直接负责交付价值。

    让一群充满激情的人完全拥有设计、构建和交付软件的所有权，令人惊奇的事情就会发生。

    - 12.面试最好用于了解某人是谁，以及他们对特定专业领域的兴趣程度，对于试图弄清楚他们是否将成为一个优秀的团队成员，那是徒劳的。

    - 13.始终努力构建一个更小的系统。

        - 有很多原因会推动你，去构建一个比原先设想的更大的系统，人类似乎有一种提供更多功能的欲望。你应该抵制这种欲望，在满足设计目标的前提下，始终努力构建一个更小的系统，这样你最终会得到一个比最初设计更好的系统。

## DevOps

- [阮一峰：运维的未来是平台工程](http://www.ruanyifeng.com/blog/2023/03/platform-engineering.html)

    - 编写软件和运行软件，其实是两种不同的技能：前者需要熟悉代码，后者需要熟悉服务器。互联网软件发展起来以后，这两种技能就逐渐分家了。

        - 互联网公司的核心资产和竞争力，更多的是代码，而不是运维。所以，公司也有意愿，把更多的力量投入在开发上，逐步压缩专门的运维团队，积极外包尽可能多的基础设施。

        - 问题：写代码的人不了解服务器环境，管理服务器的人不了解代码在干什么，这样不利于做出优秀的产品，也不利于排查问题。

    - DevOps：它等于 Dev（开发）+ Ops（运维）。开发与运维重新合在一起：编写软件的人也要负责运行软件。
        - 问题：DevOps 实际上没有办法取代运维

            - 越来越复杂的业务，注定了系统和基础设施也越来越复杂，同时还必须稳定可靠。普通的开发工程师，根本不可能做到这一点。他既不了解所有基础设施，也达不到专业运维的系统管理水平。

        - 传统运维的2个职责：

            - 1.构建基础架构：硬件的采购、安装、上架、联网这些工作

            - 2.管理运行环境：保障业务软件的运行。

            - DevOps 出现后：
                - 构建基础架构：这一职责逐渐消失，变成了采购云服务
                - 管理运行环境：这一职责则是转给了 DevOps 工程师
                - 问题：谁负责采购和整合云服务？

    - 平台工程：负责采购和整合云服务

        - 平台工程师：云服务纷繁复杂，各种 API、SDK 和配套工具令人眼花缭乱，即使经验丰富的运维工程师也不容易说清楚。因此，需要有专职人员来做出正确决策，选择一套满足需要的云服务，并且负责编写工具，整合所有采购来的云服务，供业务开发使用。

        - 1.基础设施是外包的，以求成本和开发周期最小化。

        - 2.平台工程师负责整合外包的基础设施，构建成一个平台。

        - 3.开发工程师在该平台上，自主搭建和管理运行环境，自己运行代码。

## SRE (Site Reliability Engineering，可靠性工程）

- SRE 的出发点是可用性是成功的先决条件。


- SLO：定义每个服务的用户可以接受的最低可靠性水平，然后将其作为你的 SLO
    - 例子：在一个月之中，99.9% 的请求延迟有在 300ms 内

        - 为什么不是100%？因为服务越可靠，其运营成本就越高。

- SLA:基于 SLO 制定的商业合约。承诺其 SLO 应在一段时间内达到特定水准，若未达到一段时间内保证的目标则会产生惩罚机制，比如向客户退款，或免费提供客户更长的服务订阅时间等。

    - 超出 SLO 会伤害到整体业务团队，因此服务应努力保持在 SLO 内。

### SRE roadmap

- SRE 主要工作是保障稳定性，稳定性就是不出故障，围绕着故障周期，整理出 SRE 稳定性保障体系。

### [卡瓦邦噶：SRE 的工作介绍](https://www.kawabangga.com/posts/4481)

- SRE：用软件解决运维问题。标准化，自动化，可扩展，高可用是主要的工作内容。

- SRE 目前对于招聘来说还是比较困难。一方面，这个岗位需要一定的经验，而应届生一般来说不会有运维复杂软件的经历；

- 最根本的，其实这个岗位寻找的要么是具有运维经验的开发人员，要么是具有软件开发技能的运维工程师。所以比较难以找到合适的人

- 蚂蚁金服有两种 SRE
    - 1.负责稳定性的，就是大家所理解的 SRE；
    - 2.资金安全 SRE，并不负责服务正常运行，而是负责金钱数目正确，对账没有错误，工作内容以开发为主，主要是资金核对平台和核对规则（没有做过，只是个人理解）

        - 某种意义上说，已经不算是 SRE 而是专业领域的开发了

- Netflix （2016年）的模式是谁开发，谁维护。
    - SRE 负责提供技术支持，和咨询服务。
    - Netflix 在全球 170 个国家有服务，Core SREs 只有 5 个人

- 微软有专门的 Game Streaming SRE：负责 XBox 在线游戏的稳定性

#### SRE工作分层

- 不同公司的 SRE 的内容各有偏重，取决于公司要提供什么样的服务

    - 学习网络分层的方式，将 SRE 大致的工作内容从下往上分成 3 个大类：

    - 1.Infrastructure：主要负责最基础的硬件设施，网络，类似于 IaaS，做的事情可参考 DigitalOcean

    - 2.Platform：提供中间件技术，开箱即用的一些服务，类似于 PaaS，做的事情可参考 Heroku, GCP, AWS 等

    - 3.业务 SRE：维护服务，应用，维护业务的正常运行

- 对于一个专业的 SRE 来说，技能也不应该有明显的界限
    - 比如说业务 SRE 也需要掌握一些网络技能
    - Infrastructure SRE 也要写一些代码。
    - 很多工具每一个岗位的人都多少用的到，比如 Ansible/Puppet/SaltStack 这种 IT 自动化工具，或者 Grafana/Prometheus 这种监控工具，只有理解才能用的正确。

- 换个角度讲，对于业务 SRE 来说，虽然基本上不会去管理四层以下的网络，但是如果遇到网络问题，能通过已有的工具和权限排查到交换机问题，去找 Infra SRE 帮忙：“请帮我看下 xx IP 到交换机是否有异常，因为 xxx 显示的结果是 xx”，总比 “我怀疑 xx 有网络问题，请帮忙排查下” 要好一些吧？

- Infrastructure SRE

    - Infrastructure 和 Platform SRE 其实可有可无，这些年商业化的服务其实越来越多了

        - 比如，如果公司选择全部在 AWS 部署自己的服务的话，那么就不需要自己建立 Datacenter，维护网络之类的工作了，只需要几个 AWS 专家即可

        - 如果有的话，工作内容也可大可小。可以从管理购买的 VPS 开始，也可以从采购硬件服务器开始

    - Infrastructure SRE 的工作内容可以这样定义：

        - 每一项既可以是一个很大的团队，也可以只有一个人去对商业化的 Infra 服务。可以使用开源的产品，也可以自己研发

        - 1.负责服务器的采购，预算，CMDB 管理。要知道（能查询到）每一台的负责人是谁，在干什么。这个非常重要，如果做不好，会造成极大的资源浪费。
        - 2.提供可靠软件的部署环境，一般是虚拟机，或者 bare mental。
        - 3.操作系统的版本统一维护，Linux 发行版的版本，Kernel 的版本等。
        - 4.维护机器上的基础软件，比如 NTP，监控代理，其他的一些代理。
        - 5.提供机器的登录方式，权限管理，命令审计。
        - 6.维护一套可观测性的基础设施，比如监控系统，log 系统，trace 系统。
        - 7.维护网络，大公司可能都会自己设计机房内的网络。其中包括：
            - 网络的连通，这个是必要的。对于上层用户（Platform SRE）来说，交付的服务应该是任意两个 IP 是可以 ping 通的，即管理好 3 层以下的网络。
            - NAT 服务
            - DNS 服务
            - 防火墙
            - 4 层负载均衡，7层负载均衡
            - CDN
            - 证书管理

- Platform SRE

    - Infrastructure SRE 维护的是基础设施，Platform SRE 使用他们提供的基础设施建立软件服务，让公司内的开发者可以使用开箱即用的软件服务，比如 Queue，Cache，定时任务，RPC 服务等等

    - RPC 服务：让不同的服务可以互相发现并调用
    - 私有云服务
    - 队列服务，比如 Kafka 或者 RabbitMQ
    - 分布式的 cronjob 服务
    - Cache
    - 网关服务：反向代理的配置
    - 对象存储：s3
    - 其他一些数据库：ES，mongo 等等。一般来说，关系型数据库会有 DBA 来运维，但是 NoSQL 或者图数据库一般由 SRE 维护。
    - 内部的开发环境：
        - SCM 系统，比如自建的 Gitlab
        - CI/CD 系统
        - 镜像系统，比如 Harbor
    - 其他的一些开发工具，比如分布式编译，Sentry 错误管理等等
    - 一些离线计算环境，大数据的服务

- 业务 SRE

    - 有了 Platform SRE 的支持，开发人员写代码就基本上不需要关心部署的问题了。可以专注于开发，使用公司开箱即用的服务。

    - 这一层的 SRE 更加贴近于业务，知道业务是怎么运行的，请求是怎么处理的，依赖了哪些组件。

    - 如果 X 除了问题，可以有哪些降级策略。参与应用的架构设计，提供技术支持。

    - 主要的工作内容有：
        - 参与系统的设计。比如熔断、降级，扩容等策略。
        - 做压测，了解系统的容量。
        - 做容量规划。
        - 业务侧的 Oncall。

#### 部署服务

- 部署分成两种：

    - Day 1：将服务部署上线的那一天

        - Day 1 操作是很难的。换句话说，我们在服务部署之后一直改来改去，还要保证这个服务在一个全新的环境能够可靠的部署起来。部署环境的硬编码，奇奇怪怪的 work around，都会破坏

        - Day 1 的可靠性。之前一家公司，扩容一个新机房的过程简直是噩梦，太多的奇怪配置，hardcode，导致踩过无数个坑才能在一个新的机房部署起来全部的服务。

    - Day 2+：服务部署之后，还会进行很多更新，升级，配置更改，服务迁移等等

        - Day2+ 的工作要做很多次，Day 1 做的很少，在不断的迭代升级之后，还能保证有一个可靠的

        - Day2+ 的操作也不简单，主要要关注稳定性。对于重要的变更操作要设计好变更计划，如何做到灰度测试，如果出了问题应该如何回滚，如何保证回滚可以成功（如何测试回滚）等等。

- 部署的操作最好都是可以追踪的，因为并不是所有会引起问题的操作都会立即引起问题。

    - 比如一个操作当时做完没有什么问题，但是过了 1 个月，偶然的重启或者内存达到了某一个指标触发了问题。

    - 如果能记录操作的话，我们可以回溯之前做过的变更，方便定位问题。现在一般都用 git 来追踪部署过程的变更（gitops）。

#### Oncall（保证线上服务的正常运行）

- 典型的工作流程是：收到告警，检查告警发出的原因，确认线上服务是否有问题，定位到问题，解决问题。

- 收到告警：并不总意味着真正的问题，也有可能告警设置的不合理。告警和监控面板并不是一个静态的配置，它应该是每天都在变化的，时刻在调整的。如果发现没有标志真正线上问题的告警发了出来，就应该修改告警规则。

    - 如果发现当前的监控无法快速定位问题，应该调整监控面板，添加或者删除监控指标。业务在发展，请求量在变化，某些阈值也需要不断地调整。

- 定位问题没有一概而论的方法了，需要根据看到的实时，结合自己的经验，然后做推测，然后使用工具验证自己的推测，然后确定问题的根因。

- SOP（标准操作流程）解决问题的方法论。即：如果出现了这种现象，那么执行那种操作，就可以恢复业务。SOP 文档应该提前制定，并且验证其有效性。

- 需要注意的是上述定位问题、解决问题并没有顺序关系。一个经常犯的错误是，在出现故障的时候，花了很长时间定位到故障的根因，然后再修复。这样花的时间一般会比较长。

    - 正确的做法是先根据现象看现有的 SOP 能否恢复业务。比如说当前错误只发生在某一个节点上，那么就直接下线这个节点，具体的原因后面再排查。恢复当前的故障永远是第一要务。

- 但是恢复操作也要经过测试，比如猜测可以通过重启解决问题的话，可以先重启一台做测试，而不是一次性将所有服务重启。大部分情况是需要临场分析的，是一个紧张又刺激的过程。

    - 故障到底多久恢复算好？出现多少故障是可以容忍的？怎么标志服务的稳定性到底如何？我们使用 SLI/SLO 来衡量这些问题

#### 制定和交付 SLI/SLO

- 维护服务等级协议，听起来像是一个非常简单的事情，只要“设定一个可用率”然后去实现它就好了。然而现实的情况并不是

    - 比如，制定可用率的时候，并不是说我们去“实现4个9”（99.99% 的时间可用）就够了，我们有以下问题要考虑：

- 如何定义这个可用率？比如我们以可用率 > 99.9% 为目标，有一个服务部署了 5 个 Zone, 那么有一个 Zone 挂了，其余的 Zone 是可用的，那么可用率被破坏了吗？这个可用率是每一个 Zone 的还是所有的 Zone 一起计算的？

    - 可用率计算的最小单位是什么？如果 1min 内有 50s 没有达到可用率，那么这一分钟算是 down 还是 up？
    - 可用率的周期是怎么计算的？按照一个月还是一个周？一个周是最近的 7 天还是计算一个自然周？

    - 如何对 SLI 和 SLO 做监控？

    - 如果错误预算即将用完，有什么措施？比如减少发布？如果 SLI 和 SLO 没有达到会怎么样？

- 等等，如果这些问题不考虑清楚的话，那么 SLI 和 SLO 很可能就是没有意义的。SLI/SLO 也适用于对公司内部用户的承诺，让用户对我们的服务有预期，而不能有盲目的信任

    - 比如 Google 在 SLI/SLO 还有预算的时候，会在满足 SLI/SLO 的时候自行对服务做一些破坏，让用户不要对服务有 100% 可用的错误预期。

- SLI/SLO 也会让 SRE 自己对当前服务的稳定性有更好的认识，可以根据此调整运维、变更、发布计划。

#### 故障复盘

故障复盘的唯一目的是减少故障的发生。有几个我目前认为不错的做法。

故障复盘需要有文档记录，包括故障发生的过程，时间线的记录，操作的记录，故障恢复的方法，故障根因的分析，为什么故障会发生的分析。

文档应该隐去所有当事人的姓名对公司的所有人公开。很多公司对故障文档设置查看权限，我觉得没什么道理。有些公司的故障复盘甚至对外也是公开的。

故障在复盘的时候应该将当事人的名字用代码替代，可以营造更好的讨论氛围。

不应该要求所有的故障复盘都产生 Action。之前一家的公司的故障复盘上，因为必须给领导一个“交待”，所以每次都会产生一些措施来预防相同的故障再次发生，比如增加审批流程之类的。

这很扯，让级别很高的领导审批他自己也看不懂的操作，只能让领导更痛苦，也让操作流程变得又臭又长，最后所有人都会忘记这里为什么会有一个审批，但是又没有人敢删掉。你删掉，出了事情你负责。

Blame Free 文化？之前我认为是好的。但是后来发现，有些不按照流程操作导致的问题确实多少应该 Blame 一下，比如下线服务的时候没有检查还没有 tcp 连接就直接下线了，或者操作的时候没有做 canary 就全部操作了，这种不理智的行为导致的故障。但是条条框框又不应该太多，不然活都没法干了。

#### 容量规划

容量规划是一个非常复杂的问题，甚至有一些悖论。容量要提前做好规划，但是容量的规划需要知道业务的扩张速度，扩张速度这种事情又不是提前能计划好的。所以我一直觉得这个事情很难做，也一直没有见过做的很好的例子。

但是至少可以对维护的系统建立一个模型，知道多少机器，多少资源，能容纳多少容量。这样遇到大促之类的活动也能及时估算需要的资源数量

#### 用户支持

- 用户支持也是日常的一部分。包括技术咨询，以及用户要求的线上问题排查。

- 这里就需要提到文档的重要性了。如果没有维护好文档，那么用户就会一遍又一遍问相同的问题。写文档也是一个技术活，优秀的需要很长时间的积累。

- 文档也需要经常更新。我一般会这样，保持这样一种状态：用户可以不需要任何人就从文档中找到他需要的所有答案。

- 如果我发现用户的问题无法从文档中找到，或者难以找到在文档中的什么地方，就会更新文档，或者重新组织文档。如果用户的问题已经从文档中找到，那么就直接发文档给他。

- 如果用户的问题显然是文档看都没有看过（有很多人根本不看文档的，只看文档是谁写的然后径直去问这个人），就直接忽略。

- 优秀的文档应该尽量引入少的专有名词，少使用没有用处的专业词汇描述，只描述具有指导意义的事实，假定用户没有相关的背景知识，列举使用例子，举一些现实会用到的例子而不是强行举例子，明确 Bad Case。等等。这其实是一个很大的话题了，这里就不展开了。

#### 有关做项目没有专业团队得不到训练

- 这方面是听到最多的抱怨。虽然说 SRE 在工作上应该是开发时间和运维时间各 50%
    - 但是真实的情况是，即使 SRE 有一些开发工作，也大部分是面向内部用户，面向公司内部的开发者的。
    - 大部分项目是一些想法，需要去尝试一下行不行，基本上不会有专业的设计资源，PM 资源。
        - 这种项目就需要 SRE 有多方面的技能，包括对产品的理解，清楚地知道它有什么痛点，最好是自己经历过的痛点，然后需要懂设计，管理好开发进度。然而这种人非常少。其实能写中型项目代码的 SRE 就已经非常少了。所以大部分公司内部项目都会做的又难用又复杂。

- 即使是有专业配套 PM （项目经理）和设计，甚至前端资源。基本上也是一个灾难。
    - 我也经历过这样的团队：这种内部项目对标的不是互联网项目，而更像是 toB 的项目。用户 UI 的设计，交互逻辑，操作流程，交付周期等需要的都是另一个领域的知识。
    - 否则的话人越多，也只会徒增沟通成本，拖慢项目进度。

- 回到经常听到的这个抱怨，说在 SRE 的团队没有像开发团队那样有“正规军”，有设计和 PM，大家各司其职，后端开发只要对齐 API 然后实现就好了。大部分的应届生会有这样的幻想，但实际上不是这样。

    - 被搞错的最重要的一点是，学习主要是靠自己的，和别人没有太大的关系。我觉得可能是在一个大团队里面，有很多人一起做一件事情，心里的怀疑和焦虑会少一点，人们会对这样的工作状态感到踏实，误以为是“成长”，自己做所有的工作焦虑更多。

- 事实是，在大团队工作可能学到更多的沟通技能，比如和不同的人对齐不同的阶段工作目标，要想要学到其他的东西还是要靠自己。

    - 比如拿到一个设计，如果照样子去实现了，其实不会学到什么东西。而要去理解为什么这么设计，为什么不那么设计。如果自己去做，思考的过程也基本是这样的，可以怎么设计，选择什么好。都是：思考，选择，尝试，经验，思考……

    - 另一个需要澄清的误区是，模仿并不是学习。在团队中经历了一个设计，如果记住了这个设计，下次碰到类似的问题也用这个设计去解决。这也不能叫做是学习。

- 我见过有在业务部门做过支付的 SRE 写的代码，在内部系统中去实现了订单业务的订单、交易等概念完成一个运维流程，甚至 Model 的名字都没改过。拿着锤子找钉子，会让系统变得更加糟糕和复杂。

    - 总之，工作分的细并不代表工作就会更加专业。一个人身兼数职也可以在每一个方面做得很专业。重要的是不断学习，使用正确的做事方式，向优秀的项目和优秀的开发者学习。

#### 有关背锅

互相甩锅的工作环境无疑是非常糟糕的工作环境。如果相同的团队、或者不同的团队之间需要相互勾心斗角的话，如果工作环境不允许大方承认（SRE 无可避免地会犯一些错误）自己的错误，说明公司营造的氛围有问题。

比如某些公司规定，发生 P1 级别的错误就必须开除一个 Px 级别的员工，发生 P0 级别的错误就必须开除一个 Py 级别的员工一样。如果是这种情况的话，公司实际上是在用一种懒惰地方法通过提高人的压力来提高系统的稳定性。有没有效果不知道，但是确定的是不会有人在这种情况下工作的开心。建议换一份工作。

#### 面试会问什么？

我觉得和后端开发的面试内容基本上差不多。

如果是去应聘的这个岗位所需要的一些技能，比如 K8S，监控系统等，可能也会问一些领域内的知识。

虽说这部分工具性的东西都可以学习，但是如果人家要一个经验丰富的、或者入职就能干活的，那么面试成功的机会就会小很多。

当然，也不必沮丧，这是市场的供需关系决定的，如果对方执意要找符合特定要求的候选人，那么对方的选择的范围也会小很多，不必因为错失了这种机会而后悔没去学习什么工具。话又说回来，技能越多，选择也会越多。

排查错误可能是转行做 SRE 最大的一个门槛，这个需要一些经验。如果没有经验的话，就补足一些操作系统的知识，这样遇到未知的问题也可以通过已知的知识和工具去排查。

做 SRE 需要会写代码吗？会，而且写代码的要求并不会比一个专业的后端开发低。

- 如何转行？

    - 其实难度没有想象的高，毕竟大学里面没有一个叫做 SRE 的专业。SRE 要求的知识也是编写代码、设计系统、了解操作系统和网络等。所以在大学里面将本科的课程好好学好，尝试做（并维护）一些自己的项目，毕业的时候基本上就满足要求了。非科班的人要转行的话，也可以参考大学的课程内容去补足这方面的知识。

    - 需要注意的是，培训班出来的做开发完成业务可能够，但是做 SRE 远远不够。SRE 不仅需要 make things work，还要知道背后的原理。

#### 选择大公司还是小公司？

这属于两种截然不同的工作环境。小公司一般都有一个救火英雄式的人物，在公司的时间比较长，知道所有组件的部署结构，什么都懂。跟着这种人学习会成长很快。

大公司细分领域很多。本文前面列出的内容可能每一项在大公司中都是一个团队，对某个领域可以深入研究。

所以还是看想要做什么了。我个人比较喜欢靠谱的小公司，或者大公司中靠谱的小团队。

##### 如何判断一家公司是否靠谱？

- 对于 SRE 这个职位，我总结了一些判断的技巧。比如可以判断一下对方目前的业务和 SRE 员工的数量是否处于一个“正常”的状态，人数是否在随着业务（机器的数量）现象增长？这是一个不好的迹象。是否 SRE 的数量过多？

- 如果 SRE 人太多，有两个可能的原因：

    - 1.某个领导为了扩大自己的影响力在为一些“不必要的”岗位招人，这样会导致人多事少，大家开始做一些奇奇怪怪的事情，发明奇奇怪怪的需求，以各种各样的方式浪费自己的时间来领公司的工资；

    - 2.这个公司的基础太差，大部分工作都是需要人力运维，导致基本上有多少机器就需要多少人。总之，都不是什么好事情。

- 一些技术比较好的公司，都没有庞大的 SRE 队伍，比如 Instagram, Netflix（现在可能人数不少了），以及一些创业公司，甚至都可以没有专门的 SRE，优秀的 SRE 首先要是开发者，优秀的开发者也离 SRE 不远了。

    - 一些耳熟能详的服务，比如 webarchive 这样的数据量，其实背后也只有几个人在维护。前几年面试了国内的一家公司，在机房遍布全球，业务已经发展的比较庞大（上市了）的时候，SRE 团队也只有 10 个人。

- 另外我比较喜欢问的一个问题是对方关于 AIOps 怎么看。因为我之前搞了两年这个东西，最后得到的结论是，这基本上是个浪费时间、欺骗上层领导的东西。AI 这东西的不可解释性本质上就和运维操作将就因果相违背的。

    - 所以经常喜欢问面试官怎么看这个技术，基本上就可以判断靠不靠谱。当然了，这是我个人的职业阴影导致的后遗症，只能代表个人意见。

- 就说这么多吧，都是一些个人理解，不一定对。写这篇文章感觉自己好像指点江山一样，其实我自己也干了才几年而已，所以本文内容仅供参考。如果有什么问题可以在评论提出，我能回答的话就尽量回答。

### 争议

- 反方
    - [瑞典马工：SRE 已死，有事烧纸](https://mp.weixin.qq.com/s/unNnXc-qS-5FD3Ig5fSdZg)

- 正方
    - [SRE运维进阶之路：SRE 迈向高精尖，不可或缺](https://mp.weixin.qq.com/s/CSsFD1FPzFC0JtlQWE35JQ)

## DDD(领域驱动设计)

- [腾讯技术工程：万字长文助你上手软件领域驱动设计 DDD](https://cloud.tencent.com/developer/article/1966457)

    - 数据驱动设计（DDD以前的思维模式）：从技术的维度解决业务问题

        - 针对业务需求进行数据建模：根据业务需求提炼出类，然后通过 ORM 把类映射为表结构，并根据读写性能要求使用范式优化表与表之间的关联关系。

            - 得出的数据模型是对业务需求的直接翻译，并没有蕴含稳定的领域知识/规则。

        - 一旦需求发生变化，数据模型就得发生变化，对应的库表的设计也需要进行调整。
            - 从需求穿透到了数据层，中间并没有稳定的，不易变的层级进行阻隔，最终导致系统响应变化的能力很差。

    - 协同设计：

        - 数据驱动设计例子：由产品同学提出业务需求，研发同学进行技术方案设计，并编程实现。

            > 缺点：无法形成能够消除认知差异的模型。

            - 一：需求可能是易变的、定制化的，而研发同学在缺少行业经验的情况下，往往会选择直译，即根据需求直接转换为数据模型。

            - 二：而研发同学设计的技术方案，涉及很多的技术细节，产品同学无法从中判断是否与自己提出的业务诉求和产品规划相一致，最终形成认知差异。

            - 三：且认知差异会随着迭代不断被放大，最后系统变成一个大泥球。

            ![image](./Pictures/soft-architecture/DDD-协同设计1.avif)

        - 领域驱动（DDD）例子：

            - 领域专家：具有丰富行业经验和领域知识储备的人，他们能够在易变的、定制化的需求中提炼出清晰的边界，稳定的、可复用的领域概念和业务规则，并携手产品和研发共同构建出领域模型。

            - 领域模型是对业务需求的知识表达形式，它不涉及具体的技术细节（但能够指导研发同学进行编程实现），因此消除了产品和研发在需求认知上的鸿沟。

                - 模型的变更意味着需求变更和代码变更，协作围绕模型为中心。

            ![image](./Pictures/soft-architecture/DDD-协同设计2.avif)

    - 领域驱动（DDD）

        - 面对业务需求，先提炼出领域概念，并构建领域模型来表达业务问题，而构建过程中我们应该尽可能避免牵扯技术方案或技术细节。

            - 而编码实现更像是对领域模型的代码翻译，代码（变量名、方法名、类名等）中要求能够表达领域概念，让人见码明义。

        - 系统的复杂性往往并不在技术上，而是来自领域本身、用户的活动或业务服务。当这种领域复杂性在设计中没有得到解决时，基础技术的构思再好也是无济于事。

            - 系统的复杂度体现在三个方面：

                - 1.规模：功能点与功能点之间的的关系
                    - 通过子领域，限界上下文，聚合等模式对问题进行拆分和归类，不断收窄问题域，保证聚合边界内所解决的问题集合足够收敛和可控。

                - 2.结构：是否分层？若分层，每层划分的职责边界是否清晰
                    - 整体架构的基本管理单元是聚合，它是一个完整的、自治的管理单元，当需要进行服务拆分时，可以直接以聚合作为基本单元进行拆分。

                - 3.变化：分离不易变逻辑和易变逻辑，"以不变应万变"
                    - 领域层：不变
                    - 领域层以外的应用层和基础设施层：易变。通过调整该层，实现快速响应需求的变化

        - 微服务架构的兴起，大伙惊奇地发现 DDD 是作为划分“微服务边界”的一把利器，并且 DDD 提及的很多设计理念与微服务架构十分契合，因此 DDD 逐渐被开发者们接受并流行起来。毫不夸张地说，了解和学习 DDD 可以算得上是如今软件行业从业者的一门必修课了。

        - 问题空间和解空间

            - 问题空间：表示的是真实世界，是具体的问题、用户的诉求

                - 例子：学生管理系统（SMS）
                    > 学校需要构建一个学生管理系统（Student Management System, SMS）。
                    > 
                    > 通过这个管理系统，学生可以进行选课，查询成绩，查询绩点。
                    > 
                    > 而老师则可以通过这个系统录入授课课程的成绩。录入的分数会由系统自动换算为绩点，规则如下：若分数>= 90，绩点为4.0；90>= 分数> 80，绩点为3.0；80 >= 分数 > 70，绩点为2.0；70 >= 分数 >= 60，绩点为1.0；成绩< 60，则没有绩点，并邮件通知教务员，由教务员联系学生商榷重修事宜。
                    > 
                    > 成绩录入后的一周内，若出现录入成绩错误的情况，老师可提交修改申请，由教务员审核后即可完成修改。审核完成后系统会通过邮件告知老师审核结果。一周后成绩将锁定，不予修改。成绩锁定后，次日系统会自动计算各年级、各班的学生的总绩点（总绩点由各门课程的学分与其绩点进行加权平均后所得）。
                    > 
                    > 而教务员则可以通过该系统发布可以选修的课程。同时，教务员能够查看到各年级，各班的学生的总绩点排名。

                - 统一语言（ubiquitous language）：全局分析阶段对问题空间进行的梳理和分析，形成统一语言，获取问题空间的价值需求以及业务需求。

                    - 例子：商品的价格（Price）和商品的金额（Amount），它们本质是同一个东西，但是却有不同的术语表示。
                    - 统一语言可以通过词汇表的形式展示，其中词汇表最好还要包含术语对应的英文描述
                    ![image](./Pictures/soft-architecture/DDD-统一语言.avif)

                    - 精炼循环：我们在提炼领域概念的时候会觉得统一语言定义不合理/有歧义，此时我们就会调整统一语言的定义，并重新进行提炼领域概念。领域专家来主导概念提炼、边界划分等宏观设计，原因就在于领域专家的经验和行业洞见来源于过去已经迭代的无数个精炼循环，因此由这些宏观设计推导出来的领域模型，往往都是非常稳定的。

                    - 价值需求分析：

                        - 确定系统范围：确定系统问题空间的边界，明确系统什么该做，什么不该做。结合目标系统当前状态和未来状态进行判断。

                        - 在进行价值需求分析后，我们便能判断是否需要通过 DDD 驱动系统的设计。
                            - 并非任何系统都 DDD，DDD 的核心是解决领域复杂性，若系统逻辑简单，功能不多，引入 DDD 则会得不偿失。在进行价值需求分析后，我们便能判断是否需要通过 DDD 驱动系统的设计。

                    - 业务需求分析：

                        - 业务场景：按阶段性的目标划分业务流程

                            - SMS例子：老师修改成绩就分为了老师“提交申请单”，以及教务员“同意申请单”两个场景。

            - 解空间：则是针对问题空间求解后构建的理念世界，其中包括了解决方案、模型等。

            - 战略设计覆盖了问题空间和解空间，而战术设计则聚焦在解空间上。

        - 限界上下文：

            - 例子电商购物场景：
                - 在进行商品下单后，系统会生成一个订单
                - 在用户付款完成后，系统也会生成一个订单
                - 到了物流派送流程，系统还会生成一个订单。

                - 虽然这三个步骤中的领域概念都叫订单，但是他们的关注点/职责却不同：商品订单关注的是商品详情，支付订单关注的是支付金额和分润情况，物流订单关注的是收货地址。也就是说，商品、支付和物流分别为三个限界上下文，而订单作为统一语言需要在特定的限界上下文内，我们才能够明确其关注点/负责的职责。

            - 业务模块（横向切分）和限界上下文（纵向切分）
            ![image](./Pictures/soft-architecture/DDD-限界上下文.avif)

            - 识别限界上下文的原则：

                - 正交性：如果两个或更多事物中的一个发生变化，不会影响其他事物，这些事物就是正交的。要破坏变化的传递性，就要保证每个限界上下文对外提供的业务服务不能出现雷同。

                - 奥卡姆剃刀原理：“如无必要，勿增实体”。这是避免过度设计的良方

            - 防腐层和开放主机服务都是访问领域模型时建立的一层包装，前者针对发起调用的下游（通过基础设施层体现），后者针对响应请求的上游（通过应用层+远程服务），以避免上下游之间的通信集成将各自的领域模型引入进来，造成彼此之间的强耦合。

                - 防腐层：位于下游，通过它隔离上游上下文发生的变化。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-防腐层.avif)

                - 开放主机服务：让限界上下文可以被当做一组服务访问。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-开放主机服务.avif)

                    - 对于进程内的开放主机服务，称为本地服务（对应 DDD 中的应用服务）。

                    - 对于进程间的开放主机服务，成为远程服务。根据选择的分布式通信技术的不同，又可以定义出类型不同的远程服务：
                        - 面向服务行为，比如基于 RPC，称为提供者（Provider）
                        - 面向服务资源，比如基于 REST，称为资源（Resource）
                        - 面向事件，比如基于消息中间件，称为订阅者（Subscriber）
                        - 面向视图模型，比如基于 MVC，称为控制器（Controller）

                - 发布语言：用于两个限界上下文之间的模型转换。防腐层和开放主机服务操作的对象都不应该是各自的领域模型，这正是引入发布语言的原因。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-发布语言.avif)

                    - 例子：其实云 API 根据我们定义的接口生成对应的 Request 对象和 Response 对象，并集成在云 API 的 SDK 中，这些对象就是发布语言

                - 共享内核：将限界上下文中的领域模型直接暴露给其他限界上下文使用。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-共享内核.avif)

                    - 这会削弱了限界上下文边界的控制力。
                        - 上面我们讲述的防腐层、开放主机服务以及发布语言无不传达一种思想，限界上下文不能直接暴露自己的领域模型或直接访问其他限界上下文的领域模型，一定要有隔离层！

            - 协作不同的限界上下文
                - 这些团队之间具有要么一起成功，要么一起失败的强耦合关系。
                - 要求参与的团队一起做计划、一起提交代码、一起开发和部署，采用持续集成的方式保证两个限界上下文的集成度与一致性，避免因为其中一个团队的修改影响集成点的失败。

                - 客户方/供应方协作模式：

                    > 当一个限界上下文单向地为另一个限界上下文提供服务时，它们对应的团队就形成了客户方/供应方模式。
                    - 客户方作为下游团队，供应方作为上游团队：

                        - 下游团队对上游团队提出的服务
                        - 上游团队提供的服务采用什么样的协议与调用方式
                        - 下游团队针对上游服务的测试策略
                        - 上游团队给下游团队承诺的交付日期
                        - 当上游服务的协议或调用方式发生变更时，如何控制变更

                - 遵奉者协作模式：

                    > 当上游的限界上下文处于强势地位，且上游团队响应不积极时，我们可以采用遵奉者模式。即下游严格遵从上游团队的模型，以消除复杂的转换逻辑。

                    - 可以直接复用上游上下文的模型（好的）
                    - 减少了两个限界上下文之间模型的转换成本（好的）
                    - 使得下游限界上下文对上游产生了模型上的强依赖（坏的）

            - 例子：学生管理系统（SMS）

                | 限界上下文可划分为 |
                |--------------------|
                | 成绩上下文         |
                | 课程上下文         |
                | 审批上下文         |
                | 权限上下文         |
                | 邮件上下文         |

                ![image](./Pictures/soft-architecture/DDD-限界上下文-学生管理系统（SMS）.avif)

            - 微服务：
                - 在日常实践中，都是将限界上下文和微服务的关系进行一一对应的，但这不是绝对的
                - 当我们采用的是 CQRS 架构，领域模型会被分为命令模型和查询模型，虽然它们同属一个限界上下文，但是它们往往是物理隔离的。
                ![image](./Pictures/soft-architecture/DDD-限界上下文-微服务.avif)

        - 大泥球：要避免制造大泥球
            - 越来越多的聚合因为不合理的关联和依赖导致交叉污染
            - 对大泥球的维护牵一发而动全身
                - 没有正交性
            - 强调“个人英雄主义”，只有个别“超人”能够理清逻辑

- [阿里开发者：万字详解｜从软件复杂度的角度去理解DDD]()

## 中台

### 游戏公司Supercell（超级细胞）

- 倒金字塔结构

    > 传统的金字塔型的组织架构是工业革命时代的产物，在流水线一样的工厂里，工作都是标准的，工人们只需日复一日地重复同样的事情，不允许犯任何错误。可是，这种做法，在游戏业甚至是所有创意行业却是行不通的。

    - 全体团队成员都需要具备很强的主动性。那些对他人依赖性强的人不太适合这种工作环境。它使人们意见更好地融合，每个人都像参与到我们正在做的事情中，形成了一种良好、健康的工作环境。

    - CEO埃卡·潘纳宁：自认为是“行业内最没权力的CEO”。他在每个项目中只有两个权力：

        - 1.审批一个团队的组建
        - 2.审批一个游戏是否可以从Beta测试进入全球上线的阶段

    - 决策权掌握在开发团队手中：那些真正参与研发的开发者们就有更多的自由，也能萌发更多的创意，他们做的决定越多，往往也更好更高效，因为决策者是真正接触用户的人。

        - 《部落冲突》的游戏主管伊诺·乔司：“我不是决定事物的人，我会提出我认为存在的问题的地方、可以改进的地方，但我不是做决定的人。团队做决定。我作为协调者，组织团队一起讨论并达成统一意见。我曾经提出过一些想法，被团队完全否决了。”

    - 要做到真正放权，就要容忍失败：失败并不是一件可耻的事情，如果一款游戏证明不具备竞争力，他们就会果敢地砍掉，甚至还会开香槟庆祝。

        - Supercell推出了5款商业化游戏，创作出《卡通农场》、《部落冲突》、《海岛奇兵》和《皇室战争》等大作。而在这些光鲜亮丽的背后，鲜为人知的是，他们砍掉了超过20款游戏。

    - 缺点：

        - 沟通很困难：我们把注意力集中在自己的事情上，没有有效地分享信息。

- 小团队+中台：开发过程中公共和通用的游戏素材和算法整合起来，并积累了非常科学的研发工具和框架体系，构建了一个功能非常强大的中台。这样强大的中台可以支持若干个小团队在短时间内开发出一款新的游戏。

    - 团队小而精：CEO说：“游戏行业竞争太激烈，未来难以预测。你只能尽可能组建最优秀的团队，允许这些团队在最好的工作环境下工作，从而实现成功几率的最大化。归根结底，这几乎是你所能够掌控的唯一一件事情。”

    - 阿里例子：

        - 每个电商业务都会涉及到商品信息，订单，支付，仓储，物流等等这样的通用系统，但各个板块之间数据不能共享，势必造成更大的浪费。

        - 阿里的6大中台（兵种）：

            | 中台     |                                                                                                                         |
            |----------|-------------------------------------------------------------------------------------------------------------------------|
            | 业务中台 | 提供重用服务，例如用户中心、订单中心之类的开箱即用可重用能力，为战场提供了空军支援能力，随叫随到，威力强大             |
            | 数据中台 | 提供数据分析能力，帮助从数据中学习改进，调整方向，为战场提供了海军支援能力                                              |
            | 算法中台 | 提供算法能力，帮助提供更加个性化的服务，增强用户体验，为战场提供了陆军支援能力，随机应变，所向披靡                      |
            | 技术中台 | 提供自建系统部分的技术支撑能力，帮助解决基础设施，分布式数据库等底层技术问题，为前台特种兵提供了精良的武器装备         |
            | 研发中台 | 提供自建系统部分的管理和技术实践支撑能力，帮助快速搭建项目、管理进度、测试、持续集成、持续交付，是前台特种兵的训练基地 |
            | 组织中台 | 为项目提供投资管理、风险管理、资源调度等，是战场的指挥部，战争的大脑，指挥前线，调度后方                                |

    - 腾讯例子：

        - 引擎中台对接的是腾讯以及外部的各大实验室，比如腾讯优图实验室、AILab实验室、XLab实验室等等，还有一些安全平台，证照库等。

        - 业务中台，是指在逻辑层有很多公用的服务，我们不需要每一个模块都去实现，有很多公用的服务可以抽取到业务中台去实现，比如像图像的处理、视频处理、下载代理，计费上报等。

        - 数据中台,因为每个业务都会有很多相关的数据处理，比如说计费、统计、业务报表、质量、分析、收入成本、客户分析对账等等，所以这一块我们统一抽象成了一个数据中台。


- 员工可以跳到别的岗位上：觉得自己的兴趣和才华在别处的员工，工作室允许他们自由地移动到别的部门。

### [36氪：中台，我信了你的邪 | 深氪](https://mp.weixin.qq.com/s/9j3BnR3UqA-lnJDoM5Hrvg)

- 到了去年底，阿里巴巴董事长兼CEO张勇在湖畔大学分享时也说：如果一个企业奔着中台做中台，就是死。

- “中台”概念火了一年多后，露出它狰狞的一面。

    - 多位行业人士对36氪说，由于盲目上中台，深圳一家女装企业的CIO 被开除；在华南一个有几十人的CIO（首席信息官，是Chief Information Officer的缩写）社群内，2019年由于中台项目失误导致离职、调岗的高管就有十几个。

    - “一分钱都不给，让你们滚出茅台。”中台服务公司“云徙科技”的一名前高管对36氪说，由于茅台对该公司承建的中台项目极不满意，一度如此放话。

        - 茅台的中台项目因为甲方有名、金额大，一度是最引人瞩目的中台案子，也极具代表性。36 氪了解到，茅台虽然最终没和云徙中断合作，但拖了至少13个月才正式签约；业界都说茅台是个“超级大单”，但最后云徙拿到的钱只刚过千万，云徙创始人包志刚对36氪承认，“的确没有收回成本”。

- 中台火热的现象：“中台”恍若一剂支撑新业务快速崛起的良方，同时还能省钱。在互联网公司呼号红利到顶和减员提效的2019年，一时蔚然成风。

    - 联想例子：

        - 联想BT/IT部门企业架构总监杨若东一筹莫展之际，“中台”是他能找到最好的解药。2017年时，联想集团提出要向云、数据中心、AI等新业务延伸，但新的业务部门成立，要不要成立一个新的IT 部门去支持它？

        - “不可能。”杨若东飞快算了笔账：联想成立一个新 BU ，往往需要百人的 IT 团队，这意味着一年的预算不断上涨，就算这笔钱能申请下来，几个月内也根本招不够人。但业务可等不及，冲在一线的销售们巴不得三个月搭好系统，六个月可以卖，一年之内有收入。

        - 杨若东遍寻之后找到的，是一本由阿里中间件首席架构师钟华所写的《企业IT 架构转型之道》，副标题是“阿里巴巴中台战略思想与架构实战”。下单看过之后，杨若东发现“问题被解答了”，他立刻又买下二十本送给同事。

    - 字节跳动例子：

        - 技术出身的张一鸣，创立今日头条时就融入了中台架构；36 氪也在2019年3月独家报道，字节跳动搭建了“直播中台”，将三个产品的直播技术和运营团队抽出和合并，来支撑它旗下的所有直播业务。

    - 腾讯例子：腾讯在2019年5月的入局，宣布将进一步开放数据中台和技术中台，更是将这一波“中台崇拜”推进至高潮。

    - “中台”随之在2019年成为VC们下注的赛道：不少投资人相信，大量传统公司没有IT能力自建中台，第三方服务商就有了市场。2019 年第四季度，三家中台服务商相继宣布获得融资：滴普科技完成 3500 万美元A 轮融资、云徙科技完成3.5 亿元 B 轮融资、袋鼠云完成数亿元 B 轮融资。

    - “但我们现在都在反思：中台把客户的期望值拉得太高了。”一位阿里云前高管对36氪说。中台既不是一套软件，也不是一套服务器，而是一种理念、一套方法论，这最终导致客户“接不住”。

    - 第三方公司的销售为了拿下客户，也会夸大中台的效果。云徙前技术骨干周宏告诉 36 氪，他发现，销售去客户那讲 PPT 的时候，“什么都承诺，什么东西都有，”造成一种中台能“包治百病”的感觉。

    - 这就造成了一个极为吊诡的现象：一时间大家都在说中台，似乎什么都可以往“中台”里装。有业务中台、数据中台、技术中台、安全中台、AI中台……从来没有一个“风口”，像中台这样说不清、道不明。

- 迷惑，是许多人入局中台之初的关键词。

    - 周宏就是如此。他刚加入云徙科技不久、在一名架构师拜访客户时，架构师拿出一套PPT，在客户面前口若悬河地讲了几个小时后，周宏与客户一样，都被这个PPT “迷倒了”。

        - “我当时看完之后，觉得这辈子的技术大概是白干了。”周宏对36氪说。

        - 周宏在互联网巨头做过大项目、带过超百人的技术团队，从业近20年，可眼前这份漂亮的PPT里，谈到的技术方案让他闻所未闻，他打定主意要跟这位同事好好请教。从客户那里出来，周宏满是敬佩地说：“X哥，以后要跟你好好学习，你技术太牛了。”

        - 对方的回复让周宏感到震惊：“我没干过技术啊”。“那你刚才讲的东西，我觉得都很深奥。”周宏不解。

        - “哦，这些都是我这里抄一点，那里抄一点，最后合起来的。”对方解释说。

        - 周宏向36 氪展示了一个类似的PPT，在PPT 第二页“茅台云商平台战略构想”中，几乎聚合了所有时下的热门互联网理念：O2O、B2B、B2C、众筹、物联网、金融服务、区块链……

        - “看到这里很容易被唬住，你会觉得这套方案简直无所不能。”周宏说。但这显然不现实。

        - 在“中台”萌芽的早期，没人知道“中台”怎么干，那些掉进“中台”迷宫的企业都有一个共同点：为做而做，缺乏清晰目标。

        - 被问到茅台的“中台”项目目标是什么时，周宏回答说，正是因为“目标不清楚，所以（项目）做了很久。”

        - “你说我们要不要做个中台？”地产信息化服务商“明源云”的副总裁童继龙时常被这么问，发问的往往是手里握有百亿项目的地产行业高管。“只要是提出这个问题的，大多是看到别人做了，自己着急，也想跟风做一个。”

        - 但客户要赶上趋势，服务商想挣钱，所有人为了一个概念蜂拥而上。但真做起来，才往往发现无从下手。

        - 一家炼油厂和云徙碰出的一个场景是：当用户去加油站加油，“中台”可以告诉油厂，用户加了多少油；加油站还剩多少油，以便油厂规划生产和销售策略。但真去实地考察后才发现，油厂归油厂，加油站归属于中石化，炼油厂其实拿不到加油站的数据。

        - 为了跑通这一场景，云徙和炼油厂开了半个多月的会，还在方案里加入了公众号、小程序，最后还是无济于事。“这就是个听起来很美、但实际上没用的场景，因为根本没法产品化。”

    - 更让人恼火的是，中台真的实施起来，出人意料地贵，也出人意料地耗费时间。

        - 不同于通常只涉及一个部门的SaaS软件项目，由于强调“打通”，中台项目往往意味者要跟所有部门梳理业务，所以耗费人力特别多，而人力成本是导致“中台”项目花钱最凶的部分。

        - 以云徙为例，多位员工告诉 36 氪，他们给客户的报价大概是 3000 元左右/人/天；以茅台项目为例，50 位员工进驻茅台，一天就是 15 万的人头费，何况茅台项目延期了一年。（备注：“人/天”费用只存在于项目合同期内，项目延期后甲方就不再付费，乙方则需支付违约金。）

        - 在云徙内部有“三大战役”一说，指的是它早期重要的三家客户：茅台、珠江啤酒、以及日化直销公司“如新”。据 36 氪了解，三家公司签约金额都在千万以上，且都出现了项目延期的情况。其中，茅台延期近两年、如新一期项目延期近 10 个月。

        - 周宏记得，为了让客户签下“交付确认书”，一位销售曾传授“经验"：在下雪天的时候，只穿一件单衣在客户楼下站着，“最好冻得发抖”，等客户出来的时候再去签约。

        - 这也是为什么茅台会大发雷霆，CIO们会因为盲目上中台而“下台”。

        - “问题严重的话，一个是花钱的 CIO，一个是赚钱的业务负责人，你觉得老板会怎么取舍？”一位技术负责人对36氪说。

- 中台究竟是什么？

    - 几乎很难在业界得到一条关于中台的恒定解释，但有一条关键标准：是否能够复用。

    - 联想的会议上，当下属汇报中台进展有多么顺利的时候，首席信息官Arthur Hu 提出了质疑：“现在有这么多中台服务，面上貌似挺好的，但是少一块信息：调用中台的服务数量是多少？”通过调用次数判断中台的利用效率，是联想 IT 中台的一条 KPI，也是一个明确的方法论。

    - 这也是百果科技研发总监姚杨的检验标准。他曾接待过推销“中台”产品的销售，对方讲了没几句，姚杨就没了兴致。对方卖的“中台”，是把一个大模块拆成一个个的小中心，业内一般管这叫“微服务”，已经是个老概念。看起来跟中台很像，但是如果这些小中心只是被拆开、但没法复用，就只是“伪中台”。

- 重复利用，这才是“中台”的源起。

    - 因此，被咨询要不要做中台时，童继龙一般会反问对方两个问题：1、你的规模大到足够消化中台吗？2、中台能给你带来什么商业价值？

    - 往往只有规模够大的企业，才会有多个业务，才会有重复建设的问题。童继龙抛出一个略微惊悚的比喻：“别把中台当作万能药。大象吃这个药，强身健体，蚂蚁吃这个药，一击毙命。”

    - 拿联想来说，它开发过一个“配置器”功能，可以帮消费者、渠道商自行订制 CPU 等电脑组件，但梳理业务的时候联想发现，不同部门里，竟然散落着 5、6 个相似的配置器。那么中台做配置器，对联想来说就是有效的。

    - 但这也是所谓“业务中台”让人迷惑的地方：每个行业的需求都不一样，能被复用的东西也不一样。联想中台可以做配置器，但这放在其他公司就是莫名其妙。

    - 业内一般认为，同行业的中台配置相似度较高。这也是第三方服务商们能获得投资的原因：在茅台做完项目后，同样的东西改一改可以卖给洋河大曲，但这只是个假设。即使是阿里巴巴的电商中台，放在其他的电商业务里，比如“茅台云商”，也不一定能用起来。因为每家公司的组织架构、业务逻辑都是千差万别的。

#### 不是IT问题，而是组织问题

- 从 PPT 回到现实业务，一切需要重新验证。

    - 云徙给茅台的PPT 里，一张中台全景图与阿里巴巴沉淀10 年的中台架构颇为相似，看上去也井井有条——大中台里包裹着“业务”与“数据”两个框，框里分门别类的装着“用户中心”、“会员中心”、“商品中心”……PPT再往后翻，每个“框”和“中心”怎么建，说明书都写得明明白白。

    ![image](./Pictures/soft-architecture/中台-总体架构图.avif)

    - “这个架构图画得是好看的，但实施起来，所有东西都不是这样。”周宏说。

    - 茅台的业务和天猫一样吗？当然不。2017 年5 月，云徙近三十位员工陆续进驻茅台，他们手捧阿里巴巴的中台心得，以为能照猫画虎地搬进茅台，但很快，他们被一个个从未想到的场景困住了。

    - “别说建系统，你连电脑都带不进茅台的仓库。”云徙前高管王峰回忆到。在项目调研初期，他们发现茅台仓储的工人抗拒信息化，只接受用手写单据的形式记录货品。

    - 不同于一般公司，茅台酒压根不愁卖。几番了解后王峰才明白：管理茅台仓库的人，每个月有一定比例的报损额。“他们可以把这些茅台酒报损后再拿去卖，但如果用电脑扫描进 ERP 的话，就没法操作了。”

    - 对于云徙落地中台的困难，包志刚对 36 氪表示：在茅台项目进展的高峰，云徙最多投入过 70 人，以基于场景开发需求。

    - 包志刚也承认，由于中台涉及企业的复杂业务重构，且在项目期间，茅台内部也发生重大组织变化，这对于云徙这样一家需要从 0 到 1 的创业公司来说，的确是巨大挑战。（36 氪注：2018 年 11 月，茅台集团宣布撤销旗下电商公司董事长聂永职务；2019 年 5 月，聂永以涉嫌受贿罪被逮捕；2019 年 12 月，茅台集团宣布电商公司解散。）

- 对“中台”一度感到困惑的还有王健。作为软件及咨询公司ThoughtWorks 的首席架构师，在 2017 年底，当王健为一家国际 500 强公司客户服务中台项目时，他被客户问住了：怎么证明他所展示的中台架构是正确的？王健当时哑口无言，他心里也犯嘀咕：阿里的中台看上去是成功了，可它的成功仅仅是因为中台吗？

    - 王健将这些困惑都写在了公众号《白话中台战略》系列里。随着他对中台理解的推进，不管怎么写，这个本属于 IT 架构的议题，却越来越离不开“组织”：若将中台纯粹当作技术概念，那么其中的“分布式、微服务，早已是老套的 IT 名词；但阿里中台之所以成功，倚靠的不仅是技术，更是敏捷的组织变革。

    - 事实确实如此。2015 年末，在张勇提出“大中台、小前台”的组织战略后，阿里巴巴在 2016-2019 年内，进行过 19 次组织调整，当中涉及诸多高管换岗、部门合并，均为拉通中台提供了基础。

    - 但阿里式的组织调整，对于不少企业来说属于敏感问题。“这好比皇帝对诸侯说，来，明年我要把你们各自的地盘都重新划分一下。”一位咨询公司的分析师给 36 氪举例，“可有几个皇帝敢这么说？一说都造反了，这也是为什么企业在谈中台的时候，很容易避而不谈组织层面。”

    - 事实确实如此。2015 年末，在张勇提出“大中台、小前台”的组织战略后，阿里巴巴在 2016-2019 年内，进行过 19 次组织调整，当中涉及诸多高管换岗、部门合并，均为拉通中台提供了基础。

    - 但阿里式的组织调整，对于不少企业来说属于敏感问题。“这好比皇帝对诸侯说，来，明年我要把你们各自的地盘都重新划分一下。”一位咨询公司的分析师给 36 氪举例，“可有几个皇帝敢这么说？一说都造反了，这也是为什么企业在谈中台的时候，很容易避而不谈组织层面。”

    - 当中台面临“组织”问题，也就是“人”的问题，难度远远超越所谓的 IT、技术与互联网架构。

- 一旦遇到“人”的问题，即便是将中台运用得炉火纯青的阿里巴巴，也难有更好的应对之举。

    - 李小强就吃过客户的闭门羹，他是阿里云智能新零售乳业线的负责人。2019 年初，李小强试图为一家国内一线乳业品牌提供数据中台服务，在与该品牌 CIO 达成合作意向后，他们一起飞往上海，准备和该品牌电商公司的负责人聊聊“怎么把数据打通。”

    - 可到了会议室，当李小强提出要将电商数据接入整体的数据中台后，遭到了对方的强烈反对，“CIO 和电商负责人拍了桌子”，最后，这位电商负责人摔门离开。

    - 这种组织内的博弈让李小强始料未及。“你要接对方的数据，就意味着他所有的业务你都可以看到，这是一个版块负责人天生的防御。”李小强对 36 氪说。

- 正在联想大刀阔斧进行中台设计的杨若东，很快也遇到了组织变革的难题。

    - 杨若东向 36 氪回忆起这场改革，在白板上画下三个大方框，分别代表联想的 PC、手机、服务器业务，又在大方框里各自画出小方框，代表销售、研发、供应链等通用职能的 IT 支持团队，而推动中台项目，就要把大方框里的小方框，逐个抽出来再合并为新的IT部门。

    - “IT 行业都有一个欲望，就是大家即使在重复建设，也要把自己的团队变得更大，这是天性。”杨若东对 36 氪说。最终，联想 BT/IT 的 1800 名员工还是完成了这场调整。杨若东在白板上画下一条长长的线——“2017.09-2019.04”，这场改革费时近 20 个月。

#### 反思中台

- 2019 年初，阿里云智能事业群总裁行癫组织内部战略会，参会者为阿里 P9 （资深专家）以上员工与部门负责人。会上，行癫围绕“中台”展开讨论，他提出：“阿里给客户的中台架构，输出的究竟是什么？”

    - 一位在场的阿里云前高管告诉 36 氪，技术出身、风格务实的行癫认为：一方面，阿里自身的“中台化”仍在探索中，“只完成了 30%”；另外，如果阿里云一味冲在前面做总集成商——客户的特性可能千差万别，总包就要做定制化方案和实施——会透支阿里云的品牌。多位阿里云内部人士向 36 氪承认，现在想以总集成商的身份拿客户，需要部门特批。

    - 一位与阿里云合作紧密的 IT 厂商发现，目前阿里云正主推“数据中台”而不是“业务中台”，原因是阿里云无法满足所有业务场景，但数据中台的产品更能标准化。

    - “更务实，而不是谨慎。”谈及阿里巴巴对于推进中台的态度变化，阿里云战略市场部总经理郭继军对 36 氪说。他认为所谓务实，就是以前不知道水深水浅，不知道中台怎么在行业里应用，经过两年的客户实践后，现在知道能给客户提供的、不能提供的价值分别是什么了。

    - 阿里巴巴集团CEO张勇最近再次提出的警示则是：中台并不适用于每家公司的每个阶段。在独立业务拓展期、突破期，“一定用独立团、独立师、独立旅建制来做”，否则就会变成瓶颈；但发展到一定阶段，出现太多山头时，就要“关停并转、要合并同类项。问管理要效率，取消重复性建设。”

    - 阿里巴巴的中台就经历过不受待见的日子。钟华在书中曾写到：“共享业务事业部”要同时满足淘宝和天猫的业务支持，就算再怎么加班加点，也很难及时周到地满足两大业务部门的业务需求，员工则是有苦说不出，只能默默流泪。

- 百果园的情况如出一辙。

    - 百果园子公司“百果科技”筹建中台后，为了把中台复用起来，规定：只要涉及前端应用项目开发，必须经过中台系统，否则禁止调用数据库。

    - 强制复用后，百果园旗下果多美、杰记、超奇等品牌内的会员、订单、交易等功能被统归至中台，当这些品牌自己的 IT 团队需要调取这些功能时，就要先等百果科技的中台部门做出来。

- 问题又回到了组织与人性上。“你的系统不是自己写出来的，而是复用别人的，这就需要你把后背交给兄弟们。”沈欣说。

- 百果科技CMO沈欣告诉 36 氪，为了鼓励部门间的复用，百果科技实行了不少柔性策略，比如免罚机制：如果是因为复用中台导致的宕机、订单丢失等问题，可以免于处罚。“如果不建立这种信任文化，每个人就会把锅扔到中台头上，中台很快就淹没在唾沫里面了。”

- “如果没有得到’一把手’的支持和认可，中台是非常非常难走下去的。”郭继军对36 氪说。

- 如何获得“一把手”的支持？换句话说，CEO 和 CIO 们熬过千难万险上了中台，图什么？

- 阿里巴巴用近十年的验证给出了初步回答，郭继军说，阿里巴巴的中台支持了集团灵活变阵，如果没有中台，变阵一次，底下的系统要重建一次，这根本无法实现。

- 可不是谁都能长成阿里巴巴，大多数企业经营者有着务实的需求。但不同于前台业务，一个“双11”结束可以讲赚了多少钱，而中台的经济价值，其实很难算出一个数字。做或者不做，有时候就在于CEO信或者不信。

- 中台如今走到了价值验证的关键路口。

## 微服务

### 微服务理论

#### 康威定律

- [邱小侠：微服务架构的理论基础 - 康威定律](https://developer.aliyun.com/article/8611)

    - 康威四大定律：

        - 1.组织的沟通和系统设计之间的紧密联系。对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计。

            - 沟通成本 = n(n-1)/2，沟通成本随着项目或者组织的人员增加呈指数级增长。

                - 博物学家古尔德说：组织体大小很大程度上决定组织形态。蜘蛛真变得像大象一样大，那么它的形态也会变得和大象类似。

                - 亚马逊的Bezos这样比喻：如果2个披萨不够一个团队吃的，那么这个团队就太大了。一般一个互联网公司小产品的团队差不多就是7，8人左右（包含前后端测试交互用研等，可能身兼数职）。

                | 人数            | 复杂度                                |
                |-----------------|---------------------------------------|
                | 5个人的项目组   | 需要沟通的渠道是 5*(5–1)/2 = 10       |
                | 15个人的项目组  | 需要沟通的渠道是15*(15–1)/2 = 105     |
                | 50个人的项目组  | 需要沟通的渠道是50*(50–1)/2 = 1225    |
                | 150个人的项目组 | 需要沟通的渠道是150*(150–1)/2 = 11175 |

            - Dunbar Number（邓巴数）：150个人是人类的维系关系的极限

                | 关系             | 个数      |
                |------------------|-----------|
                | 亲密（intimate） | 朋友: 5   |
                | 信任（trusted）  | 朋友: 15  |
                | 接近（close）    | 朋友: 35  |
                | 临时（casual）   | 朋友: 150 |

                ![image](./Pictures/soft-architecture/Dunbar'Number.avif)

        - 2.时间再多一件事情也不可能做的完美，但总有时间做完一件事情

            - 对于一个巨复杂的系统，我们永远无法考虑周全。Eric Hollnagel认为最好的解决办法是抓主线

                - 有点类似于毛泽东说的《不要四面出击》

            - Eric被一家航空公司请去做安全咨询顾问，复杂保证飞机飞行系统的稳定性和安全性。Eric认为做到安全有两种方式：

                - 1.常规的安全：指的是尽可能多的发现并消除错误的部分，达到绝对安全，这是理想。
                - 2.弹性安全：即使发生错误，只要及时恢复，也能正常工作，这是现实。

                - 对于飞机这样的复杂系统，再牛逼的人也无法考虑到漏洞的方方面面，所以Eric建议放弃打造完美系统的想法，而是通过不断的试飞，发现问题，确保问题发生时，系统能自动复原即可，而不追求飞行系统的绝对正确和安全。

                - 类似于持续集成、敏捷开发：

                    - 对于一个分布式系统，我们几乎永远不可能找到并修复所有的bug，单元测试覆盖1000%也没有用。解决方法不是消灭这些问题，而是容忍这些问题，在问题发生时，能自动回复，微服务组成的系统，每一个微服务都可能挂掉，这是常态，我们只有有足够的冗余和备份即可。即所谓的 弹性设计（Resilience） 或者叫高可用设计（High Availability）。

        - 3.独立自治的子系统减少沟通成本

            - 如果你的团队分成前端团队，Java后台开发团队，DBA团队，运维团队，你的系统就会长成下面的样子

                ![image](./Pictures/soft-architecture/subsystem.avif)

            - 如果你的系统是按照业务边界划分（微服务架构）

                - 定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。

                ![image](./Pictures/soft-architecture/subsystem1.avif)

        - 4.分而治之

            - 人多管不过来啊，找几个经理帮我管，我管经理

            - 每个经理都被赋予一定的职责去做大系统的某一小部分，他们和大系统便有了沟通的边界，所以大的系统也会因此被拆分成一个个小团队负责的小系统（微服务）

#### 谁适合微服务？

- 微服务比较适合未来有一定的扩展复杂度，且有很大用户增量预期的应用，说人话就是新兴的互联网公司

    ![image](./Pictures/soft-architecture/microservice.avif)

- [王者荣耀为什么不使用微服务架构？](https://www.zhihu.com/question/359630395/answer/954452799)

    - 游戏的核心在于10 个人之间各种游戏事件的高速网络通信

        - 微服务为了把业务完美拆解，把原来的同一个进程里的模块拆分成不同的服务，显著增加额外的网络开销。

- 小项目还是别用微服务了，谁用谁难受啊。

    - 这倒不是说搞微服务不好，主要是当项目较小、人手不多的情况下，搞微服务的开发、部署成本太大，一个人同时改几个微服务模块，模块之间还有调用关系，很容易搞的人心力交瘁。

    - 本来应该几个小时能搞好的东西，在微服务的加持下，各服务间来回一调用，弄个两三天一点不成问题啊。

    - 首先说说团队自治。一个人管2、3个模块，确实是自治了，自己治自己。当你一个人负责两个或更多模块的时候，你就能深刻的体会到。

    - 当你同时修改这几个模块的时候，你要在本地将这几个服务启动、调试，如果公司不人道，给你配了台垃圾电脑，那连项目都别想痛痛快快的启动。

- 还有就是工期紧的项目，就不要微服务了。

    - 本来光搞业务就已经很紧张了，结果老板还要催着、赶着，那这种情况下建议还是不要微服务了。
    - 这种项目大多数以业务为主，对架构和性能要求往往没那么高，完全可以单体解决。
    - 如果采用微服务的话， 开发周期加长了不说，后期的维护成本会很大，尤其是不熟悉项目的人做后期维护。

- 网络、部署环境有限制，就不要微服务了
    - 在和朋友聊要不要用微服务的时候，有个朋友说，给国企或者ZF做的项目，能用单体就用单体吧。
    - 他说曾经给某个ZF部门做项目，项目是在自身产品功能上做一些定制化改造，微服务框架，有6、7个服务。
    - 结果甲方那边网络完全是内网环境，系统有指定的国产系统，机器开的每一个端口都要报备、说明，部署有指定的部署平台，连 RPC 调用都有特殊的要求。
    - 每次上线要在外部网络打包，然后用物理设备拷到内网，7、8个包，每一个包走一次部署流程，然后服务间调用是否成功也只能部署完之后才能测试。
    - 本来1天能做完的事儿，3、4天都弄不完，每天都薅头发。

### 微服务架构

- [邱小侠：微服务（Microservice）那点事](https://developer.aliyun.com/article/2764)

    - 分布式：按功能拆分成独立的服务，跑在独立的一般都在独立的虚拟机上

    - API Gateway：提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合

        - 有可能成为单点故障点或者性能的瓶颈。

        ![image](./Pictures/soft-architecture/API-Gateway.avif)

    - 服务之间如何通信？

        ![image](./Pictures/soft-architecture/communication.avif)

        - 同步调用：

            - REST（JAX-RS）
            - RPC（Dubbo）

        - 异步消息调用：

            - 能成为调用之间的缓冲，确保消息积压不会冲垮被调用方

            - 不过需要付出的代价是一致性的减弱，需要接受数据最终一致性

            - 后台服务一般要实现幂等性，因为消息发送出于性能的考虑一般会有重复（保证消息的被收到且仅收到一次对性能是很大的考验）

            - 必须引入一个独立的 broker，如果公司内部没有技术积累，对 broker 分布式管理也是一个很大的挑战。

            | 软件   |
            |--------|
            | Kafka  |
            | Notify |
            | MetaQ  |

    - 负载均衡：每一个服务都是有多个拷贝。一个服务随时可能下线，也可能应对临时访问压力增加新的服务节点。
        - 通过 zookeeper 等类似技术做服务注册信息的分布式管理

            - 服务上线时，服务提供者将自己的服务信息注册到 ZK（或类似框架）
            - 通过心跳维持长链接，实时更新链接信息
            - 服务调用者通过 ZK 寻址，根据可定制算法，找到一个服务，还可以将服务信息缓存在本地以提高性能
            - 当服务下线时，ZK 会发通知给服务客户端

- [腾讯云开发者：日调1000亿，腾讯微服务平台的架构演进](https://cloud.tencent.com/developer/article/1701134)

    - 服务发现：需要一个地方记录 IP

        - 传统架构：通过 IP 和 port 来进行互相调用

        - 微服务架构：使用 K8s 和 docker，每次启动的 IP 也可能会变

            - ServiceB 的每个实例在启动时，会将自身的 IP 和 port 写入到服务发现模块的某个路径，然后 ServiceA 会从这个路径来拉取到想要访问的 ServiceB 的服务提供者的列表。

        - 组件有zookeeper，nacos，Consul等：

            - Consul： 和 Spring 的对接也很成熟，很多中小型公司，特别是比较新的公司很多都会选择 Consul 来作为服务注册发现。
                - 服务注册请求、心跳请求会被翻译成kv，然后存储到server上。
                - 服务发现会将服务注册请求、心跳请求的kv内容合并，然后返回

#### [熔断、隔离、重试、降级、超时、限流，高可用架构流量治理核心策略全掌握](https://cloud.tencent.com/developer/article/2374938)

- 一个完善的架构应该具备3个能力，也就是身体的“三高”：
    - 高性能；
    - 高可用；
    - 易扩展。

- 理解高可用时，通常参考两个关键指标：

    - 平均故障间隔（Mean Time Between Failure，简称 MTBF）：表示两次故障的间隔时间，也就是系统正常运行的平均时间，这个时间越长，说明系统的稳定性越高；

    - 故障恢复时间（Mean Time To Repair，简称 MTTR）：表示系统发生故障后恢复的时间，这个时间越短，说明故障对用户的影响越小。

    - 可用性（Availability）的计算公式：Availability= MTBF / (MTBF + MTTR) * 100%

        - 这个公式反映了一个简单的事实：只有当系统故障间隔时间越长，且恢复时间越短，系统的整体可用性才会更高。

    - 因此，在设计高可用系统时，我们的核心目标是延长 MTBF，同时努力缩短 MTTR，以减少任何潜在故障对服务的影响。

- 流量治理的主要目的包括：
    - 网络性能优化：通过流量分配、负载均衡等技术，确保网络资源的高效利用，减少延迟和避免拥塞；
    - 服务质量保障：确保关键应用和服务的流量优先级，以保障业务关键操作的流畅运行；
    - 故障容错和弹性：在网络或服务出现问题时，通过动态路由和流量重定向等机制，实现故障转移和自我恢复，以维持服务的持续可用性；
    - 安全性：实施流量加密、访问控制和入侵检测等措施，保护网络和数据不受未授权访问或攻击；
    - 成本效益：通过有效管理流量，降低带宽需求和相关成本，同时提高整体系统效率。

- 流量治理的手段：熔断，隔离，重试，降级，超时，限流

- 熔断：微服务系统中，一个服务可能会依赖多个服务，并且有一些服务也依赖于它

    - 问题：
        - 当“媒体中心”服务的其中一个依赖服务出现故障（比如用户服务），媒体中心只能被动地等待依赖服务报错或者请求超时；
        - 下游连接池会被逐渐耗光；
        - 入口请求大量堆积，CPU、内存等资源被逐渐耗尽，最终导致服务宕掉。
        - 而依赖“媒体中心”服务的上游服务，也会因为相同的原因出现故障，一系列的级联故障最终会导致整个系统不可用；
        - 合理的解决方案是引入熔断器和优雅降级，通过尽早失败来避免局部不稳定而导致的整体雪崩。

        ![image](./Pictures/soft-architecture/流量治理-熔断.avif)

    - 解决方法：

        - 1.传统熔断器：当请求失败比率达到一定阈值之后，熔断器开启，并休眠一段时间（由配置决定）。这段休眠期过后，熔断器将处于半开状态，在此状态下将试探性地放过一部分流量，如果这部分流量调用成功后，再次将熔断器关闭，否则熔断器继续保持开启并进入下一轮休眠周期。

            ![image](./Pictures/soft-architecture/流量治理-传统熔断器的请求时序图.avif)

            - 传统熔断器实现 关闭、打开、半开 三个状态；

                - 关闭（Closed）：默认状态。允许请求到达目标服务，同时统计在窗口时间内的成功和失败次数，如果达到错误率阈值将会切换为“打开”状态；

                - 打开（Open）：对应用的请求会立即返回错误响应或执行预设的失败降级逻辑，而不调用目标服务；

                - 半开（Half-Open）：进入“打开”状态会维护一个超时时间，到达超时时间后开始进入该状态，允许应用程序一定数量的请求去调用目标服务。

                    - 熔断器会对成功执行的调用进行计数，达到配置的阈值后会认为目标服务恢复正常，此时熔断器回到“关闭”状态；

                    - 如果有请求出现失败的情况，则回到“打开”状态，并重新启动超时计时器，再给系统一段时间来从故障中恢复。

                ![image](./Pictures/soft-architecture/流量治理-传统熔断器的请求时序图1.avif)

                - 当进入 Open 状态时会拒绝所有请求；进入 Closed 状态时瞬间会有大量请求，这时服务端可能还没有完全恢复，会导致熔断器又切换到 Open 状态；而 Half-Open 状态存在的目的在于实现了服务的自我修复，同时防止正在恢复的服务再次被大量打垮；
                - 所以传统熔断器在实现上过于一刀切，是一种比较刚性的熔断策略。

        - 2.Google SRE 熔断器

            - 是否可以做到在熔断器 Open 状态下（但是后端未 Shutdown）仍然可以放行少部分流量呢？Google SRE 熔断器提供了一种算法：客户端自适应限流（client-side throttling）。

            - 解决的办法就是客户端自行限制请求速度，限制生成请求的数量，超过这个数量的请求直接在本地回复失败，而不会真正发送到服务端。

            - 该算法统计的指标依赖如下两种，每个客户端记录过去两分钟内的以下信息（一般代码中以滑动窗口实现）。
                - requests：客户端请求总量
                - accepts：成功的请求总量 - 被 accepted 的量

            - Google SRE 熔断器的工作流程：
                - 在通常情况下（无错误发生时） requests == accepts ；
                - 当后端出现异常情况时，accepts 的数量会逐渐小于 requests；
                - 当后端持续异常时，客户端可以继续发送请求直到 requests = K∗accepts，一旦超过这个值，客户端就启动自适应限流机制，新产生的请求在本地会被概率（以下称为p）丢弃；

                    - 客户端请求被拒绝的概率（Client request rejection probability，以下简称为 p）：p 基于如下公式计算（其中 K 为倍率 - multiplier，常用的值为 2）。

                        ![image](./Pictures/soft-architecture/客户端请求被拒绝的概率.avif)

                - 当客户端主动丢弃请求时，requests 值会一直增大，在某个时间点会超过 K∗accepts，使 p 计算出来的值大于 0，此时客户端会以此概率对请求做主动丢弃；

                - 当后端逐渐恢复时，accepts 增加，（同时 requests 值也会增加，但是由于 K 的关系，K*accepts的放大倍数更快），使得 (requests − K×accepts) / (requests + 1) 变为负数，从而 p == 0，客户端自适应限流结束。
                - 当 requests − K∗accepts <= 0 时，p == 0，客户端不会主动丢弃请求；
                - 反之， p 会随着 accepts 值的变小而增加，即成功接受的请求数越少，本地丢弃请求的概率就越高。

                - 客户端可以发送请求直到 requests = K∗accepts， 一旦超过限制， 按照 p 进行截流。
                    - 对于后端而言，调整 K 值可以使得自适应限流算法适配不同的服务场景
                    - 降低 K 值会使自适应限流算法更加激进（允许客户端在算法启动时拒绝更多本地请求）；
                    - 增加 K 值会使自适应限流算法变得保守一些（允许服务端在算法启动时尝试接收更多的请求，与上面相反）。

        - 熔断本质上是一种快速失败策略。旨在通过及时中断失败或超时的操作，防止资源过度消耗和请求堆积，从而避免服务因小问题而引发的雪崩效应。

- 隔离：如动静隔离、读写隔离和机房隔离，通过物理或逻辑上分离资源和请求，减少单点故障的影响

    - 微服务系统中，隔离策略是流量治理的关键组成部分，其主要目的是避免单个服务的故障引发整个系统的连锁反应。

    - 通过隔离，系统能够局部化问题，确保单个服务的问题不会影响到其他服务，从而维护整体系统的稳定性和可靠性。

    - 常见的隔离策略：

        - 动静隔离：动静隔离通常是指将系统的动态内容和静态内容分开处理

            - 动态内容
                - 指需要实时计算或从数据库中检索的数据，通常由后端服务提供；
                - 可以通过缓存、数据库优化等方法来提高动态内容的处理速度。

            - 静态内容
                - 指可以直接从文件系统中获取的数据，例如图片、音视频、前端的 CSS、JS 文件等静态资源；
                - 可以存储到 OSS 并通过 CDN 进行访问加速。
                ![image](./Pictures/soft-architecture/流量治理-隔离-动静隔离.avif)

        - 读写隔离：读写隔离通常是指将读操作和写操作分离到不同的服务或实例中处理
            - 大部分的系统里读写操作都是不均衡的，写数据可能远远少于读数据；
            - 读写隔离得以让读服务和写服务独立扩展。
            - DDD中有一种常用的模式：CQRS（Command Query Responsibility Segregation，命令查询职责分离）来实现读写隔离
                - 通过 CQRS 模式，读服务和写服务可以独立地进行扩展；
                - 如果系统的读负载较高，可以增加读服务的实例数量；如果写负载较高，可以增加写服务的实例数量。
                ![image](./Pictures/soft-architecture/流量治理-隔离-读写隔离CQRS模式.avif)

            - 写服务
                - 负责处理所有的写操作，例如创建、更新和删除数据；
                - 通常会有一个或多个数据库或数据存储，用于保存系统的数据。

            - 读服务
                - 负责处理所有的读操作，例如查询和检索数据；
                - 可以有独立的数据库或数据存储，也可以使用缓存来提高查询的性能。

            - 事件驱动
                - 当写服务处理完一个写操作后，通常会发布一个事件，通知读服务数据已经发生变化；
                - 读服务可以监听这些事件，并更新其数据库或缓存，以保证数据的一致性。

        - 核心隔离：核心隔离通常是指将资源按照 “核心业务”与 “非核心业务”进行划分，优先保障“核心业务”的稳定运行AI助手

            - 核心/非核心故障域的差异隔离（机器资源、依赖资源）；
            - 核心业务可以搭建多集群通过冗余资源来提升吞吐和容灾能力；
            - 按照服务的核心程度进行分级。
            - 1级：系统中最关键的服务，如果出现故障会导致用户或业务产生重大损失；
            - 2级：对于业务非常重要，如果出现故障会导致用户体验受到影响，但不会导致系统完全无法使用；
            - 3级：会对用户造成较小的影响，不容易注意或很难发现；
            - 4级：即使失败，也不会对用户体验造成影响。

        - 热点隔离：热点隔离通常是指一种针对高频访问数据（热点数据）的隔离策略

            - 可以帮助微服务系统更高效地处理热点数据的访问请求；
            - 需要有机制来识别和监控热点数据；
                - 分析系统的历史访问记录；
                - 观察系统的监控告警信息等。
            - 将访问频次最高的 Top K 数据缓存起来，可以显著减少对后端存储服务的访问压力，同时提高数据访问的速度；
            - 可以创建一个独立的缓存服务来存储和管理热点数据，实现热点数据的隔离。

        - 用户隔离：用户隔离通常是指按照不同的分组形成不同的服务实例。这样某个服务实例宕机了也只会影响对应分组的用户，而不会影响全部用户

            - 基于 O2-SAAS 系统的租户概念，按照隔离级别的从高到低有如下几种隔离方式：

                - 1.每个租户有独立的服务与数据库
                    - 网关根据 tenant_id 识别出对应的服务实例进行转发
                    ![image](./Pictures/soft-architecture/流量治理-隔离-用户隔离1.avif)

                - 2.每个租户有共享的服务与独立的数据库
                    - 用户服务根据 tenant_id 确定操作哪一个数据库
                    ![image](./Pictures/soft-architecture/流量治理-隔离-用户隔离2.avif)

                - 3.每个租户有共享的服务与数据库
                    - 用户服务根据 tenant_id 确定操作数据库的哪一行记录
                    ![image](./Pictures/soft-architecture/流量治理-隔离-用户隔离3.avif)

        - 进程隔离：进程隔离通常是指系统中每一个进程拥有独立的地址空间，提供操作系统级别的保护区。一个进程出现问题不会影响其他进程的正常运行，一个应用出错也不会对其他应用产生副作用

            - 容器化部署便是进程隔离的最佳实践：

                ![image](./Pictures/soft-architecture/流量治理-隔离-进程隔离.avif)

        - 线程隔离：线程隔离通常是指线程池的隔离，在应用系统内部，将不同请求分类发送给不同的线程池，当某个服务出现故障时，可以根据预先设定的熔断策略阻断线程的继续执行

            ![image](./Pictures/soft-architecture/流量治理-隔离-线程隔离.avif)

            - 如图，接口A 和 接口B 共用相同的线程池，当 接口A 的访问量激增时，接口C 的处理效率就会被影响，进而可能产生雪崩效应；
            - 使用线程隔离机制，可以将 接口A 和 接口B 做一个很好的隔离。

        - 集群隔离：集群隔离通常是指将某些服务单独部署成集群，或对于某些服务进行分组集群管理

            - 具体来说就是每个服务都独立成一个系统，继续拆分模块，将功能微服务化：

            ![image](./Pictures/soft-architecture/流量治理-隔离-集群隔离.avif)

        - 机房隔离：机房隔离通常是指在不同的机房或数据中心部署和运行服务，实现物理层面的隔离

            - 机房隔离的主要目的有两个：
                - 解决数据容量大、计算和 I/O 密集度高的问题。将不同区域的用户隔离到不同的地区，比如将湖北的数据存储在湖北的服务器，浙江的数据存储在浙江的服务器，这种区域化的数据管理能有效地分散流量和系统负载；
                - 增强数据安全性和灾难恢复能力。通过在不同地理位置建立服务的完整副本（包括计算服务和数据存储），系统可以实现异地多活或冷备份。这样，即使一个机房因自然灾害或其他紧急情况受损，其他机房仍能维持服务，确保数据安全和业务连续性。

            ![image](./Pictures/soft-architecture/流量治理-隔离-机房隔离.avif)

- 重试：包括同步和异步重试，以及各种退避机制，帮助在失败时优雅地恢复服务。

    - 如何在不可靠的网络服务中实现可靠的网络通信，这是计算机网络系统中避不开的一个问题

    - 如果重试之后还是不行，说明这个故障不是短时间的故障，而是长时间的故障。那么可以对服务进行熔断降级，后面的请求不再重试，这段时间做降级处理，减少没必要的请求，等服务端恢复了之后再进行请求，这方面的工程实现很多，比如 go-zero 、 sentinel 、hystrix-go。

    - 微服务架构中，一个大系统被拆分成多个小服务，小服务之间大量的 RPC 调用，过程十分依赖网络的稳定性。

        - 网络是脆弱的，随时都可能会出现抖动，此时正在处理中的请求有可能就会失败。场景：O2 Marketing API 服务调用媒体接口拉取数据。

        - 对于网络抖动这种情况，解决的办法之一就是重试。但重试存在风险，它可能会解决故障，也可能会放大故障。

        ![image](./Pictures/soft-architecture/流量治理-重试.avif)

    - 对于网络通信失败的处理一般分为以下几步：
        - 1.感知错误：通过不同的错误码来识别不同的错误，在 HTTP 中 status code 可以用来识别不同类型的错误。
        - 2.重试决策：这一步主要用来减少不必要的重试，比如 HTTP 的 4xx 的错误，通常 4xx 表示的是客户端的错误，这时候客户端不应该进行重试操作，或者在业务中自定义的一些错误也不应该被重试。根据这些规则的判断可以有效的减少不必要的重试次数，提升响应速度。
        - 3.重试策略：重试策略就包含了重试间隔时间，重试次数等。如果次数不够，可能并不能有效的覆盖这个短时间故障的时间段，如果重试次数过多，或者重试间隔太小，又可能造成大量的资源(CPU、内存、线程、网络)浪费。
        - 4.对冲策略：对冲是指在不等待响应的情况主动发送单次调用的多个请求，然后取首个返回的回包。

    - 重试方式

        - 同步重试：
            - 程序在调用下游服务失败的时候重新发起一次；
            - 实现简单，能解决大部分网络抖动问题，是比较常用的一种重试方式。

        - 异步重试：
            - 如果服务追求数据的强一致性，并且希望在下游服务故障的时候不影响上游服务的正常运行，此时可以考虑使用异步重试。
            - 将请求信息丢到消息队列中，由消费者消费请求信息进行重试；
            - 上游服务可以快速响应请求，由消费者异步完成重试。

    - 最大重试次数

        - 无限重试可能会导致系统资源（网络带宽、CPU、内存）的耗尽，甚至引发重试风暴

        - 应评估系统的实际情况和业务需求来设置最大重试次数：
            - 设置过低，可能无法有效地处理该错误；
            - 设置过高，同样可能造成系统资源的浪费。

    - 退避策略
        - 我们知道重试是一个 trade-off 问题：
        - 一方面要考虑到本次请求时长过长而影响到的业务的忍受度；
        - 一方面要考虑到重试对下游服务产生过多请求带来的影响。
        - 退避策略基于重试算法实现。重试算法有多种，思路都是在重试之间加上一个间隔时间

        - 线性间隔（Linear Backoff）
            - 每次重试间隔时间是固定的，比如每 1s 重试一次。

        - 线性间隔+随机时间（Linear Jitter Backoff）

            - 有时候每次重试间隔时间一致可能会导致多个请求在同一时间请求；
            - 加入随机时间可以在线性间隔时间的基础上波动一个百分比的时间。

        - 指数间隔（Exponential Backoff）

            - 间隔时间是指数型递增，例如等待 3s、9s、27s 后重试。

        - 指数间隔+随机时间（Exponential Jitter Backoff）

            - 与 Linear Jitter Backoff 类似，在指数递增的基础上添加一个波动时间。

        - 上面有两种策略都加入了 扰动（jitter），目的是防止 惊群问题 （Thundering Herd Problem） 的发生。

            - 所谓惊群问题当许多进程都在等待被同一事件唤醒的时候，当事件发生后最后只有一个进程能获得处理。其余进程又造成阻塞，这会造成上下文切换的浪费所以加入一个随机时间来避免同一时间同时请求服务端还是很有必要的

        - gRPC 实现

            - gRPC 便是使用了 指数间隔+随机时间 的退避策略进行重试：GRPC Connection Backoff Protocol https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md
            ```
            /* 伪代码 */
            ConnectWithBackoff()
              current_backoff = INITIAL_BACKOFF
              current_deadline = now() + INITIAL_BACKOFF
              while (TryConnect(Max(current_deadline, now() + MIN_CONNECT_TIMEOUT))
                     != SUCCESS)
                SleepUntil(current_deadline)
                current_backoff = Min(current_backoff * MULTIPLIER, MAX_BACKOFF)
                current_deadline = now() + current_backoff +
                  UniformRandom(-JITTER * current_backoff, JITTER * current_backoff)
            ```


            - 关于伪代码中几个参数的说明：
                - INITIAL_BACKOFF：第一次重试等待的间隔；
                - MULTIPLIER：每次间隔的指数因子；
                - JITTER：控制随机的因子；
                - MAX_BACKOFF：等待的最大时长，随着重试次数的增加，我们不希望第N次重试等待的时间变成几十分钟这样不切实际的值；
                - MIN_CONNECT_TIMEOUT：一次成功的请求所需要的时间，即使是正常的请求也会有响应时间，重试时间间隔需要大于这个响应时间才不会出现请求明明已经成功，但却进行重试的操作。

    - 重试风暴

        ![image](./Pictures/soft-architecture/流量治理-重试-重试风暴.avif)

        - 通过一张图来简单介绍下重试风暴：

            - DB 负载过高时，Service C 对 DB 的请求出现失败；

            - 因为配置了重试机制，Service C 对 DB 发起了最多 3 次请求；

            - 链路上为了避免网络抖动，上游的服务均设置了超时重试 3 次的策略；

            - 这样在一次业务请求中，对 DB 的访问可能达到 3^(n) 次。

        - 此时负载高的 DB 便被卷进了重试风暴中，最终很可能导致服务雪崩。

        - 解决方法：

            - 1.限制单点重试

                - 一个服务不能不受限制地重试下游，很容易造成下游服务被打挂；

                - 除了设置最大重试次数，还需要限制重试请求的成功率。

            - 2.引入重试窗口

                - 基于断路器的思想，限制 请求失败/请求成功 的比率，给重试增加熔断功能；

                - 常见的实现方式是引入滑动窗口。

                    ![image](./Pictures/soft-architecture/流量治理-重试-重试风暴-重试窗口.avif)

                    - 内存中为每一类 RPC 调用维护一个滑动窗口，窗口分多个 bucket；
                    - bucket 每秒生成 1 个，记录 1 秒内 RPC 的请求结果数据（成功/失败 次数）；
                    - 新的 bucket 生成时，淘汰最早的一个 bucket；
                    - 新的请求到达该 RPC 服务并且失败时，根据窗口内 失败/成功 比率以及失败次数是否超过阈值来判断是否可以重试。比如阈值设置 0.1，即失败率超过 10% 时不进行重试。

            - 3.限制链路重试

                - 多级链路中如果每层都配置重试可能导致调用量指数级扩大；
                - 核心是限制每层都发生重试，理想情况下只有最下游服务发生重试；
                - Google SRE 中指出了 Google 内部使用特殊错误码的方式来实现。

                - 关于 Google SRE 的实现方式，大致细节如下：

                    - 统一约定一个特殊的 status code ，它表示：调用失败，但别重试；
                    - 任何一级重试失败后，生成该 status code 并返回给上层；
                    - 上层收到该 status code 后停止对这个下游的重试，并将错误码再传给自己的上层。

                - 该方法可以有效避免重试风暴，但请求链路上需要上下游服务约定好重试状态码并耦合对于的逻辑，一般需要在框架层面上做出约束。

    - 对冲策略

        - 有时候我们接口只是偶然会出问题，并且我们的下游服务并不在乎多请求几次，那么我们可以考虑对冲策略AI助手

        - 对冲是指在不等待响应的情况下主动发送单次调用的多个请求，然后取首个返回的回包

        - 请求流程

            - 第一次正常的请求正常发出；
            - 在等待固定时间间隔后，没有收到正确的响应，第二个对冲请求会被发出；
            - 再等待固定时间间隔后，没有收到任何前面两个请求的正确响应，第三个会被发出；
            - 一直重复以上流程直到发出的对冲请求数量达到配置的最大次数；
            - 一旦收到正确响应，所有对冲请求都会被取消，响应会被返回给应用层。

        - 与普通重试的区别

            - 对冲在超过指定时间没有响应就会直接发起请求，而重试则必须要服务端响应后才会发起请求。所以对冲更像是比较激进的重试策略。

            - 使用对冲的时候需要注意一点是，因为下游服务可能会做负载均衡策略，所以要求请求的下游服务一般是要求幂等的，能够在多次并发请求中是安全的，并且是符合预期的。

            - 普通重试时序图：
                ![image](./Pictures/soft-architecture/流量治理-重试-对冲策略-普通重试时序图.avif)

            - 普通重试时序图：
                ![image](./Pictures/soft-architecture/流量治理-重试-对冲策略-对冲重试时序图.avif)

- 降级：区分自动和手动降级，作为服务负载过重时的应急措施

    - 降级是从系统功能角度出发，人为或自动地将某些不重要的功能停掉或者简化，以降低系统负载，这部分释放的资源可以去支撑更核心的功能
        ![image](./Pictures/soft-architecture/流量治理-降级.avif)
        - 目的是为了提升系统的可用性，同时要寻找到用户体验与降级成本的平衡点；
        - 降级属于有损操作。简而言之，弃卒保帅。

    - 与限流的区别
        - 降级依靠牺牲一部分功能或体验保住容量，而限流则是依靠牺牲一部分流量来保住容量。
        - 一般来说，限流的通用性会更强一些，因为每个服务理论上都可以设置限流，但并不是每个服务都能降级，比如O2 系统中的登录服务和用户服务，就不可能被降级（没有这两个服务，用户都没法使用系统了）。

    - 以 O2 系统举例，有以下几类降级策略：

        ![image](./Pictures/soft-architecture/流量治理-降级-降级策略.avif)

    - 虽说故障是不可避免的，要达到绝对高可用一般都是使用冗余+自动故障转移，这个时候其实也不需要降级措施了。

        - 但是这样带来的成本较高，而且可用性、成本、用户体验3者本身之间是需要权衡的，一般来说他们之前会是这样的关系：

        ![image](./Pictures/soft-architecture/流量治理-降级-成本与用户体验关系.avif)

    - 执行降级

        ![image](./Pictures/soft-architecture/流量治理-降级-执行降级.avif)

    - 自动降级
        - 适合触发条件明确可控的场景，比如请求调用失败次数大于一定的阈值，服务接口超时等情况；
        - 对于一些旁路服务，服务负载过高也可以直接触发自动降级。

    - 手动降级
        - 降级操作都是有损的，部分情况下需要根据对业务的影响程度进行手动降级；
        - 通常需要先制定降级的分级策略，影响面由浅至深。

    - 降级的策略还是比较丰富的，因此需要从多个角度去化简
        - 首先，将一部分判断条件简单的降级通过自动化手段去实现；
        - 其次，根据对业务的影响程度，对降级进行分级，达到有层次的降级效果；
        - 最后，通过高频演练，确保降级的有效性。

- 超时：通过精细的策略来避免长时间等待和资源浪费

    - 超时是一件很容易被忽视的事情
        - 早期架构发展阶段，大家或多或少有过遗漏设置超时或者超时设置太长导致系统被拖慢甚至挂起的经历
        - 随着微服务架构的演进，超时逐渐被标准化到 RPC 中，并可通过微服务治理平台快捷调整超时参数
        - 传统超时会设定一个固定的阈值，响应时间超过阈值就返回失败。在网络短暂抖动的情况下，响应时间增加很容易产生大规模的成功率波动
        - 服务的响应时间并不是恒定的，在某些长尾条件下可能需要更多的计算时间，为了有足够的时间等待这种长尾请求响应，我们需要把超时设置足够长，但超时设置太长又会增加风险，超时的准确设置经常困扰我们

    - 超时策略

        - 目前业内常用的超时策略有：
        - 固定超时时间；
        - EMA 动态超时。

    - 超时控制

        ![image](./Pictures/soft-architecture/流量治理-超时-超时控制.avif)
        - 超时控制的本质是 fail fast，良好的超时控制可以尽快清空高延迟的请求，尽快释放资源避免请求堆积。

    - 服务间超时传递

        - 一个请求可能由一系列 RPC 调用组成，每个服务在开始处理请求前应检查是否还有足够的剩余时间处理，也就是应该在每个服务间传递超时时间。

        ![image](./Pictures/soft-architecture/流量治理-超时-服务间超时传递.avif)

        - 如果都使用每个 RPC 服务设置的固定超时时间，这里以上图为例
            - A -> B，设置的超时时间为 3s；
            - B 处理耗时为 2s，并继续请求 C；
            - 如果使用了超时传递那么 C 的超时时间应该为 1s，这里不采用所以超时时间为配置的 3s；
            - C 继续执行耗时为 2s，此时最上层（A）设置的超时时间已截止；
            - C -> D的请求对 A 来说已经失去了意义。

    - 进程内超时传递

        ![image](./Pictures/soft-architecture/流量治理-超时-进程内超时传递.avif)

        - 上图流程如下：
            - 一个进程内串行调用了 MySQL、Redis 和 Service B，设置总的请求时间为 3s；
            - 请求 MySQL 耗时 1s 后再请求 Redis，这时的超时时间为 2s，Redis 执行耗时 500 ms；
            - 再请求 Service B，这时超时时间为 1.5s。

        - 由于每个组件或服务都会在配置文件中配置固定的超时时间，使用时应该取实际剩余时间与配置的超时时间中的最小值。

        - Context 实现超时传递

            ![image](./Pictures/soft-architecture/流量治理-超时-进程内超时传递context实现.avif)

    - EMA动态超时

        - 如果我们的微服务系统对这种短暂的时延上涨具备足够的容忍能力，可以考虑基于 EMA 算法动态调整超时时长。

        - EMA 算法引入“平均超时”的概念，用平均响应时间代替固定超时时间，只要平均响应时间没有超时即可，而不是要求每次请求都不能超时。

        - 算法实现

            ![image](./Pictures/soft-architecture/流量治理-超时-EMA动态超时.avif)

            - 当平均响应时间（EMA）大于超时时间限制（Thwm），说明平均情况表现很差，动态超时时长（Tdto）就会趋近于超时时间限制（Thwm），降低弹性；

            - 当平均响应时间（EMA）小于超时时间限制（Thwm），说明平均情况表现很好，动态超时时长（Tdto）就可以超出超时时间限制（Thwm），但会低于最大弹性时间（Tmax），具备一定的弹性。

            - 算法实现参考：https://github.com/jiamao/ema-timeout

        - 总而言之：
            - 总体情况不能超标；
            - 平均情况表现越好，弹性越大；
            - 平均情况表现越差，弹性越小。


        - 适用条件
            - 固定业务逻辑，循环执行；
            - 程序大部分时间在等待响应，而不是 CPU 计算或者处理 I/O 中断；
            - 服务是串行处理模式，容易受异常、慢请求阻塞；
            - 响应时间不宜波动过大；
            - 服务可以接受有损。

        - 使用方法：EMA 动态超时根据业务的请求链路有两种用法：

            - 1.用于非关键路径：Thwm 设置的相对小，当非关键路径频繁耗时增加甚至超时时，降低超时时间，减少非关键路径异常带来的资源消耗，提升服务吞吐量。

            - 2.用于关键路径：Thwm 设置的相对大，用于长尾请求耗时比较多的场景，提高关键路径成功率。

    - 一般超时时间会在链路上传递，避免上游已经超时，下游继续浪费资源请求的情况。

    - 这个传递的超时时间一般是没有考虑网络耗时或不同服务器的时钟不一致的，所以会存在一定的偏差。
    - 超时策略的选择：剩余资源 = 资源容量 - QPS 单次请求消耗资源请求持续时长 – 资源释放所需时长


        |      | 固定超时                                         | EMA动态超时                  |
        |------|--------------------------------------------------|------------------------------|
        | 优点 | 稳定                                             | 可以根据耗时动态调整超时时间 |
        | 缺点 | 如果某个服务一直出问题超时，会导致服务吞吐量降低 | 服务有损                     |

        - 关键路径选择固定超时；
        - 非关键路径开启 EMA 动态超时，防止一直出问题导致服务耗时增加、吞吐量降低。

    - 超时时间的选择
        - 合理的设置超时可以减少服务资源消耗、避免长时间阻塞、降低服务过载的概率；
        - 超时时间过长容易引起降级失效、系统崩溃；
        - 超时时间过短因⽹络抖动⽽告警频繁，造成服务不稳定。

    - 如何选择合适的超时阈值？超时时间选择需要考虑的几个点：
        - 被调服务的重要性；
        - 被调服务的耗时 P99、P95、P50、平均值；
        - 网络波动；
        - 资源消耗；
        - 用户体验。

- 限流：包括客户端和服务端限流，确保系统在高负载下仍能稳定运行

    - 在客户端限流中，由于请求方和被请求方的关系明确，通常采用较为简单的限流策略，如结合分布式限流和固定的限流阈值。

    - 客户端的限流阈值可被视作被调用方对主调方的配额。

    - 合理设定限流阈值的方法包括：
        - 容量评估：通过单机压测确定服务的单机容量模型，并与下游服务协商以了解他们的限流阈值
        - 容量规划：根据日常运行、运营活动和节假日等不同场景，提前进行容量评估和规划
        - 全链路压测：通过模拟真实场景的压测，评估现有限流值的合理性

    - 在限流算法方面，大家也都已经耳熟能详。像滑动窗口、漏桶和令牌桶均是常用的限流算法。

        - 这些算法各有特点，能有效管理客户端的请求流量，保障系统的稳定运行。

        - 这里笔者简单梳理了一张常用的限流算法的思维导图，主要阐述每个算法的局限性，需要根据实际应用场景选择合适的算法：
            ![image](./Pictures/soft-architecture/流量治理-限流-限流算法.avif)

    - 服务端限流：在通过主动丢弃或延迟处理部分请求，以应对系统过载的情况。

    - 服务端限流实现的两个关键点：

        - 1.如何判断系统是否过载
            - 常用的判断依据包括：
            - 资源使用率；
            - 请求成功率；
            - 响应时间；
            - 请求排队时间，

        - 2.过载时如何选择要丢弃的请求
            - 常用的判断依据包括：
                - 按照主调方（客户端）的重要性来划分优先级；
                - 根据用户的重要性进行区分。

        - 关于服务端限流在业界内的实践应用，笔者这里整理了两个示例：

            - 开源的 Sentinel 采用类似 TCP BBR 的限流方法。它基于利特尔法则，计算时间窗口内的最大成功请求数 （MaxPass） 和最小响应时间（MinRt）。当 CPU 使用率超过 80% 时，根据 MaxPass 和 MinRt 计算窗口内理论上可以通过的最大请求量，进而确定每秒的最大请求数。如果当前处理中的请求数超过此计算值，则进行请求丢弃。

            - 微信后台则使用请求的平均排队时间作为系统过载的判断标准。当平均等待时间超过 20 毫秒时，它会以一定的降速因子来过滤部分请求。相反，如果判断平均等待时间低于 20 毫秒，则会逐渐提高请求的通过率。这种“快速降低，缓慢提升”的策略有助于防止服务的大幅波动。

### 单元化架构

#### [腾讯技术工程：腾讯云单元化架构体系介绍](https://mp.weixin.qq.com/s/q8N2N0aMzaANj0Hh5Zkqaw)

- 希望在未来几年大规模金融核心系统转型的浪潮中，能帮助一线架构师更好地理解单元化架构，进一步巩固加强腾讯云在金融核心领域取得的成果，做好技术与专家储备。

- 自2018年以来，受“华为、中兴事件”影响，我国科技受制于人的现状对国家稳定和经济发展都提出了严峻考验。目前我国IT架构体系严重依赖国外产品，金融行业尤其明显。大部分传统银行的关键账务系统都架设在IBM的大型机、小型机之上，数据库使用Oracle及DB2，存储采用EMC。在美国不断加大对我国技术封锁背景下，银行IT产业自主可控的必要性和紧迫性凸显。

- 大型银行对其核心系统的性能和稳定性要求之苛刻可谓求全责备，故银行的传统核心通常都采用IOE的技术架构。

    - 当传统核心往分布式技术架构转型的过程中充满了挑战，其中，单元化技术架构是目前所有大型银行都会在其新一代核心系统中采用的主流架构体系。

- 本文将从技术架构发展历程开始，一步步介绍每个阶段是如何演变？为什么到微服务阶段还不足以满足大型银行系统的要求？单元化架构与微服务架构的差异？以及腾讯云的单元化解决方案。
    - 微服务架构和单元化架构并不冲突，单元化是微服务架构的能力增强。

##### 技术架构发展历程

- 1.单体架构：集中式单体架构，程序和数据库都在一台主机上面。
    ![image](./Pictures/soft-architecture/单体.avif)

- 2.应用与数据分离：集中式架构在业务高峰时，由于程序和数据库部署在一台服务器上很容易就出现资源争抢问题，所以第一步就是把程序和数据库分开部署。
    ![image](./Pictures/soft-architecture/应用与数据分离.avif)

- 3.应用集群部署：随着业务量的增大，下一个问题便是应用侧的瓶颈。这块除了应用程序内部的性能调优外，从架构层面可以采用集群化部署模式，将大量的业务流量通过负载均衡服务来分流到多台应用服务器上处理。常见的负载均衡有F5，Nginx和云上的各种XLB服务。
    - 这个阶段的架构已经可以具备一定的横向扩容能力，需要注意的是应用需要实现“无状态”化，避免有状态数据存在本地。
    ![image](./Pictures/soft-architecture/应用集群部署.avif)

- 4.读写分离
    - 当应用侧可以实现横向扩容之后，逐渐对服务器垂直扩容的需求开始减少，因为垂直扩容的边际成本很高，收益却越来越小，大家更愿意通过扩容标准服务器来应对高并发。
    - 随着应用层实现横向扩容后，当业务进入到下一个阶段，压力又会回到数据库这边。应用横向扩容，而数据库还是单体。这个时候就需要分析当前系统的读写比。大多数系统的读写交易比是8:2，读多写少的场景可以考虑使用读写分离模式。开启数据库的主从复制能力，并将写交易路由到主库，读交易路由到从库。
    - 我们可以设置多个从库来负载相对较多的读交易，主库与从库间通过数据库的数据复制能力来保证一致性。
    ![image](./Pictures/soft-architecture/读写分离.avif)

- 5.前后端分离

    - 前端技术迭代会逐渐增快，前端技术栈也日益增多（H5/IOS/Android/小程序）。为了让整个研发团队分工更加明晰，系统迭代更加顺滑，前后端分离是趋势。通过前后工程的分离，以开放接口进行交互，实现前后端独立迭代与演进。

    ![image](./Pictures/soft-architecture/前后端分离.avif)

- 6.NOSQL运用

    - 在能承接当前业务量的情况下，从优化角度引入Redis、MongoDB等NoSQL中间件。Redis具备很高的读写QPS，可以有效提升系统整体性能，在秒杀、热点数据查询、数据缓存场景中运用广泛。
    ![image](./Pictures/soft-architecture/NOSQL运用.avif)

- 7.数据垂直切分
    - 随着业务的持续增长，主库已经难以支撑所有的写请求，这个阶段优先需要做的是数据库的垂直切分。即按领域把"产品数据"、"订单数据"、"用户数据"拆到不同的数据库中，这样写交易就被按照各自的业务量分流到不同的库上。
    - 需要注意的是这种拆分可能会引起分布式事务产生。如果存在一次事务跨了多个业务域的数据库，那就需要考虑多个数据库间的数据一致性问题。
        - 我们可以借助分布式数据库的产品能力解决，或在应用层引入分布式事务框架解决，也可以通过消息中间件实现最终一致性，取决于不同场景下的业务接受度。
    ![image](./Pictures/soft-architecture/数据垂直切分运用.avif)

- 8.应用垂直切分
    - 数据已经按领域切分而应用还没有。这就显得有点怪异，每个应用都需要连到3个库上才能操作，这显然是不合理的。数据库的连接数和应用后期的扩容都会存在问题。通常情况下2.7数据拆分后会同步考虑2.8的应用拆分。
    - 到这个阶段，最初的系统已经被按照不同业务领域，从设计到落地都实现了解耦。基于这种架构已经可以初步支持不同模块的独立迭代与演进，很贴近我们现在所了解的“微服务”架构。

    - “分而治之”的架构思想在分布式领域得到广泛运用，小到各种排序算法，大到MapReduce、单元化架构等等。
    ![image](./Pictures/soft-architecture/应用垂直切分.avif)

- 9.SOA架构

    - 刚我们把一个巨石应用拆分为多个子应用时，随之而来的问题是这几个子应用间的通讯问题。在微服务架构之前，银行普遍采用消息总线来做多个系统间的"衔接"。它就像一根通道，集成不同的应用、不同的协议，承担消息解释与路由职责，实现互联互通。属于早期分布式的经典架构。

    - 微服务架构和SOA架构同样都是面向服务的架构设计。微服务更强调了去中心化思想，而ESB作为全行的消息总线在一定程度上是形成了单点和瓶颈。微服务架构就是从本质上去掉了ESB，通过注册中心来实现服务发现能力。以发布和订阅服务目录的方式，让应用间通过服务目录来实现点对点的直连通讯。

    ![image](./Pictures/soft-architecture/SOA架构.avif)

- 10.聚合查询库

    - 在按领域拆分之后，另一个麻烦的问题出现了。原业务中那部分跨多业务表的复杂查询能力由于底层库表的拆分导致无法运行，这时便需要引入聚合查询技术。它和分布式事务一样，是大型金融业务系统在集中式往分布式架构演进的过程中必然会遇到的一种场景。
        - 比较好的方法是从企业架构角度将查询业务从联机系统中剥离，即OLTP和OLAP业务分离，因为两种业务所需要的底层技术栈截然不同。

    - 聚合查询指的是一种能力需求，它可以由不同的技术来实现。
        - 比如采用ElasticSearch来实现搜索引擎
        - 也可以采用Flink实现流批一体的数据处理与分析引擎，这更大程度上取决于企业架构整体的规划。-
        - 在银行的实际案例中，规划层面的确会把查询类业务从核心系统剥离到大数据平台处理。但往往会由于大数据平台或周边系统的技术能力或因为各种现状无法很好地承接核心的查询业务。落地时更多的是一种妥协方案，比如核心处理3天或7天内的查询请求，大于3天或7天的请求由大数据平台查询。这里也体现出新核心系统的建设不仅仅是换一颗心脏，而是要从企业架构的整体角度，结合实际情况对周边及配套系统同步进行评估与升级改造。

    ![image](./Pictures/soft-architecture/聚合查询库.avif)

- 11.数据水平切分

    - 在系统按领域切分之后，如果某一领域内的业务量依然大到主库无法承载。那么接下去就需要在垂直拆分的数据库上再进行一次水平拆分。水平拆分可以将落到一台主库的压力分摊到多个分库上。这个阶段设计时需要注意数据路由和扩容场景：

        - 1.数据一旦被按照一个维度进行了分库，那应用在请求时就需要在请求中带上该维度的值，进行路由判断，识别该数据在哪个分库上；

        - 2.其次是扩容问题，假如当前为10个分库，一开始的路由算法为 hash(客户号)%10，后面扩容到12个分库，那计算规则就要变成 hash(客户号)%12。这样，所有分库上的数据都需要按照新的路由规则重新计算并进行数据迁移，这个过程称为“数据重分布”，成本和代价都很高。建议在设计阶段提前与各方约定好路由规则和扩容策略。

- 12.微服务架构
    ![image](./Pictures/soft-architecture/微服务架构.avif)

##### 大型微服务系统面临的问题

- 目前绝大多数银行客户来讲，两地三中心是未来的标准架构。即：同城为双活，异地为灾备，一共三个数据中心。

    - “同城双活”从架构角度解释：一个系统分布在同城的两个数据中心，两边都能同时接收业务请求并进行处理。
    - 假如在与客户的数据库团队交流，这里就会出现一个讨论场景：他们可能会问数据库如何双活？没错，对于同一份数据副本没有办法实现两边双活。但从整个系统角度，并不妨碍它成为双活架构。

    ![image](./Pictures/soft-architecture/某银行核心系统同城双活架构图.avif)

- 流量从两个数据中心进入，到微服务网关层时，网关通过注册中心获取目标服务的可用地址，基于软负载策略发起点对点调用。应用在处理数据时，由于数据库主本是单边活，所以同城中心的应用需要跨中心访问到另一个中心进行数据操作。

- 分布式数据库一样也是架构层面实现数据多点可用，而并非是一份数据在多点同时多活。以TDSQL为例，我们可以指定一些库的主本在A中心，一些库的主本在B中心。这些库都隶属于一个分布式数据库实例，在AB两个中心同时提供服务，以此实现"整体上的双活"。

    - 在上图的案例中，账务库和公共库的主本在A中心，而历史库的主本在B中心，对应用是一个分布式数据库实例。

- 但在极端情况下，这类架构可能会存在两个问题：

    - 1.应用服务之间的横向流量；
    - 2.应用与数据库之间的横向流量；

- 以目前的网络基础设施情况，同城内多个机房间的网络情况在大部分情况下稳定性和性能都是有保障的，50公里的延时一般都在1ms以下。这对于跨中心访问来说问题并不大，足以应对大部分银行客户的要求。一般城商行的日常TPS可能就只有几十，峰值可能也就几百到一千左右。横向流量对网络带宽压力并不大，抖动和时延对业务的影响也较小。

    - 可对于大型国有银行和头部股份制银行来说，横向流量的问题则会被放大。这类行的日常TPS大多上千，活动峰值可能接近1W。每一笔交易进入，核心平均需要进行50-80次的数据库操作，所以在应用到数据库这一层横向流量会被放大数倍。其次，在应用层微服务之间的访问也会出现横向流量。因为默认的SpringCloud体系中没有提供就近访问能力，需要自行在负载策略中增加规则来实现同中心优先调用，否则就会有流量被调度到另一个中心，而每次服务间的调用都会面临反复来回调度的情况，这部分无谓的消耗是完全应该避免的。

    - 因此，在大型金融系统进行分布式转型时，是得考虑其系统内部在实现微服务化和数据分布式化之后，大量横向流量在两个机房间穿梭的问题，这对基础设施的要求是很高的。从设计角度出发，我们并不应该把宝都压在基础设施的稳定性上，这显然不可靠。单元化架构的出现也正因如此，它可以很好地减少数据中心间的横向流量，进一步提升微服务架构的性能与稳定性。

##### 腾讯云单元化架构体系

- 随着银行技术架构逐渐迈入分布式领域，单元化架构开始流行。

- 早在2015年微众银行首次提出并落地了按DCN（数据中心单元化）的设计理念，按照业务和用户维度进行水平拆分，将银行核心账户体系、核心客户体系、核心业务处理等打包在一个DCN，业务流量经全局路由转发至DCN，成为国内银行业核心系统单元化架构的首个案例。

- 国外银行没有像国内如此大规模的用户群体，很多国家的核心系统用户量仅仅和我们一个城商行的用户量差不多。所以，19年国有大行在启动新核心分布式改造时，全球范围内都没有可参考案例。经过这几年沉淀，我们联合ISV已经可以把整套方法论与交付工艺进行同业复制。

###### 什么是单元化架构

- 遵循分布式系统“分而治之”的设计思想，我们可以将一个系统分为多个"标准处理单元"。每个处理单元由一组计算资源与一部分数据资源组成。每个处理单元的计算容量保持基本一致。如图4.1所示，采用这种模式，我们可以把一个大型系统拆分为若干个单元。单元内实现闭环处理，单元之间互不影响，减少了故障半径的同时，还大大降低了无效的横向流量，提升了性能与稳定性。

    ![image](./Pictures/soft-architecture/单元化架构.avif)

###### 与微服务架构的区别

- 微服务架构和单元化架构并不冲突，单元化是微服务架构的能力增强。

    - 微服务架构更注重利用微服务的设计理念来解耦应用系统，以及利用微服务技术手段来重建系统内外的互联和治理模式。
    - 单元化架构更侧重整体性规划，它在微服务体系之上加强了标准化治理，包括标准化扩容、标准化路由，尤其对跨中心流量做了治理，让微服务中的负载调用变得更加有序。

    - 微服务像是在微观层面把功能体系建立起来，单元化则更像是在宏观层面把架构体系完善起来，两者相辅相成，相互促进。

- 其次，没有单元化，微服务一样可以运行起来，因为底层的功能机制已建立，大部分能力都能在这套机制下运转起来。但以SpringCloud为标准的微服务体系也并非万能，和大多数开源框架一样，其只针对微服务落地中的关键共性问题提供解决方案，在方案完整性和运维运营层面覆盖是不足的。在异地多活的支持和分布式事务等方面使用方更需要提前规划，做好相应解决方案。

- 单元化架构通过合理的数据切分，把计算与数据进行绑定处理，来控制业务流量单元内闭环，提供了异地多活架构的基础条件。同时提供了大规模系统的标准化管理、扩容、灰度等方案，其更像是一种架构设计思想，而非一种具体技术。

    - 这种架构思想也并非只能运用于微服务上，只要有底层原子能力的支撑，也是可以被运用于其他架构上的，只是微服务恰巧提供了这种底层原子能力。

- 客户该如何选择？

    - 微服务架构相关方案的成熟度高，建设难度和成本都相对较低，建设过程中客户可以更多地关注业务和应用架构的设计，比较适合体量中等和初创的客户。

    - 单元化架构相关方案难度较大，不仅需要产品支持单元化能力同时还需围绕单元化的应用场景做一部分制定化开发。采用这个方案的客户更关注在自主可控能力，避免绑定。建设难度和成本都相对更高，更适合体量较大的客户，或者追求架构先进性的客户。

###### 单元化架构优势

- 1.解决大型分布式系统中集中式数据库的连接数问题

    - 在分布式数据库还未成熟时，应对大型分布式系统中集中式数据库的连接数瓶颈问题而采用的一种处理方式。因为数据库连接数的增长会消耗数据库物理服务器的内存，而对于集中式数据库来讲，单台服务器的物理内存是有上限的。

    - 如图4.3.1所示，当分布式系统在进行水平扩容时，集中式数据库便会成为整个系统扩容的瓶颈点。

        ![image](./Pictures/soft-architecture/应用扩容与数据库连接压力.avif)

    - 解决方法1：通过采用计算与数据绑定处理的方式，来解决应用在不断扩容时对单一数据库产生的连接数压力。


    - 解决方法2：分布式数据库来解决，通过可扩容的proxy层来收敛上层连接，并在数据库内部实现数据库实例的扩容。对于中小客户是一个很好的选择。

    - 但也有一些大型银行，如中行、招行、邮储等依然采用了集中式数据库实例来实现其新一代核心系统。他们更关注其自主可控性，通过单元化架构自研实现数据层路由与数据分片能力，这样就不会对分布式数据库产品的特定能力产生依赖。

- 2.跨数据中心交互的性能与稳定性问题
    - 问题：当这在两个数据中心距离超过100公里时，时延问题将被放大，导致系统内部交互出现频繁超时、中断，从而引起一系列系统性问题。
    - 解决方法：单元化的设计思想可以通过计算与数据绑定的方式让流量在单元内部闭环，减少跨单元交互，增加微服务系统的稳定性与性能。
    ![image](./Pictures/soft-architecture/两种架构对跨中心横向流量的影响.avif)

- 3.标准化扩容与运维容灾问题

    - 每个单元计算容量与所处理的数据量大致相等，可作为统一的扩容单位。避免微服务使用过程中出现随机的扩容与不统一的运维动作。通过提炼不同的单元特征，可定制出针对不同类型单元的标准化运维动作和容灾方案。

###### 单元化架构的挑战

- 在《云上核心转型最佳实践》一文中有提到，大型金融核心系统分布式设计时需要考虑的六大要点。其中，有三点与单元化架构设计紧密相关，分别是：数据切分策略、技术架构策略和业务连续性。从这几点可以推导落地单元化时会面临的几大问题：

- 1.海量映射关系维护
    - 前面讲到单元化架构主要应用在大型分布式系统中，我们假设目标系统用户约3亿，按照设计要点一拟定如下策略：
        - 1.切分维度：采用客户号作为分片键，即将数据以客户维度放到各单元的数据分片中
        - 2.分布规则：采用客户号Hash方式分散存储
        - 3.扩容策略：采用TDSQL自动扩容能力
        - 4.容量评估：单分片存放500万客户数据，约64个数据分片。

    - 在这个策略前提下，数据分片、路由、扩容、容灾均可交由TDSQL实现，业务侧仅仅需要提供客户号给TDSQL即可。

    - 但现实往往并没有这么简单，我们希望通过客户号来串接业务，这样会让架构设计更为简单。可现状是大多数银行系统并没有客户号设计，而是采用客户三要素（姓名、身份证、银行卡号）或其他存折号、汇款号进行交易。

    - 所以，有两种方案：
        - 1.关联系统跟着核心做客户号改造
        - 2.在新核心前面做映射关系转换
        - 显然，第二种方案从安全可控角度更具落地性。那么假设一个客户有10个业务要素，3亿客户就有30亿映射关系。好在是相对简单的K,V存储，落地时可以采用缓存集群。较为复杂的点是：任何一个客户做类似开销户的动作，都得及时地、可靠地更新到映射关系缓存中，否则就可能导致后续交易的失败。由于是在核心的入口处发生的映射，其可靠性直接影响着整个核心系统的可用性。

- 2.流量打标与标记路由

    - 流量打标是实现单元化的核心能力之一。

    - 首先，应用实例在启动时就需要带上单元标记到注册中心注册
    - 其次负载均衡时需要优先按标记过滤服务目录，再执行负载策略。
        - 在设计规划阶段，就要设计好单元标签等相关字段，注册中心也需要支持元数据注册能力。通过扩展负载均衡组件来解析遍历约定好的标签来过滤实例。
    - 当请求进入网关时，先通过映射缓存找到其所属客户号，再按照客户号进行Hash计算得出其所属分片，进而得到所属单元信息，再以单元号作为标记进行路由，来实现在指定单元内的调用，完成流量在单元内部闭环。

- 3.路由一致性

    - 单元化架构的目标是实现流量在一个单元内部闭环，涉及到数据切分是否合理，从业务角度是否能让一次请求在一个数据分片内完成。
    - 其次是一次请求中发生多次路由时，能否对同一个客户的路由结果前后保持一致。
        - 在技术层面可能存在发生路由的有网关层、数据访问层，还有业务层（比如转账业务：完成当前账号取款后需要对对手账户的单元信息发起存款操作，如果两个客户恰巧没有被分在同一单元）。
        - 所以，这三个层面的路由元数据、路由算法都得保持一致。如果数据访问层是由TDSQL实现，那么微服务层面的路由得和TDSQL-Proxy层的路由保持一致。当发生扩容时，TDSQL的分片数也必须和单元数保持一致，才能实现路由元数据的一致。

- 4.中间件的单元化

    - 在一次交易过程中，除了微服务框架与数据库，比如会涉及其它中间件。这里需要同步考虑Redis、MQ、任务调度中心的单元化能力。
    - 中间件可以采用逻辑隔离
        - Redis可以通过封装客户端使用单元标记进行访问隔离
        - MQ可以通过把类似Tag的标签能力使用到单元隔离上
    - 任务调度中心则需要先根据客户计算其单元，再根据单元信息发起调度。需要遵循单元标记这个设计逻辑，各组件通过自身的标签能力，或者修改部分逻辑来接入单元化体系。

- 5.保障业务连续性

    - 为了实现路由一致性，我们会把缓存映射和路由计算都封装到一个组件中，称为：全局路由组件。
        - 当网关层调用全局路由进行计算时，一旦出现任何问题都将影响后续的整个链路。所有和路由相关的操作都需要考虑对应的兜底机制，比如缓存更新失败转异步，又比如寻址失败转随机分发机制等。

    - 在高可用方面除了要考虑实例级、机房级、地域级容灾之外，还需要增加对单元级高可用的设计。并将单元灾备关系及属性在系统上下文中保持传递，确保在任何路由环节都能在当前单元故障时找到容灾单元。

- 6.单元化的可观测性
    - 为了更好地维护这套机制，需要在传统监控中加入跨单元和跨机房调用的路由情况。通过采集相关埋点数据，对比分析后做可视化展现。包括将单元化的观测性接入全链路体系中，形成一体化监控。

###### 腾讯云单元化架构TCUA

- 腾讯通过参与微众银行、国有大行和头部商业银行等各大核心系统设计，从中归纳提炼形成符合银行核心系统特点的单元化架构体系，TCUA(Tencent Cloud Unitization Architecture)。

    ![image](./Pictures/soft-architecture/腾讯云单元化架构(TCUA).avif)

- 腾讯单元化架构(TCUA)是一种针对金融分布式核心系统技术架构的分层次、分领域、体系化的架构思想：

    - 接入单元（ADU）：Access Deployment Unit，负责接收流量，识别流量，转发流量。识别后的流量被转发至应用层对应的单元处理。

    - 标准单元（SDU）：Standard Deployment Unit，SDU默认按照客户维度拆分，单客户交易实现单元内闭环处理。跨客户交易会存在一定比例的跨单元协同处理。数据默认被分为64份，被均匀放置在若干个单元内。可通过灰度/旁路机制将指定标签的客户放置在旁路单元实现生产旁路与灰度运行或验证。

    - 本地单元（LDU）：Local Deployment Unit，用于存放无法按客户维度拆分的服务，如：核算、产品定价、机构柜员等。LDU的服务均为单数据中心集群，应用于单数据中心架构。

    - 同城单元（RDU）：Region Deployment Unit，用于存放无法按客户维度拆分的服务，如：核算、产品定价、机构柜员等。RDU的服务均为地域级服务集群，应用于同城多活架构。

    - 全局单元（GDU）：Global Deployment Unit，用于存放无法按客户维度拆分的服务，如：核算、产品定价、机构柜员等。GDU的服务为全国性服务集群，应用于异地多活架构。

    - 旁路单元（BDU）：Bypass Deployment Unit，又称灰度单元。用于生产的旁路或灰度验证，有独立的数据分片，一般用生产测试数据，或指定范围的生产验证（常用于银行内部员工）。

    - 在规划时，需要根据客户实际情况进行选择。除了SDU是必选，其他单元类型均为可选。比如LDU/RDU/GDU，只用选择其中一个到两个。如果客户没有灰度或旁路需求，也就不用规划BDU。单元化的架构体系是用于在进行单元化设计时，从设计框架层面提供指导与参考的作用。

- 1.接入层路由设计

    - 接入层架构主要依托于TSF微服务框架Gateway网关实现单元化路由。

    - TSF单元化管理平台(TCUA)中，主要包括了配置单元路由规则、灰度路由规则、标签路由、单元容灾等能力。Gateway通过获取路由规则和元数据对不同单元内的服务进行调用。

        - TSF不负责处理业务数据，即上文中提到的客户映射要素。如下图所示，应用厂商需要基于TSF的SPI自行扩展来获取客户号。

    ![image](./Pictures/soft-architecture/接入层路由设计.avif)

- 2.数据层路由设计

    - 数据层架构主要依托于TDSQL分布式数据库实现数据层的单元能力。主要包括数据分片、数据路由、自动扩容、容灾切换等能力。

    ![image](./Pictures/soft-architecture/数据层单元化路由.avif)

    - TSF的网关层路由与TDSQL的Proxy层路由必须保持一致。单元扩容时，在TSF先执行单元扩容规划，其次触发TDSQL分片扩容，完成后同步更新TCUA中的路由元数据，实现整体路由一致性。

- 3.应用层路由设计

    - 应用层路由设计主要依托于TSF-Feign实现就近调用与跨单元调用。同样，业务在调用Feign接口时需要传入客户号，Feign与Gateway一样到单元化平台TCUA获得路由规则和元数据后，对目标单元发起调用，从而实现与网关和数据层的路由一致性。

    ![image](./Pictures/soft-architecture/应用层单元化路由.avif)

- 4.MQ单元化设计
    - MQ的路由单元化能力主要依托于各产品自身的Tag原子能力。在TDMQ中，单独为单元化设计了一个独立的标记。消息需要在消息头中设置对应单元标记，默认为本单元标记，来实现单元内外的消息投递与消费。
    - 如果目标单元不是本单元，则TDMQ-Router组件会识别并将消息复制到目标单元，由对方单元的Comsumer进行消费。和使用普通MQ一样，业务侧需要具备消息防重或接口幂等的设计。
    ![image](./Pictures/soft-architecture/MQ单元化消息.avif)

- 5.灰度(旁路)单元设计

    - 灰度单元的本质是"特殊的路由规则"，即在一般的单元规则之前，优先检查”灰度单元规则“。
    - 例子：我们约定所有本行的行员为灰度群体，将其存入灰度表，那么请求中的客户号只要命中灰度表，就触发到灰度单元的路由。
    - 一旦执行灰度规则，则不再进行一般的单元路由规则。在TSF中，对灰度单元的管理有独立的规则配置。
    - 需要注意的是，灰度单元需要业务提前规划灰度维度和灰度方式，提前做好数据迁移。同时，应用层还应具备客户锁定能力，在数据迁移时锁定客户，不允许其进行业务交易。在迁移完成后，更新TCUA路由信息成功后，再接触锁定。保障前后的业务一致性。
    ![image](./Pictures/soft-architecture/灰度单元通用方案.avif)

- 6.单元扩容设计

    - 单元扩容，也叫单元分裂过程，由一个单元变为两个单元。核心点是总分片数(数据分片)不变，单元和分片之间是映射关系，一个单元包含若干分片。

    - 总分片数为64，假设初始4个单元，每个单元各16个分片，分布在AB两个数据中心。扩容到二阶段时，单元数量增加到8，单元内分片数量缩减到8，同时还新增了两个数据中心C和D。分为8个单元后，遵循开闭原则，原来1-4单元和数据中心的映射关系保持不变，只增加新增单元与新数据中心的映射关系。

    ![image](./Pictures/soft-architecture/单元扩容逻辑.avif)

- 7.单元容灾设计
    - 在TCUA单元管理平台中配置“容灾单元”，来建立两个单元间的容灾关系。当其中一方单元出现故障时，通过更新故障单元状态来识别并指向其容灾单元ID，从而实现路由的调整。代表容灾关系，连接了两个互为备份的单元。
    - 容灾关系的配置，与扩容关系一样，建议在设计之初就做好规划，尽量减少关系的变更，近对新增的单元做容灾关系配置，对存量单元关系保持不动。便于简化运维管理，减低变更成本和故障率。
    ![image](./Pictures/soft-architecture/单元容灾逻辑.avif)

- 8.全局单元化架构

    - 以上几点是TCUA对于单个系统单元化设计要点，其改善了单个系统内部跨多中心后的无效横向流量的治理。但在实际场景中，一次交易是先从渠道系统进入中台系统，再进到核心系统。如果仅仅是核心系统做了单元化改造，从整体链路上其效果并非最优，跨系统调用时一样会出现随机和无序的流量。为了解决系统间流量治理问题，TCUA提出了全局单元化概念。

    - 在原来某国有大行的架构中，单元的概念小于系统，一个系统可以被拆分为多个单元，这是大行目前主流的单元化落地形式。而此次在四川省某商业银行的单元化架构中，TSF首次将全局单元的概念落地。将单元提升到全局维度，用单元来包含系统。可以实现全行级端到端的单元化能力，用来解决系统间调用的跨中心流量治理问题。

    - 全局单元化架构对业务特征有一定要求：进行全局单元化改造的系统，需要保持同样的数据分片维度、同等的单元数量、采用全局统一路由算法。比如：核心系统采用客户号维度切分，共分了8个单元，采用Hash散列计算路由。那么其它渠道系统、中台系统是否也符合这种策略是需要调研的。有一些管理类、分析类系统就无法按照此模式设计，像这类系统通常也不在关键交易链路中，可以放到RDU中部署。

    ![image](./Pictures/soft-architecture/全局单元化架构.avif)

### 度量方式

- 要以业务价值为导向，而不是研发人员产出为导向

    - 错误例子：以代码量、功能数

    - 正确例子：前置时间（lead time）、周期时间（cycle time）。这些用户推崇的整体质量交付。

### 工程

#### 携程

- [腾讯云社区：计算压力倍增，携程度假起价引擎架构演变](https://cloud.tencent.com/developer/inventory/334/article/1625083)

    - 任务队列：旅游产品不像单品售卖，产品价格是由多种资源组成（机票、酒店、火、X等）,任意一项资源价格、库存发生变化，都会导致整包价改变，变量太多。

        - 任务队列在算完机票资源之后，再算酒店，算完酒店后进行单选项资源处理，最终汇总出价格。

        - 1.0版本：

            - 任务队列：

                - 用MySQL做任务队列，并且针对每个任务队列同步到sqlserver。分了2个库，64张表

                - 之后用Redis的根据资源分成多队列，代替mysql

        - 2.0版本：

            - 任务队列：Kafka代替redis

            - 任务生成：我们引入了分布式计算框架Spark，从原有的.net代码体系切换到Java

            - 线路聚合：

                - 航线1北京->上海和航线2上海->北京->上海，进行聚合，从而减少请求

        - 3.0版本：

            - 任务生成：首先是消息对产品进行解析，拿到产品的出发地、出发日期，再结合其他的信息，把这些相关的信息写到分布式文件系统里面，再通过Spark进行不同资源的聚合排序，然后再把它写回到分布式文件系统里面，接着通过某一个job去把这些信息取出来，然后把消息发送出去。

                - HDFS分布式文件系统把任务信息分发到下一步的这一个步骤简化了，在消息发送的时候，直接通过Spark进行消息发送，比如它里面可能有几百个节点，我们这几百个节点同时发送这个消息

            - 数据库：HBase替换MySQL

            - 依然存在的瓶颈问题：价格库存依赖外部的资源。外部资源的变化对系统是黑盒，只能依赖API离线计算，API的调用量也会有限制等。也就是活包

        - 缓存预热：对外的价格日历班期查询是有用到缓存的，整个缓存我们相当于是7×24小时不间断一直在写入，所以其实也不怎么存在预热的问题。

- [腾讯云社区：日均20亿流量：携程机票查询系统的架构升级](https://cloud.tencent.com/developer/article/1624858)

    - 三个独立的数据中心

    - SpringCloud + K8s + AWS云服务

    - AI的应用：

        - 反爬虫：屏蔽掉9%的流量

        - 查询筛选：在聚合服务中找出价值最高实际用户，然后把他们的请求发到引擎当中。对于一些实际价值没有那么高的，更多的是用缓存

        - 智能设置TTL生命周期：TTL与业务密切相关的

            - 缓存一致性例子：刚刚看到一个低价机票，点进去就没有了。这种情况出现的原因可能是什么呢？大家知道，航空公司的低价舱位票，一次可能就只放出来几张，如果是热门航线，可能同时有几百人在查询。所以，几百人都可能会看到这几张票，它就会出现在缓存里边。如果已经有10个人去订了票，其他人看到缓存再点进去，运价就已经失效了。

            - 解决方法：
                - 1.缓存超过固定阈值就强行清除。
                - 2.动态刷新：在达到固定阈值之前，有用户查询就刷新缓存


        ![image](./Pictures/soft-architecture/携程-机票查询-AI应用.avif)

    - 缓存架构：

        - 一级缓存是最终的结果，二级缓存是中间结果

            - 聚合服务需要多个返回结果的话，那么很大程度上都是先读一级缓存，一级缓存没有命中的话，再从二级缓存里面去读中间结果

        ![image](./Pictures/soft-architecture/携程-机票查询-缓存架构.avif)

        - 一级缓存：

            - 使用了Redis
            - 固定的TTL，一般低于5分钟的，一些场景下可能只有几十秒

        - 二级缓存：

            - 一开始使用MongoDB，后来改为Redis
            - 通过AI设定的TTL，使得命中率提升了27%

        - 缓存预热：一个分布式的，可能有一小部分节点，比如要下线或者什么，但是对整个缓存机制来说影响很小，然后这一部分请求又分散到我们的多个服务器上，几乎不会产生太大的抖动的。

    - 负载均衡Pooling：我们有一些计算非常密集的引擎，存在一些耗时长，耗费CPU资源比较多的子任务，同时这些子任务中可能夹杂着一些实时请求，所以这些任务可能会留在线程里边，阻塞整个流程。

        - 把子任务放在queue里，将节点作为worker，总是动态的去取，每次只取一个，计算完了要么把结果返回，要么把中间结果再放回queue。

            - queue基于Redis队列，有的键值里加入了IP地址

                - 为什么不使用消息队列？由于它存在很明显的顺序性，不能够基于键值去读到你所写的，比如你发送了一个子任务，这时候你要定时去拿这个结果，但是你基于其他的消息队列或者内存队列是没法拿到的

            - 如果有任何实时的外部调用，我们就可以把它分成多次，放进queue进行task的整个提交执行和应用结果的返回。

        ![image](./Pictures/soft-architecture/携程-机票查询-负载均衡.avif)

        - Pooling的过载保护：

            - 如果没有过载保护，很容易就会发生滚雪球效应，queue里面的任务越来越多，当系统取到一个任务的时候，实际上它的原请求可能早就已经timeout了。

            - 当流量实在太高的情况下，把等待时间超过某一个阈值的请求全都扔掉。

            ![image](./Pictures/soft-architecture/携程-机票查询-过载保护.avif)

# 并发架构

## 异步架构

- [dbaplus社群：一次线上高并发事故，我顿悟了异步的精髓……](https://mp.weixin.qq.com/s/A9BmADv5TweBjYvv81zOLw)

- 业务场景

    - 老师登录教研平台，会看到课程列表，点击课程后，课程会以视频的形式展现出来。

    ![image](./Pictures/soft-architecture/老师登录教研平台.avif)

    - 访问课程详情页面，包含两个核心动作：

        - 1.读取课程视频信息：从缓存服务器 Redis 获取课程的视频信息 ，返回给前端，前端通过视频组件渲染。

        - 2.写入课程观看行为记录： 当教师观看视频的过程中，浏览器每隔3秒发起请求，教研服务将观看行为记录插入到数据库表中。而且随着用户在线人数越多，写操作的频率也会指数级增长。

    - 上线初期，这种设计运行还算良好，但随着在线用户的增多，系统响应越来越慢，大量线程阻塞在写入视频观看进度表上的 Dao 方法上。

- 首先我们会想到一个非常直观的方案，提升写入数据库的能力。
    - 优化 SQL 语句
    - 提升 MySQL 数据库硬件配置
    - 分库分表

    - 问题：这种方案其实也可以满足我们的需求，但是通过扩容硬件并不便宜，另外写操作可以允许适当延迟和丢失少量数据，那这种方案更显得性价比不足。

- 那么架构优化的方向应该是：“减少写动作的耗时，提升写动作的并发度”， 只有这样才能让系统更顺畅的运行。

    - 于是，我们想到了第二种方案：写请求异步化。
        - 1.线程池模式
        - 2.本地内存 + 定时任务
        - 3.MQ 模式
        - 4.Agent 服务 + MQ 模式

    - 它们的共同特点是：将写操作命令存储在一个池子后，立刻响应给前端，减少写动作的耗时。任务服务异步从池子里获取任务后执行。

- 1.线程池模式

    - 2014年，笔者在艺龙旅行网负责红包系统相关工作。运营系统会调用红包系统给特定用户发送红包，当这些用户登录 app 后，app 端会调用红包系统的激活红包接口 。

        - 激活红包接口是一个写操作，速度也比较快(20毫秒左右)，接口的日请求量在2000万左右。

    - 应用访问高峰期，红包系统会变得不稳定，激活接口经常超时，笔者为了快速解决问题，采取了一个非常粗糙的方案：

        - "控制器收到请求后，将写操作放入到独立的线程池中后，立即返回给前端，而线程池会异步执行激活红包方法"。

        - 当时按照这种粗糙的方法优化后，红包系统非常稳定，再也没有出现接口响应超时的问题。

    - 回到教研的场景，见下图，我们也可以设计类似线程池模式的方案：
        ![image](./Pictures/soft-architecture/线程池模式.avif)

    - 使用线程池模式，需要注意如下几点：
        - 线程数不宜过高，避免占用过多的数据库连接
        - 需要考虑评估线程池队列的大小，以免出现内存溢出的问题

- 2.本地内存 + 定时任务

    - 开源中国统计浏览数的方案非常经典。

    - 用户访问过一次文章、新闻、代码详情页面，访问次数字段加 1 , 在 oschina 上这个操作是异步的，访问的时候只是将数据在内存中保存，每隔固定时间将这些数据写入数据库。
    ![image](./Pictures/soft-architecture/本地内存+定时任务.avif)
    ![image](./Pictures/soft-architecture/本地内存+定时任务-代码.avif)

    - 我们可以借鉴开源中国的方案 ：

        - 控制器接收请求后，观看进度信息存储到本地内存 LinkedBlockingQueue 对象里；
        - 异步线程每隔1分钟从队列里获取数据 ，组装成 List 对象，最后调用 Jdbc batchUpdate 方法批量写入数据库；
        - 批量写入主要是为了提升系统的整体吞吐量，每次批量写入的 List 大小也不宜过大 。
        - 这种方案优点是：不改动原有业务架构，简单易用，性能也高。该方案同样需要考虑内存溢出的风险。

- MQ模式

    - 很多同学们会想到 MQ 模式 ，消息队列最核心的功能是异步和解耦，MQ 模式架构清晰，易于扩展。
        ![image](./Pictures/soft-architecture/MQ模式.avif)

    - 核心流程如下：
        - 控制器接收写请求，将观看视频行为记录转换成消息
        - 教研服务发送消息到 MQ  ，将写操作成功信息返回给前端
        - 消费者服务从 MQ 中获取消息 ，批量操作数据库

    - 这种方案优点是：
        - MQ 本身支持高可用和异步，发送消息效率高 , 也支持批量消费;
        - 消息在 MQ 服务端会持久化，可靠性要比保存在本地内存高；
        - 不过 MQ 模式需要引入新的组件，增加额外的复杂度。

- Agent 服务 + MQ 模式

    - 互联网大厂还有一种常见的异步的方案
        ![image](./Pictures/soft-architecture/Agent服务+MQ模式.avif)

    - 教研服务器上部署 Agent 服务（独立的进程）, 教研服务接收写请求后，将请求按照固定的格式（比如 JSON ）写入到磁盘中，然后给前端返回成功信息。
    - Agent 服务会监听文件变动，将文件内容发送到消息队列 , 消费者服务获取观看行为记录，将其存储到 MySQL 数据库中。
    - 这种方案最大的优点是：架构分层清晰，业务服务不需要引入 MQ 组件。
    - 笔者原来接触过的性能监控平台，或者日志分析平台都使用这种模式。

# 防崩溃
## 容灾架构

- IT企业事故等级

    - 1.一级事故（重大事故）

        - 一级事故通常指对用户数据安全、公司基础设施、核心业务等产生严重影响的事件。一级事故可能导致公司业务受阻、用户流失、财务损失等严重后果，对公司声誉和市场地位造成重大打击。如果事故、故障涉及到业务支付功能都会被定义为一级事故。例如，大规模数据泄露、严重的网络攻击导致系统瘫痪、关键业务服务中断等。

    - 2.二级事故（较大事故）

        - 二级事故通常指对公司的业务运营和用户体验产生较大影响的事件。二级事故可能导致公司的业务受限、用户不满、合规风险增加等。例如，中小规模的数据泄露、部分业务服务中断、系统性能下降等。

    - 3.三级事故（一般事故）

        - 三级事故通常指对公司的业务和用户产生一般影响的事件。三级事故可能对公司的业务和用户产生一定程度的困扰，但通常可以通过较快的应对和处理来控制其影响范围。例如，个别用户数据泄露、局部系统故障、产品安全漏洞等。

    - 4.四级事故（轻微事故）

        - 四级事故通常指对公司的业务和用户产生轻微影响的事件，影响范围较小且较容易处理。四级事故通常可以通过及时处理和解决来避免对公司形象和业务产生较大负面影响。例如，个别用户投诉、产品功能异常等。

- 容灾能力评价指标

    - RPO，是指系统一旦出现故障，允许数据丢失的程度，而对于越重要的系统，要求数据丢失的程度越低，RPO越小。若是数据备份，一般应用一天备份一次，对于较为核心的应用则要求每小时备份一次；若是数据同步，RPO越小，则要求数据同步的延迟也要越低。而低延迟会对生产环境，包括网络带来更高的压力，同样也会带来更高的建设成本。

    - RTO，是指系统出现故障之后，能够允许故障恢复时间的长度。对于越重要的应用，一般要求RTO越小，以尽量降低业务的损失。

    - 右侧图是国家信息委员会定义的信息系统展览恢复的规范，该规范将灾难恢复的能力定义成了1-6六个等级，随着等级越高，对RPO和RTO的要求也越高。以最高的等级6为例，其要求的RTO是数分钟，即应用出现故障时要在分钟级别进行灾难的恢复，RPO等于零，这意味着数据不允许丢失，这是一个较高的标准。
        ![image](./Pictures/soft-architecture/容灾能力评价指标.avif)

### 主流容灾架构对比

- [一文详解云上跨可用区容灾解决方案和异地多活能力建设最佳案例](https://developer.aliyun.com/article/1393861)

![image](./Pictures/soft-architecture/常见故障类型.avif)

- 在实际的企业 IT 事故容灾执行策略中，一般预先制定并定期演练，以便确保容灾系统有效运行。让企业对于可能发生的系统故障进行防范性准备，比如双活容灾等等，“建立两套或多套功能相同的应用系统，当一处系统停止工作时，整个应用系统可以切换到另一处，使得该系统功能可以继续正常工作。”

![image](./Pictures/soft-architecture/四种典型容灾架构的对比.avif)

#### 同城灾备

![image](./Pictures/soft-architecture/同城灾备.avif)

- 特点：
    - 1.主备两个数据中心位于相同的城市或地理区域，一般指两个数据中心之间的距离小于100千米，即可实现非常低延迟的数据复制。在该架构中，主要实现的是单向同步。
    - 2.主数据中心最上层的流量占比是100%，备数据中心最上层的流量占比是0%，这意味着，平时主要的业务流量通过主数据中心承担，备数据中心主要用于数据备份的存储以及提供服务的冗余，而不提供业务流量的处理能力。
    - 3.该架构部署较为简单，对业务的侵入也较小，基本无需对业务做较大的改造。

- 问题：

    - 1.由于主备数据中心位于相同的城市，则面对一些较大规模的灾害时，如洪水、地震，会同时影响两个数据中心

    - 2.由于备数据中心平时不提供服务，则会导致较大的资源浪费，同时，若主数据中心出现故障，要将服务流量切到备数据中心，这个过程中有一定的可靠性风险，如备数据中心的软件版本、操作系统版本、内核的参数可能会与主数据中心不一致，带来服务的稳定性隐患。

- 这套架构适用于RTO满足分钟级别或小时级别，这主要是热备和冷备的区别，即在架构中，应用服务平时是否处于运行状态。如果处于运行状态的，则是热备，反之，则属于冷备。在冷备架构进行流量切换时，需要将备数据中心的所有应用先进行服务的拉起，耗时更长。在数据库层面，要进行主备的切换，其最上层的业务流量要进行DNS切换，将流量从主数据中心切到备数据中心。

- 应用场景：一般建议把一些风险较小的应用，如一些中小企业的普通类型的应用，采用这套容灾架构。

#### 同城双活

![image](./Pictures/soft-architecture/同城双活.avif)

- 其与同城灾备有一定区别
    - 1.主备数据中心都接收业务流量
    - 2.备数据中心的应用进行了读写分离，写操作会到达主数据中心，读操作会到达备数据中心。

- 特点：
    - 1.两个数据中心仍在同城市运行的，即距离是小于100千米，两个数据中心之间的通信时长小于2ms
    - 2.主备数据中心都处于活动状态，都对外提供服务，因此最上层一般就需要添加负债均衡，且最下层采用数据单向同步机制
    - 3.在业务层面，需要对业务进行改造，主要指业务应用的读写分离改造。

- 问题：
    - 1.主备数据中心仍位于相同的城市，在面对较大的灾难时，容灾效果会受一定影响
    - 2.这套容灾架构会给系统带来一定的复杂度，包括前面提到的应用层面要进行读写分离改造，最上层需要有负债均衡能力，最下层进行数据的同步，以及相应的故障切换的能力建设。

- 应用场景：
    - 1.TO可以实现秒级或分钟级，这取决于最上层的流量切换是否具备自动探活能力，在数据层面，进行主备数据库的切换，最上层如果不具备自动探火，还可以进行DNS切换
    - 2.其适用于在线金融交易应用、互联网应用以及社交媒体应用，这些应用往往需要高可用以及负债均衡。

#### 异地双活

![image](./Pictures/soft-architecture/异地双活.avif)

- 特点：
    - 1.两个数据中心分布在不同的城市，满足“异地”的定义，一般指两个数据中心之间的距离大于1000千米，约为北京和上海之间直线距离，一般认为它可以避免市政级别的故障或自然灾害层面的故障；
    - 2.两个数据中心都处于活动状态，对外提供服务，由于数据中心距离较远，故使用广域网进行数据的同步，且是双向同步状态，从图中可以看到，两个数据中心都叫做主数据中心，在异地多活或异地双活架构中，每个数据中心都是主数据中心，且使用双向同步确保数据的一致性，这里的数据包括数据库的数据以及一些有状态的中间件数据；
    - 3.在最上层要在流量入口部署路由层，而路由服务主要的能力是使得相同特征的流量尽量在单个数据内闭环的处理，如可以按业务类型、用户ID或请求地理位置进行分类。一般会把接入层的路由及业务进行单元化改造。

- 若按业务类型分类，则是指系统有订单及库存服务，其中订单服务部署在北京，库存服务部署在上海，则所有订单的请求都要路由到北京，所有的库存请求都要路由到上海，否则就无法找到对应的业务服务器处理。

- 若按用户ID分类，若用户A要路由到北京，则用户A所有的请求都要路由到北京，用户B要路由到上海，则用户B所有的请求都要路由到上海。若按地理位置分类，假设请求来自上海，则路由到上海地域的服务器，若请求来自北京，那则路由到北京的服务器。

- 做路由层的改造，核心原因在于两个数据中心之间的距离较远，其数据同步的延迟较大。当同一用户处理相同的数据时，发起了两个请求，如果第一个请求路由到北京，第二个请求路由到上海，由于两个请求发起的时间间隔很短，因此如果路由到不同的数据中心就可能会导致数据的紊乱，因为数据中心之间的数据同步本身就有一定的延迟，因此，我们要求相同业务特征的流量尽量在同一数据中心闭环处理，以避免数据同步延时带来问题。

- 问题：
    - 1.由于数据中心之间距离较远，在使用广域网通信时会有一定的网络延迟
    - 2.这套容灾架构会使得应用系统变得更加复杂，包括进行最上层业务路由的划分，内部进行业务的单元化改造，以及数据的双向同步等措施。

- 应用场景：其适用于RTO为秒级或分钟级，这取决于最擅长的路由服务是否可以实现自动探活，或者进行人工的路由切换。该架构适用的应用包括一些较为关键的金融系统、政府类型的应用以及云服务提供商等，即一类在面对大规模灾难时仍能够持续提供服务的应用。

#### 异地多活

![image](./Pictures/soft-architecture/异地多活.avif)

- 与异地双活类似，差别在于数据中心变得更多了，各数据中心之间继续采用双向同步的数据链路，随着数据中心的增多，数据双向同步的拓普变得越来越复杂。

- 特点：
    - 1.多个数据中心的异地多火指的是多个数据中心部署在不同的城市，各城市之间的直线距离大于1000千米的
    - 2.多个数据中心依然都处于活跃状态，同时对外提供服务，数据中心之间使用广域网进行数据的双向同步以确保数据的一致性，这里的数据同样包括数据库的数据以及一些有状态的中间件数据
    - 3.最上层依然需要部署路由层，把相同特征的流量尽量在单个数据中心内闭环处理。

- 问题：
    - 1.配置和管理多个一体数据中心的复杂度非常高，三个数据中心相较于两个数据中心在数据的同步链路复杂度已经增加不少，若是十个数据中心，复杂度会更高，这要求我们需要有强大的网络和资源管理能力
    - 2.随着数据中心的增多，确保多个数据中心之间数据的一致性也是非常大的挑战，包括数据的同步、数据的冲突、数据的复制等问题。

- 应用场景：这套架构依然适用于RTO秒级或分钟级，这取决于路由服务能否自动探活或进行人工切换。它适用于需要在全球范围内提供高可用、高容灾和高负债均衡的应用，如一些跨国企业或云服务提供商的基础服务。

## [腾讯技术工程：月活 12.8 亿的微信是如何防止崩溃的？](https://cloud.tencent.com/developer/article/2010913)

- 以微信 2018 年发表于Socc会议上的文章《Overload Control for Scaling Wechat Microservices》 为基础，介绍微信大规模微服务的过载保护策略，其中很多方法很有借鉴意义。

- 什么是服务过载?
    - 服务过载就是服务的请求量超过服务所能承受的最大值，从而导致服务器负载过高，响应延迟加大。用户侧表现就是无法加载或者加载缓慢。这会引起用户进一步的重试，服务一直在处理过去的无效请求，导致有效请求跌 0，甚至导致整个系统产生雪崩。

- 为什么会发生服务过载？
    - 互联网天生就会有突发流量。秒杀、抢购、突发大事件、节日甚至恶意攻击等，都会造成服务承受平时数倍的压力。微博经常出现某明星官宣结婚或者离婚导致服务器崩溃的场景，这就是服务过载。

- 微信中的过载场景
    - 微信采用的是微服务。
        - 微服务采用统一的 RPC 框架搭建一个个独立的服务，服务之间互相调用，实现各种各样的功能，这也是现代服务的基本架构。毕竟谁也不想看到自己朋友圈崩掉导致聊天功能也无法正常使用。

    - 微信的服务是分三层：接入服务、逻辑服务、基础服务。
        - 大多数服务属于逻辑服务，接入服务如登录、发消息、支付服务，每日请求量在 10 亿-100 亿之间，入口协议触发对逻辑服务和基础服务更多的请求，核心服务每秒要处理上亿次的请求。
        ![image](./Pictures/soft-architecture/微信的微服务分三层.avif)

    - 在大规模微服务场景下，过载会变得比较复杂。
        - 单体服务：一个事件只用一个请求
        - 微服务下：一个事件可能要请求很多的服务，任何一个服务过载失败，就会造成其他的请求都是无效的。如下图所示：
            ![image](./Pictures/soft-architecture/微服务过载.avif)
            - 例子：在一个转账服务下，需要查询分别两者的卡号，再查询 A 时成功了，但查询B失败，对于查卡号这个事件就算失败了，比如查询成功率只有 50%，那对于查询两者卡号这个成功率只有 50% * 50% = 25% 了，一个事件调用的服务次数越多，那成功率就会越低。

- 如何判断过载？

    - 通常判断过载可以使用吞吐量，延迟，CPU 使用率，丢包率，待处理请求数，请求处理事件等等。

    - 为什么不使用响应时间？因为响应时间是跟服务相关的，很多微服务是链式调用，响应时间是不可控的，也是无法标准化的，很难作为一个统一的判断依据。

    - 为什么不使用 CPU 负载？CPU 负载高不代表服务过载，因为一个服务请求处理及时，CPU 处于高位反而是比较良好的表现。

    - 微信使用在请求在队列中的平均等待时间作为判断标准，就是从请求到达，到开始处理的时间。
        - 好处：是这个是独立于服务的，可以应用于任何场景，而不用关联于业务，可以直接在框架上进行改造。
        - 腾讯微服务默认的超时时间是 500ms，通过计算每秒或每 2000 个请求的平均等待时间是否超过 20ms，判断是否过载，这个 20ms 是根据微信后台 5 年摸索出来的门槛值。
            - 当平均等待时间大于 20ms 时，以一定的降速因子过滤调部分请求。如果判断平均等待时间小于 20ms，则以一定的速率提升通过率。一般采用快降慢升的策略，防止大的服务波动。整个策略相当于一个负反馈电路。
            ![image](./Pictures/soft-architecture/微信-负反馈电路策略.avif)



- 过载保护策略：

    - 一旦检测到服务过载，需要按照一定的策略对请求进行过滤。
        - 前面分析过，对于链式调用的微服务场景，随机丢弃请求会导致整体服务的成功率很低。
        - 所以请求是按照优先级进行控制的， 优先级低的请求会优先丢弃。

    - 1.业务优先级

        - 对于不同的业务场景优先级是不同的。
            - 登录场景是最重要的业务，不能登录一切都白费。
            - 支付消息也比普通消息优先级高，因为用户对金钱是更敏感的。
            - 普通消息又比朋友圈消息优先级高。

        - 用户的每个请求都会分配一个优先级。在微服务的链式调用下，下游请求的优先级也是继承的。比如我请求登录，那么检查账号密码等一系列的的后续请求都是继承登录优先级的，这就保证了优先级的一致性。

        - 每个后台服务维护了业务优先级的hash表。微信的业务太多，并非每个业务都记录在表里，不在表里的业务就是最低优先级。
            ![image](./Pictures/soft-architecture/wechat-priority.avif)

    - 2.用户优先级

        - 很明显，只基于业务优先级的控制是不够的。
            - 首先不可能因为负载高，丢弃或允许通过一整个业务的请求。每个业务的请求量很大，那一定会造成负载的大幅波动。
            - 另外如果在业务中随机丢弃请求，在过载情况下还是会导致整体成功率很低。
            - 解决这个问题可以引入用户优先级。

        - 通过 hash 用户唯一 ID，计算用户优先级，为了防止出现总是打豆豆的现象，hash 函数每小时更换，跟业务优先级一样，单个用户的访问链条上的优先级总是一致的。
        - 为啥不采用会话 ID 计算优先级呢？
            - 从理论上来说采用会话 ID 和用户 ID 效果是一样的。
            - 但是采用会话 ID 在用户重新登录时刷新，用户会养成坏习惯，在服务有问题时就会重新登录，这样无疑进一步加剧了服务的过载情况。

        - 引入了用户优先级，那就和业务优先级组成了一个二维控制平面。根据负载情况，决定这台服务器的准入优先级(B,U)，当过来的请求业务优先级大于 B，或者业务优先级等于 B，但用户优先级高于 U 时，则通过，否则决绝。
            ![image](./Pictures/soft-architecture/微信-业务优先级+用户优先级.avif)

    - 3.自适应优先级调整

        - 在大规模微服务场景下，服务器的负载是变化非常频繁的，所以服务器的准入优先级是需要动态变化的。
            - 微信分了几十个业务优先级，每个业务优先级下有 128 个用户优先级，所以总的优先级是几千个。

        - 如何根据负载情况调整优先级呢？最简单的方式是从右到左遍历，每调整一次判断下负载情况，这个时间复杂度是 O(n), 就算使用二分法，时间复杂度也为 O(logn)。在数千个优先级下，可能需要数十次调整才能确定一个合适的优先级，每次调整好再统计优先级，可能几十秒都过去了，这个方法无疑是非常低效的。

        - 微信提出了一种基于直方图统计的方法快速调整准入优先级
            - 服务器上维护者目前准入优先级下，过去一个周期的（1s 或 2000 次请求）每个优先级的请求量，当过载时，通过消减下一个周期的请求量来减轻负载
                - 假设上一个周期所有优先级的通过的请求总和是N。下一个周期的请求量要减少N*a
                - 怎么去减少呢？每提升一个优先级就减少一定的请求量，一直提升到减少的数目大于目标量，恢复负载使用相反的方法，只不是系数为b，比a小，也是为了快降慢升。根据经验值a为 5%，b为1%。
            ![image](./Pictures/soft-architecture/微信-动态调整请求量.avif)

        - 为了进一步减轻过载机器的压力，能不能在下游过载的情况下不把请求发到下游呢？否则下游还是要接受请求、解包、丢弃请求，白白浪费带宽也加重了下游的负载。
            - 为了实现这个能力，在每次请求下游服务时，下游把当前服务的准入优先级返回给上游，上游维护下游服务的准入优先级，如果发现请求优先级达不到下游服务的准入门槛，直接丢弃，而不再请求下游，进一步减轻下游的压力。

- 总结：

    ![image](./Pictures/soft-architecture/微信整个负载控制的流程.avif)

    - 当用户从微信发起请求，请求被路由到接入层服务，分配统一的业务和用户优先级，所有到下游的字请求都继承相同的优先级。

    - 根据业务逻辑调用1个或多个下游服务。
        - 当服务收到请求，首先根据自身服务准入优先级判断请求是接受还是丢弃。服务本身根据负载情况周期性的调整准入优先级。
        - 当服务需要再向下游发起请求时，判断本地记录的下游服务准入优先级。
            - 如果小于则丢弃
            - 如果没有记录或优先级大于记录则向下游发起请求。

        - 下游服务返回上游服务需要的信息，并且在信息中携带自身准入优先级。上游接受到返回后解析信息，并更新本地记录的下游服务准入优先级。

## [腾讯云开发者：优雅应对故障：QQ音乐怎么做高可用架构体系？](https://cloud.tencent.com/developer/article/2206300)

- 1.异地双中心：

    - 深圳和上海各有API-Gateway（接入层）：从而实现STGW（腾讯基于 Nginx 自研的支持大规模并发的七层负载均衡服务）

        ![image](./Pictures/soft-architecture/qq-music.avif)

    - 逻辑层：深圳读/写；上海只读，上海的写请求由API网关路由到深圳中心处理

    - 存储层：深圳写入存储，通过同步中心/存储组件同步到上海。同步组件为[Cmongo（腾讯研发的MongoDB）](https://github.com/Tencent/CMONGO)和CKV+（腾讯自研的分布式kv数据库）

        - [CKV+之进化历程](https://cloud.tencent.com/developer/article/1387361)
            - 兼容redis协议
            - 多租户模式
            - CKV+在最终一致的数据同步基础上，引入了基于Raft协议的强一致同步逻辑

- 2.异地容灾：在API网关上做故障转移，降低客户端参与度。

    ![image](./Pictures/soft-architecture/qq-music1.avif)

    - 1.API网关故障转移：当本地中心API返回失败时（包括触发熔断和限流），API网关把请求路由到异地处理。以此解决API故障的场景。

        - 为防止异地重试流量被压垮，出现双中心雪崩，要有自适应重试方案，在异地成功率下降的时候，取消重试：

            - 引入重试窗口：耗光后，取消重试

    - 2.客户端故障转移：当API网关发生超时的时候，客户单进行异地重试。如果网关有回包，即使API返回失败，客户端也不重试。解决API网关故障的场景。

    - 当双中心的API-Gateway均异常：所有客户端请求冻结一段时间。

- 3.自适应限流：请求量超出阈值后在主调直接丢弃请求，在集群扩缩容后需要及时更新限流阈值

- 4.熔断：

    ![image](./Pictures/soft-architecture/qq-music2.avif)

    - 当“统一权限”服务的其中一个依赖服务（比如歌曲权限配置服务）出现故障时，只能被动的等待依赖服务报错或者请求超时，下游连接池会逐渐被耗光，入口请求大量堆积，CPU、内存等资源逐渐耗尽，导致服务宕掉。
    - 而依赖“统一权限”服务的上游服务，也会因为相同的原因出现故障，一系列的级联故障最终会导致整个系统宕掉。

    - 传统熔断器 有三种状态：Closed、Half Open、Open

        - Open状态：拒绝所有请求

        - 进入Closed状态时瞬间会有大量请求，服务端可能还没有完全恢复，会导致熔断器又切换到Open状态，一种比较刚性的熔断策略。

    - SRE熔断器 有两种状态：Closed、Half-Open

        - 根据请求成功率自适应地丢弃请求，尽可能多地让请求成功请求到服务端，是一种更弹性的熔断策略。

        - 熔断器阈值：

            - 正常情况下 requests（窗口时间内请求数） = accepts（正常处理的请求数） 时丢弃概率为0。
            - K：敏感度，K越小丢弃概率越大，一般在1.5-2之间

            - requests不断减少直到 requests 等于 K * accepts 时：熔断器就会打开，并按照概率丢弃请求。

        - QQ音乐采用SRE熔断器

- 动态超时

    - 微服务架构的演进，超时逐渐被标准化到RPC中

    - 传统超时会设定一个固定的阈值，响应时间超过阈值就返回失败。

    - 微服务基于EMA算法动态调整超时时长。

        - [EMA算法](https://github.com/jiamao/ema-timeout)是综合利用历史上积累到的数据，预测下一个周期内的期望。EMA算法引入“平均超时”的概念，用平均响应时间代替固定超时时间，只要平均响应时间没有超时即可，而不是要求每次都不能超时。

- 服务分级

    - 每日邮件推送1级服务和2级服务的观测数据

    - 为针对1级服务和2级服务制定SLO（达到某一段时间内的目标数值），签订SLA（无法完成商业承诺，就付出代价）

    - API-Gateway根据服务分级限流，优先确保1级服务通过

    | 等级                                                           | 例子                                         |
    |----------------------------------------------------------------|----------------------------------------------|
    | 1级 ：如果出现故障会导致用户或业务产生重大损失                 | 登录服务、流媒体服务、权限服务、数专服务等。 |
    | 2级 ：如果出现故障会导致用户体验受到影响，但是不会完全无法使用 | 排行榜服务、评论服务等。                     |
    | 3级 ：不容易注意或很难发现                                     | 用户头像服务，弹窗服务等。                   |
    | 4级 ：即使失败，也不会对用户体验造成影响                       | 比如红点服务等。                             |

- 工具链：在故障触发之前，尽可能多地识别风险，针对性地加固和防范，而不是等着故障发生。

    - 混沌工程：通过注入网络超时等故障，主动找出系统中的脆弱环节

        - QQ音乐使用ChaosMesh结合其他组件打造的混沌工程平台

    - 全链路压测：通过注入流量给系统施加压力的方式，来发现系统的性能瓶颈

    - Prometheus + Grafana做可视化展示

        - 秒级监控：基于Prometheus构建联邦集群，每3秒抓取一次数据，实现了准实时监控。并对活动进行快照采集，记录活动发生时所有微服务的请求峰值

        - 历史数据回溯：当我们需要回溯近一个月甚至一年前的指标趋势时，性能是个极大挑战。由于历史数据的精度要求不高。通过Prometheus联邦进行阶梯降采样，可以永久存放历史数据，同时也极大降低存储成本。
    - Logging

        - ELK（ElasticSearch、Logstash、Kibana）构建日志处理平台

            ![image](./Pictures/soft-architecture/qq-music-Logging.avif)

        - Filebeat 作为日志采集和传送器。Filebeat监视服务日志文件并将日志数据发送到Kafka。Kafka 在Filebeat和Logstash之间做解耦。
        - Logstash 解析多种日志格式并发送给下游。ElasticSearch 存储Logstash处理后的数据，并建立索引以便快速检索。
        - Kibana 是一个基于ElasticSearch查看日志的系统，可以使用查询语法来搜索日志，在查询时制定时间和日期范围或使用正则表达式来查找匹配的字符串。

    - Tracing追踪：一个客户端请求由系统中大量微服务配合完成处理，这增加了定位问题的难度。

        - Tracing在触发第一个调用时生成关联标识Trace ID，我们可以通过RPC把它传递给所有的后续调用，就能关联整条调用链。Tracing还通过Span来表示调用链中的各个调用之间的关系。

        - QQ音乐基于jaeger构建分布式链路追踪系统，实现分布式架构下的事务追踪、性能分析、故障溯源、服务依赖拓扑。

            - 1.jaeger client发送的spans通过jaeger-agent（代理）转发到jaeger-collector。
            - 2.jaeger-collector 接收后，验证和清洗数据后转发至kafka。
            - 3.jaeger-ingester 从kafka消费数据，并存储到ElasticSearch。
            - 4.jaeger-query 封装用于从ElasticSearch中检索traces的APIs。

            ![image](./Pictures/soft-architecture/qq-music-jaeger.avif)

    - profile：基于[conprof](https://github.com/geekgao/conprof)搭建持续性能分析系统

    - Dumps

        - core dumps：在进程崩溃时把进程内存写入一个镜像中以供分析，或者把panic信息写到日志中

            - 在容器环境中实施困难，panic信息写入日志则容易被其他日志冲掉且感知太弱。

        - QQ音乐使用的方式是在RPC框架中以拦截器的方式注入，发生panic后上报到sentry平台。

# 客户端架构

- [B站PC客户端-架构设计](https://www.bilibili.com/read/cv22750308)

    - Electron = Chromium + nodejs + nativeAPI（系统对话框、系统托盘、系统菜单、剪切板等）

    - Electron运行时：主进程 (Main Process)  + 渲染进程(Render Process)
        - 主进程： NodeJs 和原生 API
        - 渲染进程：前端技术
        - 主进程和渲染进程之间通过 IPC 进行通信
        ![image](./Pictures/soft-architecture/electron-runtime.avif)

    - B站的Electron方案：

        - 渲染进程和主进程都是基于 TypeScript 进行开发的

            - 主进程和渲染进程的中间，设计了一个 common 共享层，用来实现 Ts 类型和常量的共享。

        - 主进程： NodeJs + NestJs + Esbuild

            - NestJs：是一个受 Angular 启发的 NodeJS 后端框架，风格有点像 SpringBoot

                - 结合 OOP (Object Oriented Programming)、FP (Functional Programming) 和 FRP (Functional Reactive Programming) 等编程范式，能够开发出高可测、好拓展、松耦合、易维护的应用。

            - Esbuild：使用 go 语言实现的 js 极速打包工具

        - 渲染进程：Vue3 + Vite2 + TypeScript

            - 并且还应用了B站自研的 Vue3 组件库 vivid-ui、函数库 @bilibili/b-utils 和样式库 @bilibili/b-style 等工具库。

        - 根据业务功能，结合框架和技术栈的整体架构：

            - 渲染进程：
                - 账号登录、大会员充值、直播间和开播页都是使用 webview 嵌 WEB 页的方式接入的
                - 其它业务模块均为本地应用页面

                - 渲染层是基于 Vue 开发的 SPA 应用，主窗口和播放窗口在打开时会有一个比较耗时的加载过程，我们专门针对窗口创建和打开过程做了优化。
                    - 1.在启动时（首次打开主窗口），会先创建一个隐藏的主窗口，加载一个相对简单的开屏页。主窗口和开屏页显示之后，在主窗口开屏页下方加载和渲染比较大的主页面。

                    - 2.主页面渲染完成时，调用主进程 mainWindowReady 接口，并关闭盖在主页面上面的开屏页。主进程收到 mainWindowReady 后，创建一个隐藏的播放窗口。

                    - 3.当用户点击播放视频时，显示已渲染好的播放窗口，并加载和播放视频。关闭主窗口和播放窗口时，只将窗口隐藏并不真实销毁窗口实例，当再次打开或播放视频时，就可以快速打开窗口，提升用户体验。

                    ![image](./Pictures/soft-architecture/b-architecture-窗口优化.avif)

                - “节能模式”：渲染进程占用资源比较大，如果用户长时间未使用又没有关闭的话就会造成资源浪费，当 APP 隐藏到托盘超过一定时间未点开后会进入到此模式
                    - 会杀掉主窗口和播放窗口对应的渲染进程，释放资源占用。
                    - 再次打开时，由于没有 APP 初始化的任务，速度会比冷启动时要快很多。

            - 主进程：

                - 本地日志、本地存储和下载 SDK 都是引入的模块，其它各个模块和服务之间通过依赖注入和 rxjs 主题订阅的方式实现相互调用

                - 一个窗口页面其实本质上就是一个 HTML 页面。
                    - 主页面都是从由主进程创建的本地服务器上拉取的 Local 页面，因此断网的情况也能响应
                    - 首页、动态网络强相关的页面，在断网时会显示失败提示
                    - 离线缓存、设置等功能都能正常使用。

            - JSB 则由主进程通过 preload 的方式注入到渲染进程各页面的 window 对象中，渲染进程不论是外嵌还是本地页面都能访问到 JSB 对象实现和主进程通信。

            ![image](./Pictures/soft-architecture/b-architecture-electron.avif)

                - 主要包含 7 个常跓进程：
                    - 1 个浏览器 (Browser) 进程
                    - 1 个 GPU 进程
                    - 1 个网络服务 (Network Service) 进程
                    - 1 个音频服务 (Audio Service) 进程
                    - 3 个页面 (Tab) 进程。
                    - 通过主进程 app.getAppMetrics()方法获取 APP 各进程的 CPU 和内存数据统计

        - 开发平台工具
            - Fawkes 平台打包构建
            - 北极星进行数据上报并在观远建立数据报表
            - 魔镜平台进行自动化巡检测试
            - 在 info.bilibili.co（企业微信） 上建有专门的产品和开发文档，开发方面也有明确的代码规范要求
            ![image](./Pictures/soft-architecture/b-architecture-开发平台工具.avif)

        - 构建都基于 NPM Script， 由于构建产物也是 js 代码，很容易被人拿去套壳、植入或篡改。

            - 对构建包进行加密处理：实现了一套使用结合代码混淆、对称加密、字节码处理、WASM 解密和啥希校验的组合式客户端加密防破解方案。

                - 在打 Release 包时，会把构建生成的代码先进行混淆、压缩处理，再将主进程主程序代码使用 AES-256 对称加密生成 / app/main/.biliapp 文件，将解密和执行入口使用字节码处理，最后计算出 APP 的哈希值。

                - 当 PC 客户端启动时，会先根据操作系统和系统架构找到对应字节码入口、解密并运行主程序、主程序中校验 APP 的哈希值，在确定运行环境安全后再正常启动程序。

                ![image](./Pictures/soft-architecture/b-architecture-防破解.avif)

        - 增量更新：

            - 基于 electron-builder 进行打包，Mac 的安装窗口通过 electron-builder 配置可以直接生成，Windows 的专属一键三连安装程序则是使用 NSIS + QT 独立开发的。
                ![image](./Pictures/soft-architecture/b-architecture-打包.avif)

            - 前期版本基于 electron-updater 进行升级更新。在 1.9.x 版本之后，只需对 app.asar 代码包进行更新而不是包含框架的完整安装包

        - 双窗口模式：

            - 主窗口和播放窗口是独立的，类似爱奇艺和腾讯视频，可以让用户一边播放视频一边刷动态、逛空间、看消息。

            - PC客户端对比WEB：

                - 播放质量：PC 客户端的首帧和 VV 卡顿率会优于 WEB，主要原因为能更多预载，单实例，编码支持统一

                - 百分钟卡顿率和错误率：PC 客户端相对 WEB 来说要略高一些，新平台有更多 case 需要处理，此项会略高但重试机制尽量不影响体验。

                - PC 客户端的播放器技术：

                    - 直接用上了WEB 强大的 Nano 播放器，拥有了高级弹幕、播放设置、播放器快捷键等功能。

                    - 还将 UGC 和 OGV 播放器集成在同一个播放窗口，让视频类型切换更加顺畅，还可以通过前进后退播放历史纪录。

# 电商架构

## [二马读书：秒杀，这是我见过最最实用的技术方案](https://mp.weixin.qq.com/s/UwtsQLBgBMvDlC0SljHmeQ)

个人从事电商行业十几年，经历过大大小小的促销活动和秒杀上百次，每次做秒杀瞬时访问量会翻数十倍，甚至数百倍。对系统架构是巨大的考验，期间也曾经历过系统宕机，甚至整体雪崩。那么我们怎么设计秒杀系统，才能保证秒杀系统的高性能和稳定性，同时还要保证日常业务不受影响呢？

先看看秒杀场景特点。秒杀开始前几分钟，大量用户开始进入秒杀商品详情页面，很多人开始频繁刷新秒杀商品详情页，这时秒杀商品详情页访问量会猛增。秒杀开始，大量用户开始抢购，这时创建订单，扣库存压力会显著增大。实际上，秒杀场景基本都是秒杀参与人多，秒杀成功的人却寥寥无几，经常是几十万人或者更多人抢几百个商品库存。

- 秒杀业务流程上的考虑

    - 由于参加秒杀的商品售卖价格非常低，基本都是“抢到即赚到”，成功下单后却不付款的情况非常少。

        - 所以我们采用下单减库存的方案，下单时扣减库存，然后再进行支付。

        - 假如真有个别订单不付款怎么办？没关系，秒杀好活动最主要的目的是吸引流量，个别订单不支付对秒杀活动本身影响不大。况且，没支付剩下的库存还可以做为普通商品继续售卖。

- 页面静态化

    - “秒杀开始前几分钟，大量用户开始进入秒杀商品详情页面，很多人开始频繁刷新秒杀商品详情页，这时秒杀商品详情页访问量会猛增”。如果请求全部打到后端服务，那后端服务的压力会非常大（后端服务要处理业务逻辑，而且还要访问数据库，吞吐量比较低）。

    - 考虑到秒杀是运营同学提前安排的活动，要秒杀哪些商品、商品价格等信息在秒杀活动开始前已经确定下来，所以我们可以把秒杀商品详情页做成静态页面，把商品详情、商品价格等参数、评论评价等信息全部放在这个静态页面里，然后把这个静态页面上传到CDN上预热（CDN是内容分发网络，可以简单理解成互联网上的巨大的缓存，用于存放静态页面、图片、视频等，可以显著提高访问速度），用CDN扛流量，这样大量的商品详情页的访问请求就不用访问自己的网站（源站）。这样既可以提高访问速度，也没有给网站增加压力，同时也减少了网站带宽压力。
        ![image](./Pictures/soft-architecture/电商秒杀场景-页面静态化.avif)

- 请求拦截

    - 前端页面，相关按钮点击后置灰，防止重复提交

    - 网关（zuul，nginx）层，为了避免前端恶意请求，比如一些攻击脚本，在网关层要对下单等接口按userID限流，几秒钟只能访问一次。考虑到秒杀场景参与人多，秒杀成功的人极少，我们可以把绝大部分抢购下单请求在网关层直接拒掉，按秒杀失败处理。这样就极大减少了后端服务的压力。

    - 假设秒杀库存是200个，我们可以只放行200个请求到后端服务。要注意，为了尽量避免库存被机器人和自动脚本抢走，200个请求不能在秒杀开始瞬间同时放行，可以分段放行，比如秒杀开始后随机选取100ms内的10个请求放行（这100ms内的其他请求直接拒掉，按秒杀失败处理），之后每隔100ms放行10个请求，2秒钟可以放行完200个请求。分段放行，除了限制了机器人和自动脚本，把请求分散在各个时间段，还进一步缓解了后端服务的压力。

    - 分段放行总时间不能太长，假如每100ms放行1个请求，放行完所有200个请求需要20秒时间，这样用户就会明显感知到下单早的人没秒杀成功，下单晚的人反而秒杀成功了，用户体验会变差。

    - 另外，秒杀过程网关压力会比较大，网关可以做成集群，多节点分摊访问压力。
    ![image](./Pictures/soft-architecture/电商秒杀场景-请求拦截.avif)

- 后端服务设计

    - 如果秒杀库存只有200，经过网关拦截，再加上采用分段放行的方式，对于后端服务基本没什么压力了，日常的后端服务就完全可以支撑秒杀活动了。不用再做更复杂的设计。

        - 不过，假如秒杀库存有几万个，放行的下单请求就有几万个，为了用户体验放行总时间也不能太长，这时后端服务该怎么设计呢？

    - 这时主要压力就在数据库了，扣减库存压力，创建订单压力。

        - 库存可以放到Reids缓存中，来提高扣减库存吞吐能力。对于热点商品的库存可以利用Redis分片存储。

        - 创建订单可以走异步消息队列。后端服务接到下单请求，直接放进消息队列，监听服务取出消息后，先将订单信息写入Redis，每隔100ms或者积攒100条订单，批量写入数据库一次。前端页面下单后定时向后端拉取订单信息，获取到订单信息后跳转到支付页面。用这种批量异步写入数据库的方式大幅减少了数据库写入频次，从而明显降低了订单数据库写入压力。

        ![image](./Pictures/soft-architecture/电商秒杀场景-后端服务设计.avif)

- 隔离

    - 1.业务隔离：
        - 从业务上把秒杀和日常的售卖区分开来，把秒杀做为营销活动，要参与秒杀的商品需要提前报名参加活动，这样我们就能提前知道哪些商家哪些商品要参与秒杀，可以根据提报的商品提前生成静态页面并上传到CDN预热，提报的商品库存也需要提前预热，可以将商品库存在活动开始前预热到Redis，避免秒杀开始后大量的缓存穿透。

        ![image](./Pictures/soft-architecture/电商秒杀场景-业务隔离.avif)

    - 2.部署隔离。
        - 秒杀相关服务和日常服务要分组部署，不能因为秒杀出问题影响日常售卖业务。可以申请单独的秒杀域名，从网络入口层就开始分流。网关也单独部署，秒杀走自己单独的网关，从而避免日常网关受到影响。秒杀可以复用订单，库存，支付等日常服务，只是需要一些小的改造（比如下单流程走消息队列，批量写入订单库，以及在Redis中扣减库存）。

        ![image](./Pictures/soft-architecture/电商秒杀场景-部署隔离.avif)

    - 3.数据隔离。
        - 为了避免秒杀活动影响到日常售卖业务，Redis缓存需要单独部署，甚至数据库也需要单独部署！数据隔离后，秒杀剩余的库存怎么办？秒杀活动结束后，剩余库存可以归还到日常库存继续做为普通商品售卖。数据隔离后，秒杀订单和日常订单不在相同的数据库，之后的订单查询怎么展示？可以在创建秒杀订单后发消息到消息队列，日常订单服务采取拉的方式消费消息，这时日常订单服务是主动方，可以采用线程池的方式，根据机器的性能来增加或缩小线程池的大小，控制拉取消息的速度，来控制订单数据库的写入压力。

- 网络

    - 秒杀前要和网络运营商、CDN服务商提前申请带宽。

- 还有哪些细节要考虑

    - 1.如何避免超卖？如果在redis中扣减库存，可以利用decr命令扣减库存，decr是原子操作，在分布式环境下也不会有并发问题，decr扣减库存后，判断返回值，如果返回值小于0，扣减库存失败，秒杀也就失败了；如果在数据库中扣减库存可以在where后面加上库存大于0的条件，来避免库存被减成负值。这样就可以避免超卖情况发生了。

    - 2.接口防刷，前面已经提到过，在网关层对下单等接口按userID限流。

    - 3.网关层除了对userID做限流外，还要做整体限流。在实际访问量超过预估访问量时，整体限流可以起到保护作用，避免系统被压垮。

    - 4.防止重复下单，按userID限流已经起到了防止重复下单的作用。假如限制同一个用户10分钟能下一次单，一般情况下10分钟内，商品早已经被抢光了，用户也就没有再次下单的机会了。

    - 5.可以结合风控系统，在网关层把羊毛党等有问题的用户请求直接拒掉。

    - 6.可以在网关层上面再加一层防火墙或者高防服务，来防御DDos等分布式网络攻击。

# 新技术的危害

- 企业软件的成本，只有20%是早期的开发成本，剩下的80%都是后期的维护和更新成本。

- 很多的新技术，看上去可以节省前面20%的开发成本，但可能大大增加后面80%的维护成本。

- 没有一种技术是完美的，每个工具决策都是一种权衡。

- [On Endings: Why & How We Retired Elm at Culture Amp](https://kevinyank.com/posts/on-endings-why-how-we-retired-elm-at-culture-amp/)

    > 在自豪地宣传Elm作为构建Web UI的首选语言四年后，Culture Amp公司决定放弃它。

    - Elm是Web应用程序语言。它编译为JavaScript，可以在任何Web浏览器中运行，但作为一种基于ML的函数式编程语言，它看起来像Haskell -也就是说，几乎不像JavaScript。JavaScript充满了括号和花括号；Elm的杂乱程度要低得多

    - 回顾Elm在Culture Amp的表现。我们使用Elm构建的部分产品在第一次生产部署时就可以不出错运行。Elm本身非常稳定，具有讽刺意味的是，这种稳定性实际上在几个场合对我们不利，已经有很多年没有人看过它了，而构建它的团队经常完全忘记它是如何工作的！！值得庆幸的是，Elm的简单性使得代码简单易读。

    - Elm吸引了一些我们最好的工程师，他们很想在“那种会考虑Elm的地方”工作。与此同时同时Culture Amp避免雇佣纯粹专注于技术的工程师。

        - 作为一家产品公司，我们希望雇佣那些对我们的产品及其使命感到兴奋的人，以及那些乐于在必要时学习新东西以取得进展的人。当有人在采访中告诉我们，他们对在这里工作感到兴奋，因为他们喜欢函数式编程（比如），我们认为这表明他们可能并不适合。由于这种动机的不匹配，我们不止一次选择不雇佣候选人，多年来有一两次我希望我们能更严格地遵守这条路线

    - Elm+React：易于入门，难以维护

        - 一些团队使用React进行构建，而另一些团队使用Elm进行构建。两者导入同样的CSS模块（Sass编写），这种方法一开始取得了很大的成功。因此有能力和信心为组件的两个版本做出更改，以保持它们的同步。但在2018年，这种情况开始发生变化，保持组件的两个版本同步变得越来越困难。

        - 我们收购了另一家公司，该公司的整个代码库都是用React编写的，而其团队对Elm一无所知。一夜之间，我们从一家写了等量的Elm和React的公司，变成了一家写了75% React的公司。

        - 而且TypeScript已经发展到足够强大（并且对开发人员足够友好），可以平衡Elm

    - 最后做出改变

- [GraphQL: From Excitement to Deception](https://betterprogramming.pub/graphql-from-excitement-to-deception-f81f7c95b7cf)
    - GraphQL宣称的优点
        - 1.一次请求，多个资源
        - 2.数据的精确提取：可以对数据进行选择，从而减少网络传输的数据辆
        - 3.强类型

    - 我们的移动团队大力提倡GraphQL。桌面前端团队也喜欢类型的概念。我们在2019年采用了REST API。该团队投入时间为GraphQL构建新的端点。我们选择了Apollo库，它提供React.js、Kotlin和Swift客户端。

    - 我们很快部署了第一个端点，并且GraphQL和REST API可以共存于同一个app上。我们开始增加更多端点，2020年我们增加了50多个端点。

    - 但过了2年，我们发现了问题
        - GraphQL虽然让客户端代码变得简单，但性能比不上REST API

- [Why I regret using Ionic for app development](https://mhamri.com/why-i-regret-using-ionic-for-app-development-c8b21b88d83a)

# 复杂度，熵增，技术债

- [腾讯云开发者：对抗复杂度的圣杯战争：软件架构究竟该如何设计？](https://cloud.tencent.com/developer/article/2373773)

- [腾讯云开发者：99%的程序员容易忽视的“系统”健康问题](https://cloud.tencent.com/developer/article/2361561)

- [腾讯云开发：鹅厂万人热议｜如何理解业务系统的复杂性？](https://cloud.tencent.com/developer/article/2273369)

    - 为什么用户规模或者营收规模不增加，事情反而越来越多呢？

        - 由于业务规模停滞或者下滑，产品侧不得不做更多的事情来止住颓势甚至想要以此力挽狂澜。

        - 要么是不断地拓展产品的边界，在一个应用里加入更多的功能，也就是所谓的交付更多的用户价值，从而吸引更多潜在用户

        - 要么是不断地优化现有功能，例如通过排版来从心理学角度提高用户停留时长和点击率，亦或是进一步优化产品的交互流程，也就是所谓的提升用户体验，从而提升口碑，稳固用户基本盘。

    - 降本增效：

        - 降本：更精细化地使用服务器和存储资源，投入更多精力去关注云上账单，该省的省。在需求的技术评审环节加上成本预估，让那些提极低的 ROI 需求的产品经理知难而退。
            - 就是减少不必要的浪费。
            - 这种减少浪费的降本手段在短期很有用，但很快就会达到收益天花板。更大的收益还是要提升效率，但增效相关的工作，也许你感知到的是寥寥无几。

        - 增效：工程效能（EP）（利用各种好用的开发工具）提升写代码、构建服务以及协同开发的效率。
            - 拥有可以极速处理几百 G 大仓的代码托管平台
            - 拥有高度可配置的流水线来自动化一些日常繁琐的构建任务
            - 有良好设计的 RPC 开发框架
            - 有先进的可观测平台……

        - 这一切的一切，最终目标或许大家也经常听到——让程序员可以专注于业务的开发。

            - 但问题是，在整个软件的开发中，到底是业务开发工作量的占比高，还是非业务开发工作量占比高？

    - 《人月神话》的作者 Fred P. Brooks 的文章 《没有银弹：软件工程的本质性与附属性工作》 中提到：

        - Essential Complexity 是说软件要实现某种功能，而这种功能本身内在就具有复杂性。

        - Accidental Complexity 则代表了程序员在用代码实现功能时，由于各种软硬件等的限制以及人和人的沟通不畅而额外引入的工程上的复杂性。

        -  Essential Complexity 就是不可避免的。即使你消除了所有的Accidental Complexity，Essence Complexity 依然存在。

        - 回到上面的问题：工程效能（EP）和各种中台为开发者提供工具和服务，其实就是在尽量减少 Accidental Complexity。然后让大家可以专注于业务本身的开发，也就是 Essence Complexity。

        - 二八法则在软件开发中：Accident Complexity 是八还是 Essence Complexity是八？

            - 如果 Essence Complexity 是八。那我们一直只在 EP 上做文章，是否有点“隔靴搔痒”？

                - 无数现实中的例子，由于业务建模的不合理、由于需求的仓促上线、由于接口设计的不合理、由于各种无谓的耦合……建立在最牛的基础设施之上的业务系统，一段时间之后又将变成一座废山。代码看得令人眩晕，改功能不知道去哪里改，不知道会影响哪些功能，不知道需要改动的点是否都被覆盖到了，改个小功能要改无数的地方……

                    - 不管基础设施多么优秀，业务代码依然是废山。所以只靠工具提效是远远不够的，还需要关注业务本身，Essential Complexity。

    - 功能之间隐蔽增加的耦合

        - 相信绝大部分开发者在项目一开始的时候，都有一颗“整洁架构”的心，都希望把代码写好。尤其是项目一开始，需求做的飞快，每天几千行代码也不在话下。

            - 大家会关注函数的颗粒度，会关注模块的划分和职责是否单一，也会关注单元测试情况和代码的可测性。即使这样，随着时间推移，大家还是会发现代码改起来越来越痛苦——总会牵一发而动全身，或者明明是修改功能 A，却不得不关注功能B是否受影响。这是为什么呢？

                - 答案就是——耦合。因为 Essential Complexity的存在。如果某个功能本来就需要多个模块共同参与，不论你怎么分解这些模块，只有把它们“集成”到一起，才能实现有意义的功能。把它们集成到一起，A 依赖于 B、B 又依赖 C、C 又会反馈给 A，这不就是耦合吗？

                - 例子：社区类应用有一天，产品经理希望做一个新功能，叫作“名片系统”。简单来说就是，它允许用户自定义自己头像后展示哪些名片或者标签（可以有多个），以突显身份特征

                    ![image](./Pictures/soft-architecture/耦合-社交类应用.avif)

                    - 这个需求其实初看起来没有多复杂，闭上眼睛琢磨大概就能想到。

                        - 这里的重点不是要去不同的系统查数据麻烦，重点是这里引入了新的耦合。

                    - 但是再深入想一想，你就会发现其实并没有想象的那么简单。如果没有意识到由 Essential Complexity 引入的耦合，开发者很可能在排期的时候少估算了天数，最后不得不需要用各种“责任感”、“Ownership”这种精神力量通过加班来尽量保证不 delay。

                - 例子：我们想把App上部分优质的内容分享到微信

                    - 大部分手机App都是用原生的方式开发，例如 IOS 用 Swift/OC、Android用 Java/KT。但微信中只能分享 H5 的 Web 页面。

                    - 这就意味着同样一个需求，除了要用原生做一遍，还需要用 H5 再做一遍。不仅如此，由于分享到微信的H5 页面，用户打开后肯定都是没有登录态，因此还需要让 H5 依赖的后台接口支持无登录态调用。
                    - 有些接口逻辑强依赖于用户登录态怎么办？例如查看资讯详情的接口，接口内部除了要返回资讯内容，还要记录用户的浏览记录，还需要给资讯的浏览量+1。如果你没有关注资讯的作者，可能头像旁边要展示一个关注按钮……这些都需要依赖于用户的登录态才能完成。因此在没有登录态的情况下，就必须阉割一部分现有功能。
                        - 那要怎么阉割呢？在原接口中各种 if else？太 bad taste 了，不仅代码乱成一锅粥，统一的鉴权网关也很难处理。最好就是新开接口专门处理来自 H5 的调用，把它当成另一个独立的需求，而不是强行和之前的接口逻辑写在一起。

                            - 但这还不够，还有很多问题，例如像文章浏览量这种数据怎么处理？没有登录态，就没法对浏览量进行去重。如果每次请求都累加，就会被灰产利用来刷数据。如果不累加，似乎对作者又不太公平？这可能会导致产品侧需要同时记录有效浏览量和无登录态浏览量，这又是一个新需求了。

    - 这是发生在作者身上的真实故事，一个满腔热血，熟读《整洁架构》《重构》《设计模式》《领域驱动》 《演进式架构》的人，从零开始开发系统，却依然避免不了旧代码走向腐化，成了后人口中的废山始作俑者。

        - 有个机会从零开始负责一个公司重量级的运营系统的开发，内心非常的激动。终于可以按照自己工作之余看书学到的最佳实践方法来构建项目了，这下要让所有人刮目相看。开发过程中，也是恪尽职守，每天晚饭后都花至少1个小时拉着团队另外几个开发人员做 Code Review，经常还争执得面红耳赤，对 Bad Taste 坚决抵制。

        - 项目整体推进得很顺利，上线后取得了很大的成功，只是后来由于组织架构变动，去了另一个团队，不再负责那个项目了。不过本人一直觉得，自己给接盘方打下了一个非常好的基础，对方一定会感谢自己……直到一年后的某天，和一个同事无意间聊起来，他们就负责了我之前的那个项目（他不知道我之前负责那个项目）。本以为能从他那得到些正向的评价，结果全是吐槽，诸如代码看不懂、风格奇葩、扩展困难等等。最后补了一句，后来实在受不了，他们重写了。

        - 腐化是不可避免核心原因：架构设计和模块抽象只能面向当下，它天然是短视的或者说是有局限性的。这种局限性即使是最优秀的架构师也是无法逾越的。

    - 两个常见的开发模式：
        - 1.瀑布流式开发（上个世纪比较传统的开发模式）：
            - 甲方提需求，我要做一个什么样的软件，它要包含哪些功能 。软件公司作为乙方，来承接甲方的需求。它首先需要有人去调研甲方的需求，具象化每个功能点，然后形成最终的需求文档和性能要求文档。当甲方对需求认可并签字后，就进入了架构师的设计阶段。
            - 这个阶段架构师能够看到所有的需求，他拥有全局的视角，然后进行架构设计、方案设计和模块的拆分。最后根据架构师的设计，开发部门就分模块进行开发。
            - 开发完成之后进入测试阶段，测试完成后再交给甲方去验收，验收通过就正式交付。

            - 缺点：
                - 开发方式周期很长，动辄就是以6 个月甚至 1 年起步，很多大项目甚至要 3 年以上。但商场如战场，形势瞬息万变，等你做出来，黄花菜都凉了，再好的软件又有什么用呢？

                - 任何一个环节出问题，都会导致后续环节出问题：甲方验收时：“当初说的做 XXX，但是你们做出来是 YYY，根本不是我要的，不满足需求”。这又会涉及大量的返工，进一步让项目延期。

        - 2.敏捷开发：小步快跑，先做最重要的部分。

            - 现在互联网公司基本上都是快节奏的发布，做App 都是先发 MVP 版本（最初可用版），然后再持续优化。每个迭代，产品经理都是只提几个有限的需求，开发也只开发这几个需求就上线。然后就进入不断堆功能的小步快跑阶段，缝缝补补又一年。产品经理也会用各种方式尝试去识别功能的收益，埋点、报表、同比环比等等。

            - 优点：它能够快速捕捉市场机会，让自己活下来，活下来才有机会谈成本，再找到性价比高的地方去优化。

            - 缺点：做技术方案设计时，能拿到的信息仅仅是宏大视图中的小小一角，根本没有全貌，并不能像瀑布流开发那样拿到产品的整体视图。仅仅凭借这一点点信息，再牛的架构师设计出来的方案也是有局限性的
                - 这也是为什么前面说架构设计和模块抽象只能面向当下，它天然是短视的。这不是人的问题，这是开发方式的问题。

# 管理问题

- [白鳝的洞穴：从管理越多，做无用功越多谈起](https://mp.weixin.qq.com/s/53Co4kkoLIbRatnfrgXzsA)
