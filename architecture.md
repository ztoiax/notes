# 体系结构

- [两大图灵奖得主力作：计算机架构的新黄金时代](https://zhuanlan.zhihu.com/p/477346109)

    - DSA（Domain-Specific Architectures，特定领域的体系结构）

        - 登纳德缩放定律结束、摩尔定律衰退，而阿姆达尔定律正当其时，这意味着低效性将每年的性能改进限制在几个百分点。
            ![image](./Pictures/architecture/Moore's-law-整型程序的性能提升.avif)

        - DSA 受益于以特定领域语言（DSL）编写的程序，可以实现更高的并行性，更好的利用缓存（程序可以控制运动的存储器层次）

            - DSA例子：
                | DSA                      |
                |--------------------------|
                | GPU                      |
                | 深度学习的神经网络处理器 |
                | 软件定义处理器（SDN）    |

                - 谷歌的TPU 自 2015 年投入生产，它从搜索引擎到语言翻译和图像识别支持着谷歌各种各样的业务，同时也支持着 AlphaGo 和 AlphaZero 等 DeepMind 前沿研究。

                - 微软在其数据中心里部署了现场可编程门阵列器件（FPGA），专用于神经网络应用，对必应（Bing）搜索引擎的文件排名运算进行了硬件加速，得到了高达95%的吞吐量提升。

                - 通用任务的 CPU 通常支持 32 和 64 位整型数和浮点数数据。对于很多机器学习和图像应用来说，这种准确率有点浪费了。例如在深度神经网络中（DNN），推理通常使用 4、8 或 16 位整型数，从而提高数据和计算吞吐量。同样，对于 DNN 训练程序，浮点数很有意义，但 32 位就够了，16 为经常也能用。

            - DSL例子：
                | DSL                             |
                |---------------------------------|
                | 矩阵运算的语言 Matlab           |
                | DNN 编程的数据流语言 TensorFlow |
                | 编程 SDN 的语言 P4              |

    - 几个定律：

        - 摩尔定律（Moore's Law）：摩尔（Gordon Moore）在 1965 年的最初预测中，称晶体管密度会每年翻一番；1975 年，他又预计每两年翻一番。

            - 在 2000 年左右开始放缓。到了 2018 年，根据摩尔定律得出的预测与当下实际能力差了 15 倍。根据当前预测，这一差距将持续拉大，因为 CMOS 技术方法已经接近极限。
            ![image](./Pictures/architecture/Moore's-law.avif)

        - 登纳德缩放定律（Dennard scaling）：随着晶体管密度的增加，晶体管不断变小，但芯片的功率密度不变。由于每平方毫米硅芯片的计算能力随着技术的迭代而不断增强，计算机将变得更加节能。然而，登纳德缩放定律从 2007 年开始大幅放缓，2012 年左右接近失效

            - 每个芯片上的晶体管及每平方毫米的能耗。备注：2022年芯片功耗密度约440瓦/平方厘米
            ![image](./Pictures/architecture/Dennard-law.avif)

        - 阿姆达尔定律（Amdahl's Law）：增强（加速）某部分功能处理的措施后可获得的性能改进或执行时间的加速比
            - S=1/(1-a+a/n)
                - s为加速比
                - a为并行计算部分所占比例
                - n为并行处理结点个数

                - 当1-a=0时，(即没有串行，只有并行)最大加速比s=n；当a=0时（即只有串行，没有并行），最小加速比s=1；当n→∞时，极限加速比s→ 1/（1-a），这也就是加速比的上限。例如，若串行代码占整个代码的25%，则并行处理的总体性能不可能超过4。

            - 1986 年至 2002 年间，指令级并行（ILP）是提高性能的主要架构方法。而且随着晶体管速度的提高，其性能每年能提高 50% 左右。登纳德缩放定律的终结意味着工程师必须找到更加高效的并行化利用方法。

                - 然而，多核并不能解决由登纳德缩放定律终结带来的能效计算挑战。一个主要的障碍可以用阿姆达尔定律。如果只有 1% 的时间是串行的，那么 64 核配置可加速大约 39 倍，所需能量与 64 个处理器成正比，因此大约有 45% 的能量被浪费了。
                ![image](./Pictures/architecture/Dennard-law1.avif)

    - RISC:

        - 在今天的后 PC 时代，x86 的出货量从 2011 年的顶峰每年都会下降约 10%，而 RISC 处理器芯片出货量已经激增到了 200 亿。

        - DEC 工程师后来表明，更复杂的 CISC ISA 每个程序执行的指令数是 RISC 每个程序的 75%（上式第一项），在使用类似的技术时，CISC 执行每个指令要多消耗 5 到 6 个时钟周期（第二项），使得 RISC 微处理器的速度大约快了 3 倍。

    - 开发架构：要创建处理器中的「Linux」。开放式架构允许学术界和工业界的所有最佳人才帮助提高安全性

        - RISC-V

        - 英伟达 2017 年还宣布一个免费开放的架构，称之为英伟达深度学习加速器（NVDLA），这是一种可扩展的可配置 DSA，用于机器学习推理

    - 敏捷硬件开发。对架构师来说的一个好消息是，当代电子计算机辅助设计（ECAD）工具提高了抽象水平，使得敏捷开发成为可能，而且这种更高水平的抽象增加了设计的重用性。

-  波拉克法则（Pollack's Rule）则提出，同制程工艺下，处理器的性能提升幅度，是芯片面积（晶体管数量）提升的平方根。

- [对开发人员有用的定律、理论、原则和模式](https://github.com/nusr/hacker-laws-zh)

## RISC-V

> 要创建处理器中的「Linux」

- RISC-V 是一个模块化指令集。一小部分指令运行完整的开源软件堆栈，然后是可选的标准扩展，设计人员可以根据需要包含或省略。该基础包括 32 位地址和 64 位地址版本。

    | 标准扩展 | 操作            |
    |----------|-----------------|
    | M        | 整型数乘法/除法 |
    | A        | 原子内存操作    |
    | F/D      | 单/双精度浮点数 |
    | C        | 压缩指令        |

    - 即使架构师不接受新的扩展，软件堆栈仍然运行良好。专有架构通常需要向上的二进制兼容性，这意味着当处理器公司添加新功能时，所有未来的处理器也必须包含它。对于 RISC-V，情况并非如此，所有增强功能都是可选的，如果应用程序不需要，可以删除。

    - RISC-V 的指令少得多。base 中有 50 个指令，与原始 RISC-I 相近。剩余的标准扩展（M、A、F 和 D）增加了 53 条指令，再加上 C 又增加了 34 条，共计 137 条。ARMv8 有超过 500 条指令。

# GPU

- [腾讯大讲堂：英伟达 GPU 十年架构演进史](https://cloud.tencent.com/developer/article/1891497?areaSource=&traceId=)

- [Tales of the M1 GPU](https://asahilinux.org/2022/11/tales-of-the-m1-gpu/)

- [Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/)

# RDMA

- [RDMA技术详解（一）：RDMA概述](https://zhuanlan.zhihu.com/p/55142557)

# FPGA

- [FPGA, CPU, GPU, ASIC区别]()

- [HDLBits — Verilog Practice](https://hdlbits.01xz.net/wiki/Main_Page)
