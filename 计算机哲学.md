<!-- vim-markdown-toc GFM -->

* [理论](#理论)
    * [局部性与乐观思想](#局部性与乐观思想)
    * [分布式计算、超级计算机与神经网络共同的瓶颈](#分布式计算超级计算机与神经网络共同的瓶颈)
    * [高并发哲学](#高并发哲学)
        * [高并发的哲学原理（二）-- Apache 的性能瓶颈与 Nginx 的性能优势](#高并发的哲学原理二---apache-的性能瓶颈与-nginx-的性能优势)
        * [高并发的哲学原理（三）-- 基础设施并发：虚拟机与 Kubernetes（k8s）](#高并发的哲学原理三---基础设施并发虚拟机与-kubernetesk8s)
        * [高并发的哲学原理（四）-- 隐藏在语言背后的魔鬼：运行架构为何会成为性能瓶颈](#高并发的哲学原理四---隐藏在语言背后的魔鬼运行架构为何会成为性能瓶颈)
        * [高并发的哲学原理（五）-- 拆分网络单点(上)：应用网关、负载均衡和路由器(网关)](#高并发的哲学原理五---拆分网络单点上应用网关负载均衡和路由器网关)
        * [高并发的哲学原理（六）-- 拆分网络单点(下)：SDN 如何替代百万人民币的负载均衡硬件(网关、LVS、交换机)](#高并发的哲学原理六---拆分网络单点下sdn-如何替代百万人民币的负载均衡硬件网关lvs交换机)
        * [高并发的哲学原理（七）-- 最难以解决的单点：数据库以及它背后的存储](#高并发的哲学原理七---最难以解决的单点数据库以及它背后的存储)
        * [高并发的哲学原理（八）-- 将 InnoDB 剥的一丝不挂：B+ 树与 Buffer Pool](#高并发的哲学原理八---将-innodb-剥的一丝不挂b-树与-buffer-pool)
        * [高并发的哲学原理（九）-- 细数四代分布式数据库并拆解 TiDB 和 OceanBase（中间件、计算存储分离、列存储、CAP）](#高并发的哲学原理九---细数四代分布式数据库并拆解-tidb-和-oceanbase中间件计算存储分离列存储cap)
        * [高并发的哲学原理（十）-- 理论无限容量：站在地球表面](#高并发的哲学原理十---理论无限容量站在地球表面)
    * [Little’s Law（利特尔法则）](#littles-law利特尔法则)
    * [长尾理论](#长尾理论)

<!-- vim-markdown-toc -->

# 理论

## 局部性与乐观思想

- 局部性：

    - 空间局部性：

        - 如果一段内存被使用，那么之后，离他最近的内存也最容易被使用，无论是数据还是指令都是这样。

    - 时间局部性：如果一个变量所在的内存被访问过，那么接下来这一段内存很可能被再次访问
        - LRU和LFU算法

- 乐观思想：

    - L1 L2 L3 三级缓存

    - 虚拟内存

        - 虚拟内存依据计算机内存的局部性，将磁盘作为内存的本体，将内存作为磁盘的缓存，用很小的性能代价带来了数十倍并发进程数

    - 指令流水线与分支预测

        - 指令流水线的最佳情况：是每条流水线里的十几个指令都是正确的，这样完全不浪费时钟周期。

        - 分支预测器猜测条件表达式两路分支中哪一路最可能发生，然后推测执行这一路的指令，来避免流水线停顿造成的时间浪费。

    - 分布式计算：

        - 由 95% 可靠的 PC 机组成的分布式系统，起可靠性也不会达到 99.99%，但是绝大多数场景下，99% 的可靠性就够了，毕竟拿 PC 机做分布式比小型机便宜得多嘛。

    - 乐观锁

        - 在并发控制和数据库设计里都拥有重要地位，其本质就是在特定的需求下，假定不会冲突，冲突之后再浪费较长时间处理，比直接每次请求都浪费较短时间检测，总体的性能高。

- 乐观思想的代价

    - 虚拟内存中的内存的局部性突然大幅失效，磁盘读写速度成了内存读写速度，系统卡死

    - 分布式数据库的六台机器中的 master 挂了，系统在一秒内选举出了新的 master，你以为系统会稳定运行？master 挂掉的原因就是压力过大，这样就会导致新的 master 瞬间又被打挂，然后一台一台地继续，服务彻底失效。
        - 例子：[「故障说明」对六月六日 LeanCloud 多项服务发生中断的说明(7)](https://forum.leancloud.cn/t/leancloud/914)

            - 把 MongoDB 从 2.4 升级到了 2.6。新版本对地理位置的查询，以及 count 查询的准确性有所改进，所以我们认为这次升级对用户来说是值得的。但新版本的一个负面影响是，因为每次启动时要检查索引，所以启动时间大大延长了。而如果 MongoDB 是在出错的情况下重新启动，会导致大量的索引被重新建立，进一步延长启动的时间。

            - 在这个过程中，除了事故本身，我们在沟通上也犯了一些错误。当用户询问服务恢复时间时，我们给出了过于乐观的估计，但因为以上所说的原因，多个 MongoDB 节点经过了多次重启，实际恢复服务的时间晚了很多，这给用户造成了进一步的困扰。

## 分布式计算、超级计算机与神经网络共同的瓶颈

- x86服务器vs小型机：x86只有一个优点，其他的全是缺点
    - 缺点：性能、可靠性、可扩展性、占地面积都不如小型机
        - 小型机是专门设计的硬件和专门设计的软件，只面向这种规模（例如几百颗 CPU）的计算
        - 小型机是完全闭源的，不需要考虑扩展性，特定的几种硬件在稳定性上前进了一大步
        - x86 的 IO 性能被架构锁死了，各种总线、PCI、PCIe、USB、SATA、以太网，为了个人计算机的便利性，牺牲了很多的性能和可靠性
        - 小型机使用总线通信，可以实现极高的信息传递效率，极其有效的监控以及极高的故障隔离速度
        - x86 服务器基于网络的分布式具有天然的缺陷：
            - 操作系统决定了网络性能不足
            - 网络需要使用事件驱动处理，比总线电路的延迟高几个数量级
            - PC 机的硬件不够可靠，故障率高
            - 很难有效监控，隔离故障速度慢

    - 优点：价格。一个优点就决定了每年 2000 多亿美元的 IDC 市场被 x86 服务器占领了 90%

- x86 分布式计算：

    - 人们费这么大的劲研究基于网络的 x86 服务器分布式计算，目的是什么？还不是为了省钱，想用一大票便宜的 PC 机替换掉昂贵的小型机、大型机。

    - 现有的分布式计算，无论是 Hadoop 之类的大数据平台，还是 HBase 这样的分布式数据库，无论是 Docker 这种容器排布，还是 Redis 这种朴素分布式数据库

        - 其本质都是因为 x86 的扩展性不够好，导致大家只能自己想办法利用网络来自己构建一个宏观上更强性能更高负载能力的计算机。

    - 本质是把网络当做总线，设计了一套新的计算机体系结构：
        - 每一台机器就等于一个运算器加一个存储器
        - master 节点就是控制器加输入设备、输出设备

    - 缺点：上古时代，小型机的扩展能力是非常变态的，到今天，基于小型机的 Oracle 数据库系统依旧能做到惊人的性能和可靠性。实际上单颗 x86 CPU 的性能已经远超 IBM 小型机用的 PowerPC，但是当数量来到几百颗，x86 服务器集群就败下阵来

- master 失效问题

    - 无论怎样设计，master 失效必然会导致服务异常，因为网络本身不够可靠，所以监控系统的容错要做的比较高，所以基于网络的分布式系统的故障恢复时间一般在秒级。而小型机的单 CPU 故障对外是完全无感的。

    - 现行的选举机制主要以节点上的数据以及节点数据之间的关系为依据，通过一顿猛如虎的数学操作，选举出一个新的 master。逻辑上，选举没有任何问题，如果 master 因为硬件故障而失效，新的 master 会自动顶替上，并在短时间内恢复工作。
        - 1.硬件故障概率极低，大部分 master 失效都不是因为硬件故障
        - 2.如果是流量过大导致的 master 失效，那么选举出新的 master 也无济于事：提升集群规模才是解决之道
        - 3.即使能够及时地在一分钟之内顶替上 master 的工作，那这一分钟的异常也可能导致雪崩式的 cache miss，从磁盘缓存到虚拟内存，从 TLB 到三级缓存，再到二级缓存和一级缓存，全部失效。如果每一层的失效会让系统响应时间增加五倍的话，那最终的总响应时长将是惊人的。

- 系统规模问题：

    - 无论是 Master-Slave 模式还是 Proxy 模式，整个系统的流量最终还是要落到一个特定的资源上。当然这个资源可能是多台机器，但是依旧无法解决一个严重的问题：系统规模越大，其本底性能损失就越大。

    - 这其实是我们所在的这个宇宙空间的一个基本规律。我一直认为，这个宇宙里只有一个自然规律：熵增。既然我们这个宇宙是一个熵增宇宙，那么这个问题就无法解决。

- MapReduce 的基本思想：

    - 由于数据流实在是太大，所以需要基于磁盘，这样数据就被天然地分布到了多台机器上，然后“就地计算”即可，这被称作“计算向数据靠拢”。

    - 除此之外，MapReduce 还提供了全套的数据分片、信息交换、任务分发和聚合功能，使用者只需要使用自己的编程语言，分发任务即可，使用者甚至不需要知道具体的并发模型是怎么设计的，用就完了。

- Redis、MongoDB 的分布式：

    - Redis 有两个不同的分布式方案：

        - 1.Redis Cluster 是官方提供的工具：它通过特殊的协议，实现了每台机器都拥有数据存储和分布式调节功能，性能没有损失。缺点就是缺乏统一管理，运维不友好。

        - 2.Codis：通过一个 proxy 层，完全隔离掉了分布式调节功能，底层的多台机器可以任意水平扩展，运维十分友好。

    - MongoDB 官方提供了一套完整的分布式部署的方案：

        - 提供了 mongos 控制中心，config server 配置存储，以及众多的 shard（其底层一般依然有两台互为主从强数据一致性的 mongod）。这三个组件可以任意部署在任意的机器上，MongoDB 提供了 master 选举功能，在检测到 master 异常后会自动选举出新的 master 节点。

- 机器学习的瓶颈：

    - 本质也是数据交换：机器学习需要极多的计算，而计算速度的瓶颈现在就在运算器和存储器的通信上，这也是显卡搞深度学习比 CPU 快数十倍的原因：显存和 GPU 信息交换的速度极快。

## 高并发哲学

- 一提到高并发，很多人的第一反应都可以归纳为以下两种情况：
    - 1.进程间通信(IPC)、共享内存、管道、队列、事件：这是学院派
    - 2.内存缓存、消息队列、分库分表、NoSQL、ES 搜索：这是实战派
    - 无论是学院派还是实战派，其背后的哲学原理都是一样的。——找出单点，进行拆分。

- 高并发问题的解决思路：性能问题要靠架构解决。

    - 在架构上动刀是最简单的，也是最容易获得收益的

        - 例子：MySQL 单机性能优化(软件优化)、x86 CPU 多核性能提升(硬件优化)，拆到微观来看，也是在做架构优化

    - 没有银弹就是计算机世界的第一准则，你想获得收益，总得拿出一些东西，和信息之神交换。

- 找出单点，进行拆分，就是将每一个大单点都拆成一个小单点+多资源并行的形式。

    - 在解决高并发问题的过程中，我们会不断地遇到新的单点：web server、单个操作系统、虚拟化/容器技术、编程语言运行架构、网络、UNIX 进程模型、数据库等。每遇到一个单点，我们都要见招拆招，使用架构工具拆掉它。计算机的虚拟化程度非常高，几乎每个单点都可以继续往下拆。

    - 动静分离：

        - Apache 和 Nginx 的性能测试，在本机访问同一张 jpg 图片的情况下，Apache 的 QPS 为 2 万出头，而 Nginx 则超过 8 万，四倍性能。

        - 所以，如果你还在用 Apache 承载所有流量，在前面加一个 Nginx 就能显著降低 CPU 占用率，大幅提升系统性能。如果你再利用云服务商把这些静态资源用 CDN 来承载，你的静态资源压力还能再降低 90%。

    - 动静分离以后，CPU 又满了，该怎么办呢？这个时候就需要把数据库拆出去了。

        - 只要你的系统不是用户极其少，或者你们公司极其扣，把数据库独立部署的收益都是要高于投入的：1 核 2G 的虚拟机就够 MySQL 跑到 200 QPS了，配合缓存支撑一个日 PV 100 万的小系统应该够了。

        - 2017 年，我维护的一个 SEO 网站突然遭遇大量爬虫的袭击：由于这个网站拥有数百万个内容页面，页面内也有着大量的“类似文章推荐”，在只依靠 MySQL like语句的情况下，单个页面的返回时间长达 300-500ms。

            - 一天两万的真实用户 UV 对系统的压力并不大，但这些爬虫不讲武德，上来就是 100 QPS，当时 1 核 2G 的虚拟机和 1 核 1G 的 MySQL 可遭了殃了，完全顶不住。

            - 这些爬虫并不是正规大厂的爬虫，而是采集机器人，由于拥有海量代理 ip，对网站形成了 DDOS 态势，没法使用常规手段封禁，只能想办法抗住。

            - 我首先做的，就是将静态资源全部 CDN 化，直接让 CPU 占用率降低了一半。然后就开始着手提升系统性能：
                - 1.使用 ElasticSearch 提供“类似文章推荐”，将每个页面的响应时间压缩到了 200ms

                - 2.提升数据库性能：增加索引，增加 Redis 缓存，使用定时任务刷新文章总数而不是实时计算，将响应时间压缩到了 120ms

                - 3.访问 ES 的 HTTP 请求进行并行化：虽然 PHP 是一种阻塞语言，但是一次性发送多个 HTTP 请求的能力还是有的，平均每个页面有五次请求，每次 15ms，并行化以后从 15ms*5 减少到了 25ms，最终将平均响应时间压缩到了 70ms

                - 同时，服务器和数据库也进行了计算资源的扩容，增加到了 2 核 4G 的虚拟机和 2 核 4G 的 MySQL，最终顶住了每天 200 万次页面访问的冲击，对比之下，真实用户 PV 每天只有十万左右。

            - 这个时候可能有人会问了，既然是内容网站，为什么不静态化呢？因为数据量太大了，500 万个页面，一个页面 100KB，就是 476GB 的磁盘容量，这个量级太夸张了，不如做性能优化硬抗了，这么多静态资源的管理和刷新反而是个更大的问题。在百万量级下，数据库绝对是更好的数据存储解决方案，远比自己管理文件要更简单更稳定。

            - 即便我做了那么多，还是不乏有一些爬虫愣头青在学习了 swoole 和 go 协程之后，对我的网站发动数千 QPS 的死亡冲锋，这个时候再怎么性能优化都是没用的，这时就需要使用倒数第二个工具：限流。
                - 1.针对单个 ip 做请求频率限制
                - 2.针对整个 /24 ip 段做请求频率限制（很多爬虫采用同一段内的多个 ip 绕过限流）
                - 3.针对每个 UA 做请求频率限制

### 高并发的哲学原理（二）-- Apache 的性能瓶颈与 Nginx 的性能优势

- [岁寒博客：高并发的哲学原理（二）-- Apache 的性能瓶颈与 Nginx 的性能优势](https://github.com/johnlui/PPHC/tree/main/02.%20Apache%20%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88%E4%B8%8E%20Nginx%20%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8A%BF)

- Nginx 的 epoll 比 Apache 的 select 性能高

    - epoll：简单来说，就是：转守为攻

        - epoll 化被动为主动，以前需要两次遍历才能实现的网络数据包和线程的匹配，现在通过事件驱动的方式主动献上指针，性能暴增。

            - 这就像云原生时代的 Prometheus 监控：化主动上传为被动查询，大幅提升单个采集节点的性能上限，成功解决了监控领域的高并发性能问题。

        - 在 5K 个 TCP 连接的情况下，每收到一个数据包，Nginx 找到对应线程的速度比 Apache 高了两个数量级，即便是 event 模式下的 Apache，性能依然远低于 Nginx，因为 Nginx 就是专门为“反向代理”设计的，而 Apache 本质是个 web 应用容器，无法做到纯粹的事件驱动，性能自然无法和 Nginx 相比。

- Apache 支持三种进程模型：prefork、worker 和 event

    - prefork 是进程模式，需要消耗更多的内存，每次接到一段新的数据，需要使用 select 模型，遍历 TCP连接数 x 进程数 这么多次才能找到匹配的进程，在数千个 TCP 连接下，光是寻找线程就需要消耗掉一个 CPU 核心，单机性能达到极限，无法利用更多的 CPU 资源

    - worker 是线程模式，依旧使用 select 模型来遍历 TCP 请求和线程，性能上限和 prefork 一致，区别是内存消耗量有了一些降低，初始 TCP 承载能力稍好，请求数突然增加的场景下，开新线程的速度反而比 prefork 更慢，且基础延迟比 prefork 模式更高

    - event 模式采用和 Nginx 一致的 epoll 模型承载，理论上表现和 Nginx 一致，但由于 Apache 大概率和 mod_php（插件）模式的 PHP 一起部署，由于 PHP 阻塞运行的特性，性能和上面两兄弟并无明显区别。而且即便是 event 模式下的 Apache，性能依然远低于 Nginx。

- Nginx epoll 和 Apache prefork 模型相比

    - 优点：

        - Nginx 每个 worker 进程可以 handle 上千个 TCP 连接，消耗很少的内存和 CPU 资源，可以让单台服务器承接比 Apache 多两个数量级的用户量，相比于 Apache 单机 5K 的 TCP 连接数上限（对应的是 2000 个在线用户），是一个巨大的进步

        - Nginx 对 TCP 的复用使它非常善于应对海量客户端的直接连接，根据我的实测，在 HTTP 高并发下 Nginx 的活跃 TCP 连接数可以做到 Apache 的五分之一，而且用户量越高，复用效果越好

        - 在架构上，基于 FastCGI 网络协议进行架构扩展，也可以更轻易地利用多台物理服务器的并行计算能力，提升整个系统的性能上限

    - 缺点：在低负载下，Nginx 事件驱动的特性使得每个请求的响应时长比 Apache prefork 模式略长一些（14ms vs 9ms）

- 压力测试
    - Nginx + fpm 一共发出了 59146 个请求，成功了五万个
    - Nginx + Apache 一共发出了 56464 个请求，成功了五万两千个，比 fpm 还多一些
    - nginx+php-fpm 模式最大 QPS 为 800 但比较稳定，Nginx + Apache 最大 QPS 1000 但不够稳定
    - 至于 Apache 标准模式，显然它的技术架构不足以处理 5000 个 TCP 连接下 1000 QPS 的状况，QPS 低且不稳定，错误率高达 43%

    - 结论：

        - Apache + prefork 的问题在于它对数千个 TCP 连接的处理能力不足。
            - 提升 Apache 性能只需要在前面加一个 Nginx 作为 HTTP 反向代理即可，因为此时 Apache 只需要处理好和 Nginx 之间的少量 TCP 连接，性能损耗较小

        - php-fpm 和 mod_php 在执行 PHP 的时候没有任何性能差异

- 你的系统就是无法离开 Apache，该怎么承接高并发呢？有办法：既然单机不行，那就把单机虚拟化成多个 linux 机器，就能顶得住高并发了。

    - 一个负载均衡服务器 + 多个上游服务器的技术架构正是“找出单点，进行拆分”思想的具体体现。

    - 基于虚拟化做多节点集群，可以相对线性地提升系统性能，你只要在前面搭建一个负载均衡即可。

    - 那我们就仔细思考一下，Apache 架构中，到底那个单点是不好拆的，哪些部分是可以并行的？

        - 监听 443 端口的进程（root 用户）是单点，也能拆

        - 在单机上，PHP 解释器进程本身就是并行的，那我们把它拆到多台机器上，就是顺理成章的事情。

### 高并发的哲学原理（三）-- 基础设施并发：虚拟机与 Kubernetes（k8s）

- [岁寒博客：高并发的哲学原理（三）-- 基础设施并发：虚拟机与 Kubernetes（k8s）](https://github.com/johnlui/PPHC/tree/main/02.%20Apache%20%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88%E4%B8%8E%20Nginx%20%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8A%BFttps://github.com/johnlui/PPHC/tree/main/02.%20Apache%20%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88%E4%B8%8E%20Nginx%20%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8A%BF)

- 百亿架构：我为自研电商设计的可伸缩技术架构

    ![image](./Pictures/计算机哲学/kong架构.avif)

    - 经过一年多的运行，我发现它撑到年 GMV 100 亿问题不大（表示这个电商平台在特定时间内的总交易额达到了 100 亿人民币）

        - 以今年十多亿的 GMV 为例，目前 2 核 4G kong 网关虚拟机的 CPU 占用最大只到了 20%，那 8 核 kong 网关应该就能顶住 100 亿的冲击了。

    - 这套架构的核心是两个东西：kong 网关和服务发现。

- kong网关

    - 必须有东西来承接“监听 443 端口”这个单点，在这里我选择了 kong 网关作为 HTTP 反向代理服务器，将用户的海量 HTTPS 请求 handle 住，再以 http 协议发送到后端的多台 2 核 4G 虚拟机上。

    - Kong 是基于国产 OpenResty 技术的开源网关，OpenResty 将非常轻量的 lua 语言嵌入了 Nginx 生命周期，大幅扩展了 Nginx 的功能。Kong 除了拥有 HTTP 网关的一整套功能外，还有插件系统和基于数据库的水平扩展能力，理论上可以支撑超高并发的系统。

- 服务发现

    - 在流量低谷期我们使用一台虚拟机跑 Apache 作为上游服务器，在开团前需要再开出来一台上游服务器的话，Kong 该怎么知道这台服务器开出来了，并且获取到他们的 ip 呢？使用服务发现技术。

    - 原理：构造一个共识集群，各个节点之间会使用固定的端口相互通信，当新的上游服务器开机后，它上面的 consul 服务会开机启动，之后就会和配置好的一个 master 的 ip 进行通信，加入这个集群，并广播本机可以提供的服务名称，假设名叫up。

    - Kong 向 consul DNS 发送一个查询：查找up.service.consul这个域名对应的 ip，之前，这个域名只会返回一个 ip，在新机器开机并成功加入集群后，这个域名对应的就是两个 ip 了，Kong 就可以把 HTTP 请求均匀地发送给新旧两台上游服务器了。

- 虚拟化技术

    - 在一台裸金属服务器的操作系统内直接运行 Apache、MySQL、Redis、ElasticSearch，和开4台虚拟机分别运行他们，到底有什么区别？

        - 1.资源隔离：

            - 后端技术拥有很多成熟的开源软件，每个软件都拥有独特的发展路径，百花齐放，群魔乱舞。如果把所有服务都装在裸金属服务器上，理论上讲使用内存管道通信的效率比虚拟机之间通过虚拟以太网通信还要更高，但是资源隔离就难做了。

            - 拥有自我资源限制能力的软件不多，大部分软件都是“有多大屁股穿多大裤衩”：根据请求压力任意获取计算资源，这就让计算资源的分配容易出现问题，导致木桶效应，最终导致系统整体性能反而更低。

        - 2.降低运维复杂度

            - 市面上成熟的监控软件都是基于操作系统的，进程也能监控，但是比较困难。控制虚拟机也比控制进程要更加容易。而k8s 容器平台更加灵活高效

            - 时至今日，VMWare 在超融合领域也拥有统治地位：基于三台服务器的小集群，就可以提供高可用架构的全套基础设置：统一应用网关、共享存储、虚拟机热漂移、自动故障转移等。

                - 如果只用一台物理服务器直接安装 Linux，很显然这些高可用特性都做不到，一旦这台物理机的某个部件发生了故障导致宕机的话，全部服务都会挂掉。

        - 3. 隐藏价值：性能氮泵

            - 由于很多软件都拥有 Apache 一样的“单机性能极限”，所以虚拟化技术将单机拆成多机，就可以直接实现性能增益。

                - 如果你把 Apache、Redis、MySQL、ElasticSearch 都装在裸金属操作系统上的话，他们就会异口同声说：给我那么多核心有什么用，我真的用不上啊。

            - Redis 的单机性能极限：

                - 两核就能做到十万 QPS，你给他 32 核，还是十万 QPS，对资源是一种浪费。

                - 在前几天 Redis 回应新兴内存数据库 Dragonfly 挑战的文章中，Redis 维护团队建议大家搭建“单机集群”¹ 来实现对机器上所有 CPU 的完全利用

                - 而且，基于虚拟化技术搭建多虚拟机上的 Redis 集群，是一种比单机集群更加稳妥的高性能 Redis 解决方案。

            - MySQL 的单机性能极限

                - 如果我拿最新的双路 AMD EPYC 9654 96 核服务器来跑单机 MySQL 呢？显然单节点 MySQL 无论如何是无法吃完 192 个物理核心，384 个线程的，而它的性能极限也会停在几万 QPS。

                - web 系统的瓶颈在数据库，数据库的瓶颈在存储

                - 实际上，标准 MySQL 的性能瓶颈在内存容量和磁盘速度，对 CPU 资源的需求并不是很高，在两台虚拟机拥有独立固态硬盘的情况下，把 16 核虚拟机拆成两台 8 核虚拟机并打造成一个半同步一主一从的 MySQL 集群，便可以轻松将数据库的读性能提升一倍，只需要稍微牺牲一丢丢写性能。

            - ElasticSearch 的单机性能极限

                - ES 作为一个 Java 应用，显然拥有着明确的单机性能极限：线程切换需要读写内存，性能上限就在那里。ES 自己就采用了自选举集群架构来实现水平扩展：官方建议单节点不要超过 32GB 内存。

                - 如果你的 CPU 和内存很多，就可以基于虚拟机技术做多节点 ES 集群，ES 集群的扩展能力是非常不错的：作为一个搜索引擎，大家竟然都拿他当数据库用，从这里就足以看出它优秀的水平扩展能力。

    - k8s 技术的本质

        - Docker 实现了一次构建、处处运行

        - Docker 项目还在容器镜像的制作上引入了“层”的概念，这种基于“层”（也就是“commit” ) 进行 build，push，update 的思路，显然是借鉴了 Git 的思想。所以这个做法的好处也跟 Github 如出一辙：制作 Docker 镜像不再是一个枯燥而乏味的事情

        - Docker 的成功主要就是靠的 DockerHub，它将开源软件推进了一大步：开源软件可以直接分发“下载即可用”的标准化软件镜像，大家可以像在开源社区协作一样，在镜像社区协作，一层一层地搭建出适合自己的镜像，人类作为群居动物的本能嘎的一下就觉醒了。

        - 它可以实现虚拟机一样的功能——资源隔离、降低运维复杂度和性能氮泵，而且，它还可以在裸金属环境下快速部署出一个数千台服务器的集群。

        - 传统虚拟机镜像巨大、启动缓慢、多个操作系统同时运行带来了资源浪费、迁移缓慢、管理困难，而 k8s 镜像很小，启动迅速，资源损耗低，管理 API 丰富，更是可以轻易实现“单机多实例部署”和“目录共享”，是海量服务器新时代的优秀基础架构。

    - 通过使用负载均衡 + 虚拟机/负载均衡 + k8s，在依然使用前面那台双路 E5-2682 V4 64 vCore 的情况下，我们可以把单个系统的 QPS 从上篇文章的 1000 提升到 5000。

### 高并发的哲学原理（四）-- 隐藏在语言背后的魔鬼：运行架构为何会成为性能瓶颈

- [岁寒博客：高并发的哲学原理（四）-- 隐藏在语言背后的魔鬼：运行架构为何会成为性能瓶颈](https://github.com/johnlui/PPHC/tree/main/04.%20%E9%9A%90%E8%97%8F%E5%9C%A8%E8%AF%AD%E8%A8%80%E8%83%8C%E5%90%8E%E7%9A%84%E9%AD%94%E9%AC%BC%EF%BC%9A%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84%E4%B8%BA%E4%BD%95%E4%BC%9A%E6%88%90%E4%B8%BA%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88)

- 编程语言的性能差异是程序员社区经久不衰的话题，但当你对各种技术的了解越深入，就越能感受到各种语言的本质区别：不同语言的设计方向不同，就像时间换空间、空间换时间，他们只是选择了一种优势找信息之神换成了另一种优势罢了。

    - 没有任何编程语言是单纯的“语法集合”，每一种语言都是它背后“运行架构”的体现，语言之间的差异本质上就运行架构设计方向的差异。

- web 系统规模发展史

    - web 1.0 时代，各种静态、动态、解释型、编译型、虚拟机型语言百花齐放，因为当时系统规模和系统用户都比较少，而资源则大多以静态 HTML 页面的形式显示，技术上大家都熟悉哪个用哪个，这些后端技术也大多能满足需求。

    - web 2.0 时代，真正的高并发系统出现了，一分钟内需要写入数据的用户数超过了百万，这个时代，最终锤炼出了 Java 和 PHP 两种技术：

        - PHP 擅长简单 CURD
        - Java 擅长事务处理（例如电商下单）
        - 这个时代发展到顶峰，就是手机 APP 和大前端的时代：界面由前端完全掌控，后端团队提供稳定高性能的 API 即可。

        - 在 web 生态发展的过程中，也催生出了如 Python、Ruby、Scala、Node.js 这样的后端技术之花，但他们在冲向顶峰后也迅速落幕，现在连 PHP 也在逐步退场，只有 Java 由于拥有完善的微服务基础设施，暂时看起来还安全。

    - web 2.0 后期，乔布斯将人类拉入了移动互联网时代。

        - 今天的互联网巨头们，同时在线用户量动辄上亿，对系统性能的需求发生了爆炸性的增长，也催生出了 PHP 的接班人：go 语言。十多年前我第一次写 go 的时候就认识到，它就是 C with net，自带网络库的万能底层语言，可以让普通开发者轻松写出超高性能的应用。

- 语言特性如何决定性能

    - PHP 语言是一种单线程全阻塞语言：

        - 在每个 HTTP/FastCGI 请求中，PHP 解释器会启动一个 进程/线程 来运行一段 PHP 代码，在运行的时候，无论是读写磁盘（磁盘 IO）还是读写数据库（网络 IO），PHP 线程都会停下来等待：此时并不消耗 CPU 资源，但是 TCP 和线程资源都还在持续等待，如果这个请求不结束，那该线程将会一直保持运行，持续消耗着 TCP 和内存资源。

        - 由于语言本身的运行架构一致，所以 php-fpm 和 Apache 执行 PHP 的性能是一致的。在 2 vCore 4G 内存的情况下，PHP 200QPS 的性能极限是无法通过把 Apache 换成 php-fpm 来解决的。

        - 那么阻塞式运行架构的性能瓶颈应该怎么突破呢？轮到 Node.js 登场了。

    - Node.js 的非阻塞 IO：

        - Ryan Dahl 敏锐地发现了 IO 浪费时间这个问题，并且挑选了一个为浏览器创造的单线程语言 JavaScript 来实现他的抱负：将所有 IO 操作全部异步化，并利用 js 的单线程排队特性，创造了一种高性能且稳定的后端技术：Node.js。

        - 不过，计算机的世界没有银弹，Node.js 虽然性能强，但是代码编写起来更加困难，需要多付出一些异步编程的思考时间，debug 也更加地困难。

            - 在阻塞式语言中，所有的 IO 操作都是需要停下来等待的，例如磁盘 IO，数据库网络 IO 等，而真正用于计算的 CPU 资源反而大多数时候在浪费：绝大多数 API 不需要多少复杂的数据转换，更多的时间花在了和各种数据库的通信上。而世界上绝大多数语言都是阻塞式运行的，因为这样做虽然性能不高，但却最符合人类大脑的习惯，编码也更加容易。在当时，高性能大多是用多核+多进程/线程来实现的。

        - Node.js 是一种非常神奇的单线程异步非阻塞架构，以 Google v8 引擎作为 JavaScript 解释器，利用事件驱动技术，大幅提升了单机能够处理的 QPS 极限，而它“只是完整利用了单核 CPU”而已。
        - Node.js 还具备一个 Nginx 的优势：可以单机处理海量用户的 TCP 连接。
        - Node.js 可以完整利用单核 CPU 了，那现在的服务器 CPU 已经做到了单颗 96 核 192 线程，该如何利用这么多的 CPU 核心呢？该 golang 登场了。

    - go 语言的协程

        - 为了更好地“直接利用全部 CPU”，Java 诞生了线程池技术，至今还在发光发热；而 golang 选择釜底抽薪：在语言层面打造一个完善的“超并发”工具：goroutine（协程）。

            - 我之所以将 goroutine 称为“超并发”工具，是因为它是语言提供的一个 线程池+协程 的综合解决方案，并使用 channel 管道思想来传递数据，为使用者提供了一个无需手动管理的高性能并发控制 runtime，可以保证完全榨干每一个 CPU 时间片。

            - golang 的协程本质上来讲就是 在一个线程内不断地 goto，就像 DPDK 完全在用户态运行由于避免了上下文切换而大幅提升了网络性能一样，golang 在线程内主动 goto 也可以轻松将 CPU 利用率顶到 100%，实现硬件资源利用的最大化。

            - 当然，不断地 goto只是一种形象的类比方法，实际上 golang 的协程技术经历了好几次迭代，具体实现大家可以看灯塔 draveness 的书：《Go 语言设计与实现》¹。

        - goroutine 的弱点

            - 就像性能优化的核心是空间换时间、时间换空间一样，goroutine 也不是银弹，也是牺牲了一些东西的。根据我的实践，这个东西就是“极其昂贵的内存同步开销”，而且 goroutine 引发的这个问题比 Java 的线程池内存同步问题严重的多。

            - 一旦你想在单个 golang 进程内部的海量协程之间做“数据同步”，那你面临的就不只是 CPU 资源浪费那么简单了，你会发现，CPU 依然吃完了，但是并发量还是好低：多线程的内存同步开销已经摧毁了无数根 Java 程序员的头发，goroutine 线程 * 协程 的内存同步性能堪称灾难:

        - Redis 是 golang 协程最亲密的伙伴，就像 MySQL 之于 PHP

            - 网络栈是一种贯彻了 linux 一切皆文件思维的优秀工具，此时可以帮上大忙：找另一个单线程性能之王 Redis 打辅助，即可帮助海量协程排队：此时一旦某个协程进入网络 IO 状态，则会立即让出 CPU 时间片：goto 到下一个协程，不浪费 CPU 资源。

            - 当然，你也可以选择自己用 golang 写一个类似 Redis 的单线程内存数据库，和你的业务进程进行网络通信，也可以解决这个问题。

            - 一旦解决了协程之间内存同步的问题，golang 就开始胡吃海塞，大杀四方，榨干 CPU 的全部性能潜力。

        - 通过使用 golang，我们依然使用前面那台双路 E5-2682 V4 64 vCore，在数据库性能足够的情况下，我们可以把单个系统的 QPS 从 5000 提升到 50000，并且可以在裸金属服务器上直接部署，不需要虚拟机/k8s 并发基础设施，甚至都不需要前置一个负载均衡器。

            - 当然，现实中 50000 QPS 的系统几乎必然拥有负载均衡器，即便每个接口只返回 20KB，那网络带宽也已经达到了 976MB/S，即 7.8Gbit，单机带宽都快干到 10G 了，肯定是不会只用单台服务器硬抗的，即使单机性能能达到，那单机也无法保证这么大规模系统的稳定性。这个时候我们就需要负载均衡器的介入

    - Java 技术的优势

        - Java 是一整套基于运行时虚拟机技术的解决方案。总体来看，它选择了“空间换时间”：Java 应用对内存的需求量显著超过其它技术，而经过了这么多年的优化，Java 的“时间性能”在绝大多数场景下都已经做到了无限接近 C++ 的水平。

        - Java 虽然是虚拟机技术，但它是常驻内存的，并且这个技术非常的灵活。对，你没有看错，Java 技术确实非常灵活。spring 框架对写代码程序员的约束确实很强，但这是对使用者的繁琐，Java 本身是非常灵活的。

        - 经过了这么多年的发展，Java 其实一直都能跟上时代：JDBC、RMI、反射、JIT、数字签名、JWS、断言、链式异常、泛型、注解、lambda、类型推断等等等等。我们知道，传统的 Java 大多采用线程做并行，但是在今年（2022）它甚至发展出了协程 Fiber！

        - 21 世纪头十年，JVM 在很多公司内都变成了代替虚拟机技术的存在，成为了事实上的“标准服务端运行环境”，以至于诞生了 JPython、JRuby、JPHP 等颇具邪典气质的技术：把动态语言的解释器内置到 JVM 内，再把代码和解释器打包成一个 jar/war，让 JVM 可以直接运行 Python、Ruby、PHP 项目。

            - 这是什么，这就是容器技术啊！

### 高并发的哲学原理（五）-- 拆分网络单点(上)：应用网关、负载均衡和路由器(网关)

- [岁寒博客：高并发的哲学原理（五）-- 拆分网络单点(上)：应用网关、负载均衡和路由器(网关)](https://github.com/johnlui/PPHC/tree/main/05.%20%E6%8B%86%E5%88%86%E7%BD%91%E7%BB%9C%E5%8D%95%E7%82%B9(%E4%B8%8A)%EF%BC%9A%E5%BA%94%E7%94%A8%E7%BD%91%E5%85%B3%E3%80%81%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E8%B7%AF%E7%94%B1%E5%99%A8(%E7%BD%91%E5%85%B3))

- 应用网关：又称 API 网关，顾名思义，它就是所有 API 请求的大门：自己接下所有的 HTTP/HTTPS/TCP 请求，再将请求转发给真正的上游服务器。

    - 上游服务器可能是一堆虚拟机，也可能是一堆容器，甚至可以是多个数据中心各自的应用网关。

    - 常见的应用网关软件有 HAProxy、Nginx、Envoy 等，而 Cisco、Juniper、F5 等一体化设备厂商也有相关的硬件产品。

    - 优势：

        - 1.解放后端架构：各种语言、各种技术、各种部署形式、甚至全国各地的机房都可以成为某条 URL 的最终真实服务方，让你的后端架构彻底起飞。

        - 2.TLS 卸载：终端用户访问应用网关的时候采用的是 HTTPS 协议，这个协议是需要对数据进行加密解密的，应用网关非常适合干这件事情，而背后的业务系统只提供标准 HTTP 协议即可

        - 3.身份验证和安全性提升：应用网关可以对后端异构系统进行统一的身份验证，无需一个一个单独实现。

        - 4.指标和数据收集：由于所有流量都会经过网关，所以对指标进行收集也变的简单了，你甚至可以将双向流量的内容全部记录下来，用于数据统计和安全分析。

        - 5.数据压缩与转换：应用网关还可以统一对流量进行 gzip 压缩，可以将所有业务一次性升级到 HTTP/2 和 HTTP/3，可以对数据进行格式转换（XML 到 JSON）和修改（增加/修改/删除字段），总是就是能各种上下其手，翻云覆雨，随心所欲。

    - 应用网关的另一个价值就是负载均衡了：
        - 可以做红蓝发布和金丝雀发布
        - 可以针对流量特点做灰度发布
        - 可以主动调节各个后端服务器的压力
        - 屏蔽失效的后端服务器等等

    - 虽然应用网关和负载均衡是两个不同的概念，但在低负载系统里，他们两个往往由同一个软件来扮演，例如前面说到的 Kong 网关就同时具备这两个功能。

    - 应用网关怎么拆？

        - 如果单个应用网关扛不住五万 QPS，那我们搞一个负载均衡器放在应用网关的前面

        - 并没有要求应用网关只能由一台服务器来承接，换句话说，应用网关不是单点，只要多个节点的行为一致，那就可以共同承接这五万 QPS 的真实用户流量。

        - Kong 集群：在多台机器上装上同样版本的应用网关软件，然后在他们之间同步配置文件即可。Kong 采用的策略是让多个实例连接同一个PostgreSQL数据库，每五秒从数据库获取一次最新的配置，如果数据库挂掉，那就保持内存中的现有配置继续运行。

            - 类似思维还有：DNS 分布式拆分、列存储 clickhouse

            ![image](./Pictures/计算机哲学/kong集群+负载均衡.avif)

    - 负载均衡器为何能抗住五万 QPS？

        - 既然单机的 Nginx 都顶不住五万 QPS 带来的 TCP 资源开销，那负载均衡器如何抗住呢？因为负载均衡器承载的是比 Nginx 所承载的 TCP 更下面一层的协议：IP 协议。

        - 在真实世界中，QPS 一般比保持 TCP 连接的客户端的数量要少，在此我们假设为四分之一，即：有 20 万个客户端设备在这段时间内访问我们的系统，每个客户端设备平均每 4 秒发送一个 HTTPS 请求。

        - 单台 Nginx 反向代理的性能极限

            - 由于 Nginx 不仅需要建立 TCP 连接，还需要将 TCP 连接中发送过来的数据包和某个进程/线程进行匹配，还需要对 HTTP 协议的信息进行解析、识别、转换、添加，所以它也有 QPS 上限：

            - 在 2015 年主流的服务器 CPU 上，Nginx 官方在进行了极限优化的情况下进行了反向代理性能测试，在“建立 TCP 连接-发送 HTTPS 请求-断开 TCP 连接”的极限拉扯下，最高性能为 6W QPS（SSL TPS RSA 2048bit）²。

            - 假设我们使用最新的服务器硬件，当虚拟机 CPU 达到 32 vCore 的时候，未经优化的单机 Nginx 性能就已经达到极限，能承受大约 1 万 HTTPS QPS，对应的连接用户就是 4 万，这个数字其实已经很夸张了。

        - 我们假设单台 Kong 应用网关的极限为 1 万 QPS，于是我们就需要五台 Kong，那这五台 Kong 前面的 TCP 负载均衡为何能够抗住呢？因为 TCP 负载均衡器要干的事情比 Kong 少非常多：它只需要在 IP 层做少量的工作即可。

        - TCP 负载均衡器（NAT）的工作过程

            ![image](./Pictures/计算机哲学/kong集群+负载均衡1.avif)

            - 注意，负载均衡器只是接收了一个 IP 报文，并没有和客户端进行三次握手，并没有和客户端建立“TCP 连接”

            - 左侧，隐藏了路由器：客户端和负载均衡器之间是使用公网 ip 通信的，他们俩是在全球互联网内的两台对等设备，只是数据包经过了很多个真·路由器的“路由”操作，双方才能收到对方发送的数据包。

            - 右侧，隐藏了交换机：负载均衡器和上游服务器通信的时候采用的是内网 ip：10.0.0.100 和 10.0.0.1，他们俩是怎么通信的呢？通过交换机。

            - 这个操作在网络领域内被称作 NAT（网络地址转换）。
                - 1.负载均衡器收到了一个 ip 报文：源地址 123.123.123.123，目的地址 110.242.68.3
                    - ip 报文内包裹着一个 TCP 报文，详情如下：源端口 52387，目的端口 443
                - 2.在接收到客户端的 IP 报文以后，负载均衡器会找一台上游服务器，准备把数据发送过去：

                - 由于这个工作非常简单，其中大部分的工作都可以用专用硬件来解决：开发专门的 NPU（网络数据包处理器）来进行快速数据修改。所以，家用路由器可以做到在 300 块终端售价的情况下实现超过 1Gbit/S 的 NAT 性能。

        - Kong 网关需要建立“TCP 连接”

            - 1.三次握手建立连接

            - 2.对数据包进行排序、校验，收到心跳包需要回复

            - 3.需要将这个 TCP 连接和一个进程/线程进行绑定：

                - 1.在收到数据以后，找出这个进程/线程，把数据发送给它

                - 2.等进程/线程回复以后，再找到该进程/线程对应的那个 TCP 连接，把数据发送出去

    - 应用网关也叫七层负载均衡；我们讨论的工作在 IP 层的负载均衡叫四层负载均衡

    - 我们通过使用一个负载均衡器，可以完美抗下五万 QPS 的负载：一个 TCP 负载均衡器，下挂五个安装了 Kong 应用网关的虚拟机，再下挂 N 台虚拟机，无论是 PHP 语言还是 golang，都可以实现五万 QPS 的设计目标。

### 高并发的哲学原理（六）-- 拆分网络单点(下)：SDN 如何替代百万人民币的负载均衡硬件(网关、LVS、交换机)

- [岁寒博客：高并发的哲学原理（六）-- 拆分网络单点(下)：SDN 如何替代百万人民币的负载均衡硬件(网关、LVS、交换机)](https://github.com/johnlui/PPHC/tree/main/06.%20%E6%8B%86%E5%88%86%E7%BD%91%E7%BB%9C%E5%8D%95%E7%82%B9(%E4%B8%8B)%EF%BC%9ASDN%20%E5%A6%82%E4%BD%95%E6%9B%BF%E4%BB%A3%E7%99%BE%E4%B8%87%E4%BA%BA%E6%B0%91%E5%B8%81%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%A1%AC%E4%BB%B6(%E7%BD%91%E5%85%B3%E3%80%81LVS%E3%80%81%E4%BA%A4%E6%8D%A2%E6%9C%BA))

- 硬件负载均衡：

    - F5 创业史

        - 1996 年，华盛顿大学的几个学生共同创建了一家生产负载均衡设备的公司
        - 互联网的规模每 100 天增长一倍，这也让 F5 在成立三年后火速上市。
        - 2001 年，F5 公司在经历了互联网泡沫后，顺利地把设备卖进了银行等大型机构，因为 F5 比微软和甲骨文都更有前瞻性：他们的 iControl 系统可以提供 API，让大型机构自己开发软件来控制通过负载均衡设备的所有流量。
        - 2019 年，F5 Networks 以 6.7 亿美金的价格收购了 Nginx，硬件厂商和软件厂商实现了一次梦幻联动，也侧面说明了我们确实已经迎来了软件定义网络的大时代。

    - 防火墙

        - 实际上，在今天的企业网络架构中，专业的网关设备都已经消失，取而代之的是一个看起来不是网络设备的网络设备：防火墙。

        - 特别是具备应用识别能力的“下一代防火墙”：，更是将防火墙设备的价值推上了巅峰，并一次性让企业级路由器和中低端负载均衡全部退场，这又是一个软件战胜硬件的故事。

            - 下一代防火墙行业的个中翘楚 Fortinet 公司，由两名出生于北京的清华大学老师的孩子 2000 年在美国创办。

    - 2002 年 2 月，戴尔为 PowerEdge 1650 服务器第一次配上了千兆以太网。当时，负载均衡的主流实现还是基于硬件的，或者说是基于“软硬件一体化解决方案”的。在当时，服务器 CPU 的单核性能还很低，甚至核心数都很少，网卡芯片技术也没有今天这般牛皮（相比于下面讲的 NPU），所以当时想用运行在标准操作系统(Windows/Linux)内的软件来实现千兆软网关还是一个“前沿探索项目”。更不要说万兆负载均衡了

    - 21 世纪的头十年，最优秀的超千兆解决方案是：利用二层网络的链路聚合协议，使用多个千兆口同时负载均衡，实现超千兆的速度。

        - 而且当时能做到数 G 带宽的负载均衡设备动辄上百万，价格惊人，有需求的终端客户简直就是大冤种，不过在那个移动通信基站都要完全进口的年代，哪个中国人不是大冤种呢。

    - 路由器和交换机巨大的价格落差

        - 一台能够跑满千兆 NAT 的路由器，最低价格大概在 300 块，

        - 一个所有口都能同时跑满全双工千兆（上下行同时跑满千兆）的五口交换机，你知道多少钱吗？39 块钱，包邮。

            - 因为交换机干的事情更为简单，可以用非常低端的芯片满足需求。

    - [无情开评：它能把所有流量都安排得明明白白——全局型负载均衡器](https://www.bilibili.com/list/watchlater?bvid=BV1tp4y1s7Ge)

        - 流量负载均衡：外网到内网的流量（进来的）
            - 一般部署在交换机与服务器池之间

        - 链路负载均衡是：内网到外网的流量（出去的）
            - 意义：假设网通（联通）的宽带，进去电信的区。没有出去的负载均衡，就意味着怎么进就怎么出——即从电信回到联通。如果有出去的负载均衡，就可以实现从联通回到联通。
            - 对负载均衡器来说，会有数据库保存ip地址，而ip地址对应不同运营商
            - 一般部署在路由器的上方或下方

- 软件负载均衡：

    - 今天，一台总价 3 万元的通用 X86 服务器搭配 100G 以太网卡，使用基于 DPDK 开发的用户态应用程序在 Linux 上发小包，很容易就可以跑满 100Gbps 的网卡带宽。

    - 一台 F5 生产的售价百万的硬件负载均衡设备，它只用了一颗 4 核 8 线程的志强 x86 CPU，就实现了 40G 的四层负载均衡能力和 18G 的七层负载均衡（应用网关）能力。

        - 这台设备内部有两个控制器和四个接口插槽，可以实现“全双活”，即控制流量的“CPU 内存主板”和“网络接口”都是双份，在任意一个资源意外宕机后，另一个备用资源可以无缝顶上，可以实现无丢包的硬件级高可用。同时，这台设备背后的电源适配器应该至少有四个，可以实现运行时热替换，甚至连风扇模组都是冗余的，可热替换的。

    - 下面我们正式开始利用软件的力量，一步一步在标准 x86 服务器上面跑的标准 Linux 系统内，构建出一个和这台硬件负载均衡设备高可用性一致，且带宽可以达到 200G 的负载均衡集群。

        - SDN 是一种跨越了一二三层的技术，MAC 层也是我们构建 200G 负载均衡集群的重要技术战场

        - LVS：

            - 1998 年，在章文嵩博士二年级的时候，他发现 Cisco 的硬件负载均衡器要卖几万美金，觉得这玩意儿不难写，于是利用两周的课余时间创建并开源了 LVS（当时叫 IPVS）。时至今日，LVS 技术创造的商业价值已经无法计算，互联网上的绝大部分数据包，都会被 LVS 或者承袭 LVS 思想的软件处理。

            - 工作原理：通过修改 MAC 层、IP 层、TCP 层的数据包，即实现了一部分交换机和网关的功能，指挥流量到达真正的服务器上。

            - 由于有内核态加持，LVS 比 HAProxy 和 Nginx 的单机性能都要强很多。

            - 3个常用模式：
                - 1.NAT 模式：即网关模式，双向流量均经过网关转发，性能开销最大
                - 2.TUN 模式：类似于单臂路由，性能高且可跨越机房
                - 3.DR 模式：只能用在局域网，但是性能惊人，因为回程流量直接走局域网

                    - DR 模式下，LVS 只负责篡改数据包，不负责充当网关，所以我们还是需要一个网关在公网 ip 和私网 ip 之间进行 NAT 转换。

                    - 在生产环境部署中，由于 LVS 集群是所有流量的入口，所以其可用性需要做到非常高，一般不会只部署在一个机房里，所以现实中最常用的是 NAT 模式：双向流量均经过 LVS 集群，这样便可以实现多地多中心的跨公网多活。

                    - LVS 只需要处理正向数据包，通常正向数据包（请求）要远小于反向数据包（响应），所以带宽占用较低

                        - 反向数据包走的是标准的二层以太网，每台上游服务器都可以跑满自己的线速

                    - 需要在每一台上游服务器上都将该 VIP（10.0.0.100）配置为 lo（本地回环）接口的 ip
                        - 需要让每一台上游服务器都只响应真实 ip 如 10.0.0.1 的 ARP 查询请求，如果一不小心回复了针对 VIP 的 ARP 请求，将会立刻天下大乱：局域网内有多台机器同时声称自己拥有 10.0.0.100 这个 ip，交换机直接疯掉

                    ![image](./Pictures/计算机哲学/LVS-DR模式架构图.avif)

                - LVS 设计思想：LVS 和上游服务器上配置虚拟 ip，以对数据包进行篡改后再发送为手段，在标准以太网模型下构建出了一个可行的负载均衡系统。

                    - 它不像交换机那样完全不修改数据包，也不像网关那样维持一个对应关系并修改很多东西，它篡改了数据包，但不多，所以可以实现非常高的性能。

            - 专业的负载均衡协议：OSPF/ECMP

                - OSPF：开放式最短路径优先协议，一种基于链路状态的内部网关协议。每个OSPF路由器都包含了整个网络的拓扑。并计算通过网络的最短路径。OSPF会通过多播的方式自动对外传播检测到的网络变化。

                - ECMP：等价多路径协议。即当存在多条不同的链路到达同一目的地址时，利用ECMP可以同时使用多条链路，不仅增加了传输带宽，还可以无时延、无丢包的备份失效链路的数据传输。如果利用传统的路由算法，只能利用其中的一条链路进行数据的传输。

            - LVS 单机性能为何会卡在 20G？最新的 AMD EPYC 9654 服务器 CPU 有 96 个物理核心，双路平台共有 384 个 vCore，但是 LVS 单机性能依旧徘徊在 20G 附近。

                - 1.Linux 网络栈已经达到性能极限了。

                    - LVS 基于 kernel 里的 netfilter，依赖 Linux 网络栈，导致进程切换需要读写内存，数据包的发送和接收也要读写内存，在极高的带宽需求之下，相对耗时的内存读写就成了阻碍性能进一步提升的最大障碍。

                    - 2个解决方案：

                        - 1.DPDK 是 Intel 开源的高性能网络数据处理框架，运行在用户态的进程通过申请大页内存和轮询代替中断两个关键特性，给高速率网卡提供了一个高性能解决方案。它的 CPU 亲和性、多核调度架构、内存 NUMA 优化等基础架构又进一步推高了性能，最终让它成功脱颖而出成为用户态网络界面框架的首选。

                            - 爱奇艺开源的 DPVS https://github.com/iqiyi/dpvs 就是 DPDK 技术在负载均衡领域的成功运用。在 10G 网络下发送 64 字节的小包进行测试，DPVS 可以做到标准 LVS 的五倍性能。在这里我们保守一点，对折一下 2.5 倍，那 DPVS 的单网卡性能极限就是 50G。

                        - 2.网卡芯片硬件卸载

                            - 最新的 NPU 已经可以支持很多的硬件卸载特性：IP 分片、TCP 分段、小包重组、checksum 校验、硬件 QOS，以及最重要的 VXLAN 的剥离和插入：此功能是 DPVS 的重要组成部分，可以减少数据流互相干扰，大幅提升系统总容量。

                            - 此外，RDMA 技术也是网卡芯片的一大进步方向

                - 2.全局锁优化

                    - 除了 Linux 网络栈的限制，LVS 本身架构上的全局锁也是一个突破口，全局锁导致了海量的 CPU 核心无法被利用

                    - 阿里云的处理思路：通过 RSS 技术把同一个五源组报文扔到同一个 CPU 上处理，保证入方向的所有相同连接上的报文都能交给相同的 CPU 处理。

                        - 同时在每个核在转发出去时都用当前 CPU 上的 Local 地址，通过设置一些 fdir 规则，报文回来时后端服务器访问的目的地址就是对应 CPU 上的 local 地址。这样就能实现这一条连接上面左右方向的报文都被同一个 CPU 处理，将存储“五元组对应关系”的内存数据库在不同的 CPU 核心上隔离开，这样就可以利用多个 VIP 来实现整体系统容量的线性提升。

        - LVS + Keepalived 可以实现高可用

            - 金融级项目可以在一个城市跨三个机房做三节点的 Keepalived 集群。为什么不做多城市集群？因为多城市已经属于“两地三中心”的高可用技术领域，一般不在二层网络上做，跨城市专用光纤的建设费用是非常高的，城市内拉光纤就便宜多了。

            ![image](./Pictures/计算机哲学/LVS+Keepalived.avif)

            - 运行原理：
                - 两台机器频繁通信，通过分数计算确定哪台机器的分数更高，由这台机器向局域网发送 VRRP 组播报文宣称 VIP 在我这里
                - 当分数高的那台机器宕机，或者断网，或者检测到服务进程消失（例如 Nginx 挂掉），分数低的那台机器会在极短时间内立刻顶上，宣称 VIP 在自己这里

        - Keepalived 也可以用在其他组件上实现高可用

            - 我司办公区自建机房内也部署了一些非关键业务，其性能要求并不高，所以我选择单独部署 Keepalived：和 Kong 网关配合提供高可用网关；和 MySQL 配合做双主双活集群；和 Apache 配合做一个跨越 4 台物理机的虚拟机集群，提供高可用 HTTP 服务

        - 200G负载均衡集群架构：

            ![image](./Pictures/计算机哲学/200G负载均衡集群架构图.avif)

            - 1.拆除 ip 单点，DNS 拆分：DNS 协议可以将用户的终端流量直接导向全国多个机房

            - 2.拆除交换机单点：OSPF/ECMP 路由技术
                - 路由_1和路由_2采用支持 ECMP 的硬件设备或者软件路由来充当，他们会把流量平均分给两个交换机。
                - 每台交换机承载 100G 带宽，对交换机来说简直就是洒洒水，2 万块人民币的硬件交换机就能接近 24 x 100G 全线速交换（二手的甚至只要六千块）。

            - 3.拆除服务器单点：LVS 单机双网卡四网口
                - 每台 LVS 服务器都安装双口 100G 网卡 2 张，共有四个网口，这样单机可以实现 50G x 2 的极限性能。每个网卡上面的两个网口，分别连接两台交换机，可以在实现了高可用的同时保证协议速度(线速)不会成为瓶颈。

            - 4.天下无单点：全冗余架构
                - 从左至右，整个架构的每一层的每一个节点，都和左边一层的所有节点进行连接，这种全冗余架构可以满足在任意一台设备宕机的情况下，整个系统依然可用，甚至系统容量都能维持不变。
                - 如果某台路由宕机，则另一台路由会将它的公网 ip 接过来，可以实现分钟级故障恢复（主要是公网路由表可能更新缓慢）。

                - 如果某台交换机宕机，则左侧的路由通过 ECMP 及时调整路由配置，可以实现秒级切换。

                - 如果某台 LVS 服务器宕机：Keepalived 机制会让 Standby 设备在 1 秒之内顶上。

        - 200G 并不是这个系统的极限，如果我们让一组的两台 LVS 服务器使用两个 VIP 做互为主备的双活的话，可以把整个系统的容量提升到理论极限 400G。
            - 单个公网 ip：最大带宽为系统最大容量 200G
            - 单个 VIP：最大带宽为 100G
            - 单个数据流：最大带宽为单网卡性能极限 50G

        - 还记得上面那台 100 万的硬件负载均衡器吗，他的最大 L4 带宽只有 40G，而我们这一套 200/400G 的设备要多少钱呢？1x2 + 2x2 + 3x4 = 18万

            - 通过本文构建的这个 200/400G 负载均衡集群，配合多个应用网关，以及后面海量的物理服务器，我们终于成功实现了一百万 QPS 的目标。但是，这只是 web 服务层面的百万 QPS，在真实世界中，数据库才是那个最难解决的单点。

### 高并发的哲学原理（七）-- 最难以解决的单点：数据库以及它背后的存储

- [岁寒博客：高并发的哲学原理（七）-- 最难以解决的单点：数据库以及它背后的存储](https://github.com/johnlui/PPHC/tree/main/07.%20%E6%9C%80%E9%9A%BE%E4%BB%A5%E8%A7%A3%E5%86%B3%E7%9A%84%E5%8D%95%E7%82%B9%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BB%A5%E5%8F%8A%E5%AE%83%E8%83%8C%E5%90%8E%E7%9A%84%E5%AD%98%E5%82%A8)

- 在常见的 web 系统架构中，关系型数据库就是那个最大的无法拆分的单点：在一个系统内，多个 API 调用所产生的多种行为，最终都要作用到同一张表上，这个系统的运行才能符合逻辑。

- 关系型数据库的“关系”二字，指的是一个表内部的这些数据之间，拥有行和列两个方向的关系，这其实是另一种形式的“时间换空间”、“空间换时间”思想：提前约束这些数据，让他们以一定的规则存储在一起，写入的时候会慢一点，但是这样调用起来就简单又高效

    - 例如无需全表扫描瞬间找出最大 ID、例如即便将海量数据存储在磁盘上，依然能够以很快的速度检索到满足某个条件的某一行、例如在快速定位到某一行后便可以快速取出连续多行的数据等等。

- 逻辑上，无论数据库如何拆分，微服务如何设计，一定有一个资源是必须排队的，哪怕我们可以用“现在的时间换未来的时间”这种方式来进行性能优化（后面的文章还会提到），排队是必须存在的。

    - 用户要一个一个注册，ID 不能一样；订单要一个一个下，两个订单的信息不能错乱。这其实就是最原始的需求——排队。

    - 对于大部分需要记录到数据库里的信息来说，基于先来后到进行排队入库都是一个不可妥协的硬需求，否则在逻辑上数据就会出错。

    - 对于所谓的 NoSQL 数据库来说，连一个简单的 ID 自增都需要扫描全表才能做到，它是不能承担数据单点角色的。由于它不是为了承担数据单点而设计的，NoSQL 注定只能是关系型数据库用来提升性能的的副手。

- 数据库是一个非常复杂的软件

    - 关系型数据库就像空气一样充斥在后端技术里，但是可能很少有人想过一个惊人的事实：99.9% 使用 MySQL 的系统，其业务代码的复杂度都没有 MySQL 本身的复杂度高。

    - MySQL 为了实现关系型数据库四大原则，几乎把计算机的每一种资源都用到了极致：进程、线程、多核、网络、寄存器、内存、机械磁盘、固态磁盘。

- 数据库这个单点，单在哪里？磁盘。

    - 一般的技术文章一说到持久性原子性，就是什么 undo log、redo log、多版本并发、锁。我不这么看，下面我们从 MySQL 的基础功能开始思考。

    - MySQL 是整个 web 系统中唯一一个在意外掉电重启以后，还能保持数据不丢的组件，那它是怎么做到的呢？很简单，基于计算机上唯一一个断电不丢数据的磁盘实现的。所以，不用看什么*do log了，把它们全部当做磁盘文件就行了。

    - 如果你执行了update语句，那无论 MySQL 有多少级的缓存，多少种的日志，都得等到它成功将此次数据修改写入到磁盘上以后，才会给客户端返回成功状态。而文件的修改是有队列的，可以保证每一次写操作的可靠性。
        - 这里的写入磁盘，不一定指的是真的存到了那张表对应的数据文件里，也可以是*do log。如果此时服务器意外重启，那在 MySQL 启动以后，它还是会把自己刚才记录的这些*do log里的信息再默默地写入到磁盘上真正的表数据文件里。

### 高并发的哲学原理（八）-- 将 InnoDB 剥的一丝不挂：B+ 树与 Buffer Pool

- [岁寒博客：高并发的哲学原理（八）-- 将 InnoDB 剥的一丝不挂：B+ 树与 Buffer Pool](https://github.com/johnlui/PPHC/tree/main/08.%20%E5%B0%86%20InnoDB%20%E5%89%A5%E7%9A%84%E4%B8%80%E4%B8%9D%E4%B8%8D%E6%8C%82%EF%BC%9AB%2B%20%E6%A0%91%E4%B8%8E%20Buffer%20Pool)

- 到底该何时分表？

    - 2017 年发布的阿里巴巴 Java 开发手册中写道“单表行数超过 500 万行或者单表容量超过 2 GB ，才推荐进行分库分表”，被很多技术博文写成了：阿里巴巴推荐超过 500 万行的表进行分表，这种理解是错误的。

    - 虽然经过我的实测，在每行数据定长 1024 字节，Buffer Pool 配置为 22GB，在单表体积 24GB 的情况下，四层索引和三层索引并没有任何性能差异

        - 但是现实世界中的数据表可不是这么严丝合缝：

            - 1.为了节约空间和保持扩展性，绝大多数短字符串类型采用的是 varchar 而非定长的 char，这就让 level=0 的每一页包含的数据行数不一致，这会让这颗“平衡多路查找树”不怎么平衡
            - 2.生产表经常面临数据删除和更新：同层的页之间的双向链表和不同层页之间的单向指针都需要经常变化，同样会让这棵树变的不平衡
            - 3.一张表使用的越久，ibd 文件中的碎片就越多，极端情况下（例如新增 10 行删除 9 行）会让数据页的缓存几乎失效
            - 4.磁盘上单文件体积过大，不仅在读取 IOPS 上不如多文件，还会引发文件系统的高负载：单个文件描述符也是一种单点，大文件的读写性能都不太行，还容易浪费大量内存

        - 那么，该如何回答“到底该何时分表”这个问题呢？很遗憾并没有一个放之四海皆准的答案，这和每个表的读取、新增、更新的具体情况是分不开的。

    - 虽然在数据库技术层面我们无法给出何时分表的答案，但是从软件工程层面我们可以得出一个结论：

        - 能不分就不分，不到万不得已不搞分表，如果能靠加索引或者加内存来解决就不要考虑分表，分表会对业务代码造成根本性的影响，会产生长久的技术债务。

- 内存缓存 Buffer Pool（缓存池）

    - Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认为 128MB，强烈建议任何一台 MySQL 服务器都根据自己的机器资源情况，增大配置的内存值，这玩意儿能把 MySQL 的性能提升多个数量级。

        - 缓存池大小由innodb_buffer_pool_size参数来管理

    - Buffer Pool 应该怎么优化

        - 内存配置的越大越好：多一倍的内存，比多一倍的 CPU 更能提高数据库性能

            - 一般建议大家设置成系统可用内存的 75%

            - 但是根据我的经验，对于普通的“冷热均衡”的数据库这样是合理的，因为热数据较少，但是如果你需要在短时间内（如几天）普遍地读写几乎所有表的所有数据，那这个比例最好设置在 50% 附近，否则在运行一段时间后将会爆内存（OOM 错误），MySQL 进程会被杀掉。

        - 减少对冷数据的随机调用：优化定时任务和队列的业务代码，避免这种情况

        - 在大批量执行小修改的时候、尽量自己控制事务：由于 InnoDB 底层的数据隔离机制，让它的每一个写动作都是一个事务，所以如果你要在一次会话中写多行数据，最好自己控制事务，可以显著减少对缓冲池的影响以及磁盘 IO 数量

        - 避免修改主键：修改主键的值会带来大量的数据移动，磁盘会不堪重负，缓存会疯狂失效

    - 控制+存储思维：虽然缓存池已经在内存中了，但是既然缓存池是一组 16KB 的页，那它就需要一个额外的内存索引来保存每一页的表空间、页号、缓存页地址、链表节点信息，这个结构叫控制块。N 个控制块和 N 个 16KB 数据页连在一起就是 Buffer Pool 占据那一段连续内存。

        - 缓存池和磁盘数据一样，分为一个又一个 16KB 的页来进行管理。除了缓存“索引页”和“数据页”，缓存池里面还有 undo 页，插入缓存、自适应哈希索引、锁信息等。

        - 除了控制块和数据页，Buffer Pool 中还存在着管理空闲页的free 链表和管理脏页的flush 链表

    - 数据如何读写：

        - 缓存池中的 16KB 页是和磁盘上的页一一对应的，这就带来了读写两个方向的改变：

        - 读数据时，如果该页已经在内存中了，则无需再浪费一次磁盘 IO。

        - 写数据时，会直接将数据写入缓存中的页（不影响之后的读取），并在成功写入 redo log 之后返回成功。同时会将该页设置为脏页，等待后台进程将数据真正写入磁盘。

    - 缓存池的 LRU 算法

        - 传统的 LRU 算法只用一个链表就实现了“移动至头部”和“淘汰尾部”两个操作，为什么 InnoDB 非要搞一个变体呢？还是因为 B+ 树：由于底层数据的非连续性，导致 Buffer Pool 会遇到两个比较严重的问题：预读失效和缓冲池污染。

            - 预读失效：预读本质上是基于局部性对需求的一种预估，正常的 SQL 并不能保证每一条取出的数据都是大概集中的，例如取性别为女的用户，就需要跳着走完全表，预读失效非常正常。

                - 解决方法：LRU 算法加了一层 LRU 算法，减小了缓存粒度：

                    - LRU 链表将数据分为新生代和老生代两个区域，分别占据5/8和3/8的内存空间，预读时只插入老生代的头部，同时老生代尾部元素会被淘汰。当数据真的被读取时，这一页会被立刻转移到新生代的头部，并且会挤出去一个新生代尾部的元素进入老生代的头部，数据还在缓存中。

            - 缓冲池污染：由于磁盘数据库拥有极大的体量，相比之下内存容量却十分捉襟见肘，所以在用内存来做磁盘缓存时，一旦需求不满足局部性，缓存会被迅速劣化：当一条 SQL 需要扫描海量的数据页时，其它表用得好好的热数据嘎的一下就被清出内存了，结果就是磁盘 IO 数量突然增加，系统崩溃。

                - 解决方法：于是 InnoDB 给“数据被读取时，这一页会从老生代转移到新生代的头部”这个操作加了个条件：在老生代里面待的时间要足够久。
                    - 改变的是“转移页操作”所需要的条件，而且这个条件(即留存时间)的判断非常简单，只需要在加入老生代的时候增加一个时间戳就行，4 个字节，除此之外无需任何维护
                    - 采用时间而不是次数来做限制，更加符合数据库的最终用户——人的真实需求。读取次数可能因为技术原因而增加，时间不会。没有无缘无故的爱，更没有无缘无故的读取。

### 高并发的哲学原理（九）-- 细数四代分布式数据库并拆解 TiDB 和 OceanBase（中间件、计算存储分离、列存储、CAP）

- [岁寒博客：高并发的哲学原理（九）-- 细数四代分布式数据库并拆解 TiDB 和 OceanBase（中间件、计算存储分离、列存储、CAP）](https://github.com/johnlui/PPHC/tree/main/09.%20%E7%BB%86%E6%95%B0%E5%9B%9B%E4%BB%A3%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B9%B6%E6%8B%86%E8%A7%A3%20TiDB%20%E5%92%8C%20OceanBase%EF%BC%88%E4%B8%BB%E4%BB%8E%E3%80%81%E4%B8%AD%E9%97%B4%E4%BB%B6%E3%80%81KV%E3%80%81%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%AD%98%E5%82%A8%E5%88%86%E7%A6%BB%E3%80%81%E5%88%97%E5%AD%98%E5%82%A8%E3%80%81CAP%E5%AE%9A%E7%90%86%EF%BC%89)

- 单机数据库的不可能三角：①持久化 ②事务隔离 ③高性能。

    - 1.持久化需要每一次写数据都要落到磁盘上，宕机再启动以后，数据库可以自修复。如果只要求这一条，很好实现。

    - 2.事务隔离需要每一次会话(session)的事务都拥有自己的数据库版本：既要多个并行的事务相互之间不会写到对方的虚拟数据库上(读提交)，又要不能读到对方的虚拟数据库上(可重复读)，还要在一个事务内不能读到别的事务已经提交的新增的数据(幻读)，终极需求则是完全串行化：我的读 session 不结束，你就不能读。这个需求和持久化需求结合以后，会大幅增加日志管理的复杂度，但，还是可以管理的。

    - 3.读写都要尽量地快：单独实现也很快，Redis 嘛，但是加上持久化和事务隔离，就很难做了：需要对前两项进行妥协。

    - MySQL的选择：

        - 1.选择了持久化：失去人性，失去很多，失去持久化，失去一切。
        - 2.选择了一部分高性能：MyISAM 就是为了快速读写而创造的，早期 MySQL 在低配 PC 机上就有不错的性能。后来更高级的 InnoDB 出现了，小数据量时它的读取性能不如 MyISAM，写性能更是彻底拉胯，但是在面对大数据量场景时，读性能爆棚，还能提供很多后端程序员梦寐以求的高级功能（例如丰富的索引）
        - 3.最后将事务隔离拆成了几个级别，任君挑选：你要强事务隔离，性能就差；你能接受弱事务隔离，性能就强。你说无事务隔离？那你用 MySQL 干什么，Redis 它不香吗。

        - 所以 MySQL 其实选择了 持久化*1 + 高性能*0.8 + 事务隔离*0.5，算下来，还赚了 0.3 (￣▽￣)"
        - 不过，从 MySQL 也可以看出，“数据库的不可能三角”并不是完全互斥的，是可以相互妥协的。

- 读写分离：

    - 由于 web 系统中读写需求拥有明显的二八分特征——读取流量占 80%，写入流量占 20%

        - 搭建一个一主四从的 MySQL 集群，总 QPS 就能从单节点的 1 万提升到 5 万，顺便还能拥有主节点故障后高可用的能力。

    ![image](./Pictures/计算机哲学/mysql各种主从架构.avif)

    - 这些主从架构的实现方式都是一致的：基于行同步或者语句同步，近实时地从主节点向从节点同步新增和修改的数据：
        - 无论是远古时代谷歌的 MMM(Multi-Master Replication Manager for MySQL)
        - 还是中古时代的 MySQL 官方的 MGR(MySQL Group Replication)
        - 还是最近刚刚完成开发且收费的官方 InnoDB Cluster

    - sqlproxy：由于这种方法必然会让主从之间存在有一段时间的延迟(数百毫秒到数秒)，所以一般在主从前面还要加一个网关进行语句分发：

        ![image](./Pictures/计算机哲学/mysql-sqlproxy.avif)

    - 主从架构有一个很大的弱点：

        - 写入性能无法提升：由于数据库承载的单点功能实在是太多了(自增、时间先后、事务)，导致哪怕架构玩出了花，能写入数据的节点还是只能有一个，所有这些架构都只能提升读性能。

    - 那怎么提升写性能呢？这个时候就要掏出分布式数据库了。

- 分布式数据库

    - 由于数据库的单点性非常强，所以在谷歌搞出 GFS、MapReduce、Bigtable 三驾马车之前，业界对于高性能数据库的主要解决方案是买 IOE 套件：IBM 小型机 + Oracle + EMC 商业存储。

    - 后来搜索引擎成为了第一代全民网站，而搜索引擎的数据库却“不那么关系型”，所以谷歌搞出了自己的分布式 KV 数据库。后来谷歌发现 SQL 和事务隔离在很多情况下还是刚需，于是在 KV 层之上改了一个强一致支持事务隔离的 Spanner 分布式数据库。

    - 而随着云计算的兴起，分布式数据库已经成了云上的“刚需”：业务系统全部上云，总不能还用 Oracle 物理服务器吧？于是云上数据库又开始大踏步发展起来。

    - 分布式数据库的发展史：

        - 第一代分布式数据库：中间件

            - 对数据表进行纵向分表：按照一定规则，将一张超多行数的表分散到多个数据库中。
            - 然后，无论是插入、更新还是查询，都通过一个 proxy 将 SQL 进行重定向和拆分，发送给多个数据库，再将结果聚合，返回
            - 基本原理一句话就能描述：使用一个常驻内存的进程，假装自己是个独立数据库，再提供全局唯一主键、跨分片查询、分布式事务等功能，将背后的多个数据库“包装”成一个数据库。
            - 虽然“中间件”这个名字听起来像一个独立组件，但实际上它依然是强业务亲和性的：没有几家公司会自己研发数据库，但每家公司都会研发自己的所谓中间件，因为中间件基本上就代表了其背后的一整套“多数据库分库分表开发规范”。

        - 第二代分布式数据库：KV

            - 由于搜索不需要关系型数据库，自然谷歌搞的分布式数据库就是 KV 模型。谷歌的三驾马车论文发布以后，业界迅速发展出了一个新的数据库门类 NoSQL(Not Only SQL)，专门针对非结构化和半结构化的海量数据。

            - 目前，缓存（Redis）和文档/日志（MongoDB）大家一般都会用 NoSQL 来承载。在这个领域，最成功的莫过于基于 Hadoop 生态中 HDFS 构建的 HBase 了：它主要提供的是行级数据一致性，即 CAP 理论中的 CP，放弃了事务，可以高性能地存储海量数据。

        - 第三代分布式数据库：以 Spanner 为代表的 NewSQL

            - 从 2005 年开始，Google Adwords 开始基于 MySQL 搭建系统，这也推动了 MySQL 在 Google 内部的大规模使用。随着业务的发展，MySQL 集群越来越庞大，其中最痛苦的就是“数据再分片”，据说有一次谷歌对数据库的重新分片持续了 2 年才完成。于是谷歌痛定思痛，搞出了一个支持分布式事务和数据强一致性的分布式关系型数据库：Google Spanner。

            - 2012 年，谷歌发布了 Spanner 论文¹，拉开了分布式强一致性关系型数据库的大幕。这个数据库是真的牛逼，当我第一次看到它机柜照片的时候直接震惊了：

                ![image](./Pictures/计算机哲学/Spanner机柜.avif)

                - 这套系统采用了 GPS 授时 + 2 台原子钟 + 4 台时间服务器，让分布在全球多个数据中心的 Spanner 集群进行相当精确的时间同步：基于 TrueTime 服务，时间差可以控制在 10ms 之内。这种真正的全球数据库可以做到即使单个数据中心完全失效，应用也完全无感知。

                - 当然，如此规模的全球数据库全世界也没有几家公司有需求，如果我们只在一个数据中心内署数据库集群，时间同步可以很容易地做到 1ms 之内，原子钟这种高端货还用不到。

            - 写入型 SQL 会在写入缓存页 + 写入磁盘 redo log 之后返回成功，此时，真正的 ibd 磁盘文件并未更新。所以，Spanner 使用 Paxos 协议在多个副本之间同步 redo log，只要 redo log 没问题，多副本数据的最终一致性就没有问题。

            - 事务的两阶段提交
                - 单机架构下的事务，也是某一旦一条 SQL 执行出错，整个事务都是要回滚的嘛。多机架构下这个需求所需要的成本又大幅增加了，两阶段提交的流程是这样的：
                    - 告诉所有节点更新数据
                    - 收集所有节点的执行结果，如果有一台返回了失败，则再通知所有节点，取消执行该事务
                - 这个简单模型拥有非常恐怖的理论故障概率：一旦在第一步执行成功后某台机器宕机，则集群直接卡死：大量节点会被锁住。

                - Spanner 使用 Paxos 化解了这个问题：只要 leader 节点的事务执行成功了，即向客户端返回成功，而后续数据的一致性则会基于prepare timestamp和commit timestamp加上 Paxos 算法来保证。

            - 多版本并发控制（MVCC）

                - Spanner 使用时间戳来进行事务之间的 MVCC：为每一次数据的变化分配一个全球统一的时间戳。这么做的本质依然是“空间+时间”换时间，而且是拿过去的时间换现在的时间，特别像支持事后对焦的光场相机。

                - 1.传统的单机 MVCC 是基于单机的原子性实现的事务顺序，再实现的事务隔离，属于即时判断。
                - 2.Spanner 基于 TrueTime 记录下了每行数据的更新时间，增加了每次写入的时间成本，同时也增加了存储空间。
                - 3.在进行多节点事务同步时，就不需要再和拥有此行数据的所有节点进行网络通信，只依靠 TrueTime 就可以用 Paxos 算法直接进行数据合并：基于时间戳判断谁前谁后，属于事后判断。

            - Spanner 放弃了什么？

                - CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。

                - Google Spanner 数据库首先要保证的其实是分区容错性，这是“全球数据库”的基本要求，也最影响他们赚钱；然后是一致性，“强一致”是核心设计目标，也是 Spanner 的核心价值；谷歌放弃的是可用性(A)，只有 majority available。

                    - 除此之外，为了“外部一致性”，即客户端看到的全局强一致性，谷歌为每一个事务增加了 2 倍的时钟延迟，换句话说就是增加了写操作的返回时间，这就是分布式系统的代价：目前平均 TrueTime 的延迟为 3.5ms，所以对 Spanner 的每一次写操作都需要增加 7ms 的等待时间。

                    - Spanner 一致性的根本来源：大家应该都发现了，其实 Spanner 是通过给 Paxos 分布式共识算法加了一个“本地外挂” TrueTime 实现的海量数据的分布式管理，它实现全局强一致性的根本来源是Paxos和TrueTime。而在普通单机房部署的分布式系统中，不需要 GPS 授时和原子钟，直接搞一个时间同步服务就行。

            - NewSQL 最大的特点就是使用非 B 树磁盘存储结构（一般为 LSM-Tree）

                - 目前比较常见的 NewSQL 有 ClustrixDB、NuoDB、VoltDB，国内的 TiDB 和 OceanBase 也属于 NewSQL，但他们俩有本质区别，我们下面会详细讨论。

        - 第四代分布式数据库：云上数据库

            - 在 NewSQL 时代之后，随着云计算的兴起，云上数据库突然成为了市场的宠儿，市场占有率迅速上涨。它们其实都是对 MySQL 的改造，并不属于 NewSQL 范畴

            - 2014 年 10 月，亚马逊发布了 Aurora 云上数据库，开创性地在云环境中将计算节点和存储节点分离：基于云上资源的特点，将计算节点 scale up（增配），将存储节点 scale out（增加节点），实现了极佳的性能/成本平衡。Aurora 将云上关系型数据库产品推向了一个新的高度。

            - 它火的原因我相信大多数人都认识的不对：不是因为性能强，而是因为便宜。

                - 我们很容易就能找到云计算真正的商业价值在哪里：传统托管式部署，哪些资源浪费的最多，哪里就是云计算的商业价值所在。

                - 为了满足业务波动而多采购的 CPU 和内存，可能浪费了 50%；网络安全设备，可以说 95% 以上的资源都是浪费；高端存储，这个已经不能用资源浪费来形容了，而是被云计算颠覆了

                    - 云厂商用海量的多地域多机房内廉价的 x86 服务器里面的廉价磁盘，基于软件，构建出了超级便宜、多副本、高可用的存储，唯一的问题是性能不是太好。亚马逊 S3 和阿里云 OSS 就是最佳代表，可以说这类对象存储服务，其单价已经低于本地机房的 2.5 寸 SAS 机械磁盘了，更不要说本地机房还需要另外采购昂贵的存储控制器和 SAN 交换机了。

                    - 亚马逊的Aurora 和 阿里的PolarDB 的核心价值是用一种低成本的方式，制造了一个 Oracle 要高成本才能做出来的软件和服务，这才是真的“创造价值”。

            - 计算与存储分离的优势：

                - 计算与存储分离并不是什么“高性能”技术，而是一种“低成本”技术：

                    - 关系型数据的存储引擎 InnoDB 本身就是面向低性能的磁盘而设计的，而 CPU 和内存却是越快越好、越大越好，如果还把磁盘和 MySQL 进程部署在同一台物理机内，一定会造成磁盘性能的浪费。计算与存储分离的真正价值在于大幅降低了存储的成本。

                - 显著降低了传统 MySQL 主从同步的延迟

                    - 传统架构下，无论是语句同步还是行同步，都要等到事务提交后，才能开始同步，这就必然带来很长时间的延迟，影响应用代码的编写。而计算和存储分离之后，基于 redo log 传递的主从同步就要快得多了，从 1-2s 降低到了 100ms 以下。由于主从延迟降低，集群中从节点的个数可以提升，总体性能可以达到更高。

            - Aurora 的主从同步机制

                - 1.主从节点之间只有 redo log 传递
                - 2.从节点在拿到 redo log 之后，会刷新自己 Buffer Pool 中存在的数据页，其它不存在的页的信息会丢弃

                - 两个问题：
                    - 从节点的客户端在主从不同步的一段时间内，读到的是旧数据，这个需要网关或者应用代码来处理
                    - 从节点的 Buffer Pool 有效性变差，命中率下降，引发性能下降

            - Aurora 的架构局限

                - Aurora 认为网络速度会成为云数据库的瓶颈，而在它研发的 2012-2013 年也确实如此，当时万兆网卡刚刚普及，CPU 单核性能也不足，软件也没有跟上，可以说速度比千兆网卡也快不了多少，所以亚马逊又搞了神奇的技术：存储节点具有自己将 redo log 写入 ibd 文件的能力。

                    - 由于这个神奇能力的存在，Aurora 的多机之间采用传输 redo log 的方式来同步数据，并用一种今天看起来不太靠谱的协议来保证最终一致性：consul 使用的那个 gossip 协议。
                    - 由于 Aurora 采用六副本技术，所以每次写入都需要发起六次不怎么快的网络 IO，并且在其中 4 个成功以后才给客户端返回成功。
                    - Aurora 确实便宜，但是单节点的性能也确实捉鸡，这代表的就是写入性能差，进而限制了整个集群的性能上限。而且，经过比较长的时间(100ms)才能保证从从节点上读到的数据是最新的，这会让主节点压力增大影响集群性能上限，或者让应用代码做长时间的等待，严重的会引起应用代码的执行逻辑变更，引入持久的技术债务。

            - 阿里云 PolarDB 后来居上

                - 2015 年，PolarDB 开始研发，当时 25Gb RDMA 网络已经逐渐普及，所以阿里云将视角放在了网络速度之外：在 IO 速度没有瓶颈以后，基于内核提供的 syscall 所编写的旧代码将会成为新的性能瓶颈。
                    - 站在 2023 年初回头看，阿里云的判断是非常准确的。

                - 一个计算存储分离的数据库集群的性能上限就是主节点的写入性能上限。

                    - Aurora 有多主可写数据库，对 ID 进行自动切分，使用时有一堆限制
                    - PolarDB 也有多主可写数据库，但是更绝：每个库/表只支持绑定到一个可写节点，感情就是对多个数据库做了个逻辑聚合，还不如中间件呢。

                - PolarDB 是如何提升主节点性能的呢？

                    - 1.共享的不是 redo log，而是 ibd 文件

                        - 主从之间并不是依靠纯属 redo log 来同步数据的，而是直接共享同一个 ibd 文件，即真正的共享磁盘。而且，基于块设备的 Raft 算法也比基于文件的 gossip 协议要快很多。

                    - 2.绕过内核和网路栈：大幅提升存储性能，降低延迟，减少 CPU 消耗

                        - 虽然对 redo log 的解析这一步在 Aurora 那边是存储做的，PolarDB 这边是主节点做的，看似增加了 CPU 消耗，但是这并不是真正的性能瓶颈所在，真正的瓶颈是网络栈和 UNIX 进程模型。
                        - 跳过 TCP/IP 网络栈，直接使用 RDMA 网络从存储节点读取数据，延迟暴降
                        - 跳过 kernel 的线程调度，自行开发绑定 CPU 核心的状态机，采用非阻塞 IO，在 CPU 占用下降的情况下，延迟进一步降低

                    - 3.提出 ParallelRaft 协议，允许部分乱序提交

                        - ParallelRaft 协议让 Aurora 那边需要执行六次的网络 IO 变成了一次：只需要向 leader 节点写入成功，剩下的数据同步由 Raft 算法来执行，这和 Google Spanner 的两阶段提交优化是一个思路。

                        - 原始的 Raft 协议确实逻辑完备，实现简单，就是一个一个地协商太慢了。ParallelRaft 让收敛协商能够并行起来，加速 redo log 落入 ibd 文件的过程。

                    - 4.主从之间基于低延迟的共享存储同步 redo log 数据以刷新 Buffer Pool

                        - 基于共享存储的低延迟优势，PolarDB 主从之间使用共享存储来同步 redo log 以刷新缓存，这一点逻辑上和 Aurora 一致，但是实际表现比较好，我实测主从同步时间在 20~70ms 范围内。

                    - 5.单机性能比标准 MySQL 更强

                        - RDMA 存储比本地存储更快，因为减少了计算和存储争抢中断的问题：IO 这个 CPU 不擅长的东西完全卸载给了 RDMA 网卡。同配置下 PolarDB 比标准 MySQL 的性能要高几倍。

                - 在各种实测里面，PolarDB 在相同规格下对其他的云上数据库都拥有 2 倍的性能优势，但是它基于 RDMA 存储的特点也让它付出了两个代价：1. 硬件成本高昂 2. 扩展性有上限。

                    - 是不是感觉很熟悉？Shared-Disk 的代表 Oracle RAC 也有这两个缺点。不知道大家有没有发现，PolarDB 就是云时代的 RAC 数据库：看起来是 Shared-Disk，其实是共享缓存让他们的性能变的超强。
                    ![image](./Pictures/计算机哲学/各代分布式数据库的兼容性对比.avif)

- TiDB 和 OceanBase 该怎么选？

    - TiDB 和 OceanBase 是目前中国 NewSQL 数据库的绝代双骄，争论一直不绝于耳。

    - TiDB 是承袭 Spanner 思想的 NewSQL，对 MySQL 的兼容性一般，基于key+版本号的事务控制也比较弱，据说性能比较好，特别是写入性能。

    - OceanBase 是基于 Shared-Nothing 思想原生开发的分区存储数据库，其每个节点都支持完整的 SQL 查询，相互之间无需频繁通信。OceanBase 还支持多租户隔离，这明显就是为了云服务准备的(无论是公有云还是私有云)，和绝大多数企业无关。另外，OceanBase 对于 MySQL 的兼容性也几乎是 NewSQL 里面最高的，毕竟它需要支持支付宝的真实业务，兼容性是硬性要求，业务屎山可没人移得动 (づ｡◕‿‿◕｡)づ

    - TiDB设计思路

            ![image](./Pictures/计算机哲学/TiDB架构图.avif)

            - 上图中的“SQL 层”就是解析 SQL 语句并将其转化为 KV 命令的一层，是无状态的，下面的存储层才是核心，它叫 TiKV。

        - TiKV 如何存储数据

            ![image](./Pictures/计算机哲学/TiKV官方原理图.avif)

                - TiKV 是 TiDB 的核心组件，一致性和事务隔离都是基于它的能力得以实现的。

                - 每个 TiKV 拥有两个独立的 RocksDB 实例，一个用于存储 Raft Log，另一个用于存储用户数据和多版本隔离数据（基于key+版本号实现），从这里可以看出，TiDB 的存储存在大量冗余，所以 TiDB 的测试性能才会如此的高，符合空间换时间的基本原理。

                    - TiKV 还发明了一层虚拟的“分片”(Region)，将数据切分成 96MB~144MB 的多个分片，并且用 Raft 算法将其分散到多个节点上存储。注意，在 TiKV 内部存储用户数据的那个 RocksDB 内部，多个分片是致密存储的，分片之间并没有逻辑关系。

        - 和 TiKV 并列的还有一个 TiFlash 列存储引擎，是为了 OLAP 在线数据分析用的

        - TiDB 对 CAP 和不可能三角的抉择
            - TiDB 选择了保证一致性
            - 放弃了事务隔离
            - 和 Spanner 一样放弃了可用性

        - 一句话概括 TiDB：①搭建在 KV 数据库集群之上的②兼容部分 MySQL 语法的③有一些事务处理能力的高性能数据库。

    - OceanBase 设计思路

        - 以最新的 OceanBase 4.0 版本的架构为目标进行讨论。

        - TiDB 底层数据叫分片，那 OceanBase 为什么叫分区呢？因为分片的意思只是数据被分开了（本身 KV 数据之间也没关系），但分区表示的是分区内部的数据之间是有联系的

            - OceanBase 的每个节点本身，依然是一个关系型数据库，拥有自己的 SQL 引擎、存储引擎和事务引擎。

            - OceanBase 在建表时就需要设定数据分区规则，之后每一行数据都属于且仅属于某个分区。在数据插入和查询的时候，需要找到这一行数据所在的区，进行针对性地路由。这和第一代分布式——中间件的思想一致。

            - 这么做相当于简单地并行执行多条 SQL，以数据切分和数据聚合为代价，让数据库并行起来。而这个数据切分和数据聚合的代价，可以很小，也可以很大，需要 OceanBase 进行精细的性能优化。

            - 分区之间，通过 Multi-Paxos 协议来同步数据：每一个逻辑分区都会有多个副本分布在多台机器上，只有其中一个副本会成为 leader，并接受写请求。这里的架构和 PolarDB 一样了，此时，客户端的一致性读需要网关(OBProxy)来判断，主从之间的同步是有可感知的延迟的。

        ![image](./Pictures/计算机哲学/OceanBase存储架构.avif)

        - OceanBase 数据库的存储引擎基于 LSM Tree 架构
            - 将数据分为静态基线数据（放在 SSTable 中）和动态增量数据（放在 MemTable 中）两部分
            - SSTable 是只读的，一旦生成就不再被修改，存储于磁盘
            - MemTable 支持读写，存储于内存。数据库 DML 操作插入、更新、删除等首先写入 MemTable，等到 MemTable 达到一定大小时转储到磁盘成为 SSTable
            - 在进行查询时，需要分别对 SSTable 和 MemTable 进行查询，并将查询结果进行归并，返回给 SQL 层归并后的查询结果。

            - 同时在内存实现了 Block Cache 和 Row cache，来避免对基线数据的随机读。
                - 当内存的增量数据达到一定规模的时候，会触发增量数据和基线数据的合并，把增量数据落盘。同时每天晚上的空闲时刻，系统也会自动每日合并。

            - OceanBase 数据库本质上是一个基线加增量的存储引擎，在保持 LSM-Tree 架构优点的同时也借鉴了部分传统关系数据库存储引擎的优点。

            - OceanBase 除了记录日志(Redo Log)并修改内存缓存(MemTable)之外，只要内存充足，白天 OceanBase 不会主动将内存缓存中的数据刷洗到 SSTable 里的，官方更推荐每天凌晨定时刷洗。这是什么思想？可以说是空间(内存)换时间，也可以说是拿未来的时间换现在的时间。

        - OceanBase 用内存 B+ 树和磁盘 LSM-Tree 共同构成了数据读写体系，和InnoDB 是多么像啊！只是 OceanBase 做的更细：跟 TiDB 相比，就像是在 TiKV 上面加了一层 Buffer Pool 一样。

        - OceanBase 性能来源之一——充分的内存缓存

            - 磁盘一定是慢的，内存一定是快的，所以在数据量大于机器的内存容量时，各种数据库的性能差别可以聚焦到一个点上：内存利用效率，即热数据命中内存缓存的概率。

            - 为了提升缓存命中率，OceanBase 设计了很多层内存缓存，尽全力避免了对磁盘的随机读取，只让 LSM-Tree 的磁盘承担它擅长的连续读任务，包子有肉不在褶上，商用环境中捶打过的软件就是不一样，功夫都在细节里

            ![image](./Pictures/计算机哲学/OceanBase充分利用内存.avif)

                - BloomFilter Cache：布隆过滤器缓存
                - MemTable：同时使用 B+ 树和 HashTable 作为内存引擎，分别处理不同的场景
                - Row Cache：存储 Get/MultiGet 查询的结果
                - Block Index Cache：当需要访问某个宏块的微块时，提前装载这个宏块的微块索引
                - Block Cache：像 Buffer Pool 一样缓存数据块(InnoDB 页)
                - Fuse Row Cache：在 LSM-Tree 架构中, 同一行的修改可能存在于不同的 SSTable 中，在查询时需要对各个 SSTable 查询的结果进行熔合，对于熔合结果缓存可以更大幅度地支持热点行查询
                - Partition Location Cache：用于缓存 Partition 的位置信息，帮助对一个查询进行路由
                - Schema Cache：缓存数据表的元信息，用于执行计划的生成以及后续的查询
                - Clog Cache：缓存 clog 数据，用于加速某些情况下 Paxos 日志的拉取

        - OceanBase 性能来源之二——直接变身内存数据库

            - 把一整天的新增和修改的数据全部放到内存里，相当于直接变身成了内存数据库（还会用 B 树和 Hashtable 存两份），确实是一种终极的性能优化手段

                - 为了极致的性能，OceanBase 直接取消了 MySQL 中“后台进程每秒将 redo log 刷写到 ibd 文件”这一步，等于放大了集群宕机重启后恢复数据的时间（重启后需要大量的时间和磁盘 IO 将 redo log 刷写入磁盘），然后把这件事放到半夜去做

        - OceanBase 如何提升并行查询和数据聚合的性能

            - 传统的中间件 Sharding 技术中，也会做一些并行查询，但是他们做的都是纯客户端的查询：proxy 作为标准客户端，分别从多台机器拿到数据之后，用自己的内存进行数据处理。有两个问题：

                - 1.只能做简单的并行和聚合，复杂的做不了
                - 2.后端数据库相互之间无通信，没有很好地利用资源，总响应时间很长。

            - OceanBase 让一切尽可能地并行起来了：在某台机器上的 proxy(OBServer) 接到请求以后，它会担任协调者的角色，将任务并行地分发到多个其他的 OBServer 上执行；同时，将多个子计划划分到各个节点上以后，会在各节点之间建立 M*N 个网络通信 channel，并行地传输信息；此外，OceanBase 还对传统数据库的执行计划优化做了详细的拆分，对特定的关键词一个一个地做分布式优化，才最终达成了地表最强的成就。

        - OceanBase 对 CAP 和不可能三角的抉择：只能做到最终一致性

- Shared-Nothing、Shared-Memory 和 Shared-Disk

    - Shared-Nothing：两台物理机，除了网络通信之外，不进行任何资源共享，CPU、内存、磁盘都是独立的。这样，整个系统的理论性能就可以达到单机的二倍。

    - Shared-Disk：多台机器通过共享 SAN 磁盘的方式协同工作，让系统整体性能突破单机的极限。

        - Oracle RAC 是这个架构的佼佼者，不过它的成功并不在于磁盘，而在于它的分布式锁(CACHE FUSION)：RAC 利用时间戳和分布式锁实现了分布式事务和多台机器同时可写，大幅提升了集群的性能。注意，时间戳在这里又出现了。CACHE FUSION 其实已经可以被称作 Shared-Memory 了。感兴趣的可以自己了解，我们不再深入。

    - IBM 推出了 Shared-Nothing 的 DB2 ICE。十年后，Oracle RAC 发展的如火如荼，而 DB2 ICE 已经消失在了历史的长河中。

    - 2012 年 Google 发布了 Spanner 论文，在非常成熟的世界上最大规模的 KV 数据库之上，构建 SQL 层，实现持久化、事务和多版本并发控制，扛起了 Shared-Nothing 技术方向的大旗，直到今天。

- 列存储思想

    - 在读取一行数据时，显然 B+ 树的效率无人能及，但是当我们需要读取 100 万行数据中的某一列时，B+ 树就需要把这 100 万行数据全部载入内存：每次将一页 16KB 载入内存，循环这一页内的 14 行数据，把这个特定的字段复制出来；重复执行这个操作 71429 次，才能得到我们想要的结果。这显然是 B+ 树非常不擅长的需求。

    - 而列存储将数据基于行的排布翻转过来了：所有数据基于列，致密地排列在磁盘上，这样对某一列的读取就变成了磁盘顺序读，即便是机械磁盘，顺序读也非常快。

    - 列存储数据库 clickhouse 颇有毛子暴力美学的典范，和 Nginx 的气质很像

        - clickhouse 推荐使用尽量多的 CPU 核心，对单核性能无要求，我拿 E5-V2 旧服务器测过，速度确实非常惊人，8000 万行的表，查询起来不仅比 MySQL 快，比 Hadoop 也快特别多。

### 高并发的哲学原理（十）-- 理论无限容量：站在地球表面

- [岁寒博客：高并发的哲学原理（十）-- 理论无限容量：站在地球表面](https://github.com/johnlui/PPHC/tree/main/10.%20%E7%90%86%E8%AE%BA%E6%97%A0%E9%99%90%E5%AE%B9%E9%87%8F%EF%BC%9A%E7%AB%99%E5%9C%A8%E5%9C%B0%E7%90%83%E8%A1%A8%E9%9D%A2)

- 如果两个 API 的数据落到同一张表上，那他们两个就属于同一个系统。

    - 如果两个系统的数据库不在一起，那他们就不是一个系统，就像拼多多有 7.5 亿月活用户，淘宝有 8.5 亿，你不能说“拼宝宝”电商系统有 16 亿月活用户一样。

    - 在一个电商系统内，用户 API 和商品 API 似乎没有多对多交集？是的，这就是微服务架构的拆分逻辑。

- 微服务架构

    - 微服务的拆分方式，反映的是其背后技术团队的组织方式。

        - 技术团队的组织方式是什么决定的呢？是由系统内各部分天然的内聚性决定的：用户相关的业务和商品相关的业务都有很强的内聚性，他们之间不会主动发生关联，但他们会分别和订单发生关联。

        - 在大量调用的 API 中，一次携带了数据写入的请求一定只会对单个微服务进行写入，但会对多个微服务进行数据读取

        - 如果某个头部 API 请求会对两个微服务系统进行写入，那说明微服务的划分出了问题，需要调整系统结构划分

        - 把几乎不相互写入的数据拆到两个数据库上，这种组织形态在人类社会随处可见

    - 一个电商订单的生命周期内对用户、商品、订单三个部分数据库的读写情况：
        - 1.搜索：商品数据库-读
        - 2.点进详情：商品数据库-读，用户数据库-读（地址、会员）
        - 3.立即购买：商品数据库-读，用户数据库-读，订单数据库-写
        - 4.支付：订单数据库-读写，用户数据库-读
        - 5.商家后台查看并处理订单：订单数据库-读写，用户数据库-读，商品数据库-读

        - 大部分情况下，每一步都只有一个主要的微服务被需要，其它微服务都处于辅助地位：只读，且大部分都是单点读取。这就为我们降低了数据库单点的负载——只要把这三个微服务部署到三个独立的数据库上，就可以通过 API 调用的形式降低单个数据库的极限 QPS。

- 削峰：

    - 1.缓存：可以削读的峰
        -  OceanBase 就采用了一种终极缓存方案

    - 2.队列：可以削写的峰
        - 排队的思维特别好理解，而现实中防止超售功能也确实是基于排队功能做的。
        - 传统数据库的事务隔离属于强迫用户等待，而现在大多使用队列系统来处理排队，排队这件事情才真正异步起来了。

    - 3.奇技淫巧
        - 继续找东西和信息之神交换：过去的时间换现在的时间。
        - 在大促之前，先把订单生成好，然后用户下单时直接写入用户信息：不需要执行“检查库存”这个单点操作了，负载低了很多。

    - 现实世界中的削峰：

        - 在削峰的操作下，200 万 QPS 的 PolarDB 集群在 Redis 集群的配合下，是可以顶住 100 万 API QPS 的。
        - 史上流量最大的那一年双 11，每秒订单创建最大值仅为 58.3 万笔，这已经是这个地球上的最高记录了。

        - 但是，现实世界中，一切都要讲 ROI（收益成本之比），搞一个顶配的 PolarDB 集群确实可以顶住巅峰时期一百万 API QPS，但是你老板看着账单肯定会肉痛，那，该如何省钱呢？

            - 基于地理位置对应用和数据库分区：

                - 实际上，地理上被隔开的两个人，在系统内还真没什么机会需要相互查询对方的数据，这就是我们能基于地理位置对应用和数据库进行分区的逻辑原因。

                - 为什么非要全国的用户访问同一个数据库呢？我们可以利用微服务思想对业务系统和数据进行拆分：北京的用户和上海的用户，理论上讲可以只访问“本地天猫”。

                - 拆分DNS：不同地区的人，对同一个域名进行访问，可以获得两个公网 ip，这样“本地天猫”就实现了。

                    - DNS 几乎完全放弃了一致性，但却实现了极高的可用性和分区容错性。

                - 类 DNS 哲学思想：Consul 和 Kong：
                    - gossip 协议也是这个思想：让消息像病毒一样传播，能够实现最终一致性就行了，要啥自行车。
                    - Kong集群：所有节点每 5 秒从数据库读取最新的配置文件，然后，这些节点就成了一个行为完全一致的集群啦。“想那么多干什么，短时间内多个节点的行为不一致，就让他们不一致好了，5 秒之后不就一致了。”


- 跟 Clickhouse 学习如何打造高并发系统

    - MySQL、MongoDB、Hadoop，谁也没有老子快。为什么 Clickhouse 这么快呢？

        - 1.列存储还压缩：首先，它将数据以列为单位组织起来，压缩后存入磁盘上一个又一个的 block，这些 block 就像 InnoDB 的 16KB 页一样，只是它更大（64KB~1MB）。

        - 2.并行能力：每个 block 内，Clickhouse 还用“稀疏索引”的方式，将每一列的数据划分为了多个 granularity(颗粒度)，然后给每个 granularity 分配一个 CPU 核心进行并行计算，并且它还利用 SSE4.2 指令集，利用 CPU 的 SIMD(Single Instruction Multiple Data) 指令，在 CPU 寄存器层面进行并行操作。

        - 3.放弃内存缓存：由于所有数据都在磁盘上，而节点的 CPU 又直接和磁盘数据打交道，所以 Clickhouse 实现了真正的并行：增加 CPU 核心数就能提升系统容量，无论在不在同一台机器上都行，反正 CPU 相互之前完全不需要通信。这样，Clickhouse 通过堆核心数就能够实现系统容量的“近线性扩展”。

- 熔断：这个词在技术圈的流行应该有微博一半功劳，压力一大就熔断：主动停止不重要的服务，断尾自救，争取让核心业务不挂。

- 限流：限制一部分地区、一部分用户的访问，以保护整个集群不崩，一般用于限制单个用户对系统造成的压力过大，对面很可能是机器人。

- 宕机例子：

    - Facebook 2021年 10 月 4 号宕机。Facebook 的用户不可谓不多，对高可用的投入不可谓不足，为什么还是会整个公司完全宕机 7 小时呢？

        - 事故的起因是一个错误的命令意外断开了 Facebook 的 DNS 服务，结果问题大了
            - 所有客户端 API 失效，用户无法获得任何信息
            - 数据中心 VPN 服务失效，无法远程登录到数据中心内的设备上
            - 亲自去机房，发现门禁卡刷不开门，破拆后才接触到物理设备，插上显示器和键盘才能解决问题
            - 邮件、Google 文档、Zoom 都登不上
            - 办公大楼的门禁卡系统也失效了，无法刷开会议室的门，甚至无法离开办公楼

    - 阿里云香港一个数据中心因为空调故障导致整个数据中心宕机超过 24 小时

## Little’s Law（利特尔法则）

- [infoq：跟我一起认识 Little’s Law](https://www.infoq.cn/article/uzfdjVym5vEPRA8DOxYG)

    - Little’s Law：延迟和吞吐的关系是受并发数影响的，抛开并发数去找另外两者的关系是没有规律的。

        - 并发用户数：指真正对服务发送请求的用户数量，需要注意和在线用户数的区别

            - 例子：在线用户数为 1000，其中只有 100 个用户的操作触发了与远端服务的交互，并发用户数是 100

        - 响应时间：Little’s Law 中是“平均响应时间”，而实际工作中“分位值”来作为响应时间的统计值来衡量性能的。平均值只是作为一个辅助参考。

            - 例子：平均工资通常没多大参考价值，有可能很多人是被平均的。

            - 分为值：假如一共有100个请求，那么排在第90位的响应时间就是90分位值。有90分位、95分位、75分位。
                ![image](./Pictures/计算机哲学/分为值.avif)

    - 并发数 = 吞吐量 * 响应时间

        - 假如一个程序只有 1 个线程，这个线程每秒可以处理 10 次事件，那么我们说这个程序处理单次事件的延迟为 100ms，吞吐为 10 次/秒。

        - 假如一个程序有 4 个线程，每个线程每秒可以处理 5 次事件，那么我们说这个程序处理单次事件的延迟为 200ms，吞吐为 20 次/秒。

        - 假如一个程序有 1 个线程，每个线程每秒可以处理 20 次事件，那么我们说这个程序处理单次事件的延迟为 50ms，吞吐为 20 次/秒。

    ![image](./Pictures/计算机哲学/Little’s-Law.avif)

    - 拐点：并发用户数增加，吞吐量开始出现下降的趋势，同时响应时间也开始增大

    - 在“拐点”之前和刚进入拐点这段区域：系统是“稳定”的，并发数、吞吐量、平均响应时间是符合 Little’s Law 公式的。

## 长尾理论

- 长尾理论：原来不受到重视的销量小但种类多的产品或服务由于总量巨大，累积起来的总收益超过主流产品的现象。在互联网领域，长尾效应尤为显著。

    - 例子：亚马逊40%的书本销售来自于本地书店里不卖的书本。音乐影视串流市场、智能手机应用市场、线上游戏市场陆续发生这种现象，网络选择客制化的兴起也让实体市场产品逐渐零碎化，例如名不见经传的餐厅在网络市场下爆红。

    - 例子：亚马逊一半左右的销售来自于比较热门的商品，而另一半却来自相对不那么热门的商品。这跟传统的“二八定律（80%的业绩来自20%的产品）”完全相反

