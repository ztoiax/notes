# 分布式锁

- [腾讯技术工程：一文讲透Redis分布式锁安全问题](https://cloud.tencent.com/developer/article/2332108)

- 为什么需要分布式锁？

    - 单机互诉锁：当我们在同一台机器的不同进程，想要同时操作一个共享资源（例如修改同一个文件），我们可以使用操作系统提供的「文件锁」或「信号量」来做互斥。

        - 分布式锁：这些互斥操作，都仅限于线程、进程处于同一台机器上，如果是分布在「不同机器」上的不同进程，要同时操作一个共享资源（例如修改数据库的某一行），就需要引入「分布式锁」来解决这个问题了。

    - 想要实现分布式锁，必须借助一个外部系统，所有进程都去这个系统上申请「加锁」。

        - 这个外部系统，可以是 MySQL，也可以是 Redis、Zookeeper、Etcd。但在高并发业务场景下，为了追求更好的性能，我们通常会选择使用 Redis。

- 基于 Redis 分布式锁怎么实现？从最简单的开始讲起

    - SETNX 命令实现：

        - 加锁：
            ```redis
            SETNX lock 1
            ```

        - 释放锁：
            ```redis
            DEL lock
            ```

        - 有死锁问题：当客户端 1 拿到锁后，如果发生下面的场景，就会造成「死锁」
            - 1.程序处理业务逻辑异常，没及时释放锁
            - 2.进程挂了，没机会释放锁

            - 这个客户端就会一直占用这个锁，而其它客户端就「永远」拿不到这把锁了（锁饥饿）。

    - 解决死锁问题：

        - 解决问题1（程序在处理业务逻辑时发生异常，没及时释放锁）：对这块业务代码加上异常处理，保证无论业务逻辑是否异常，都可以把锁释放掉，例如在 Go 的 defer、Java/Python 的 finally 中及时释放锁：

            ```
            Go：defer redis.del(key)
            Java：try ... catch ... fianlly: redis.del(key)
            Python：try ... except ... fianlly: redis.del(key)
            ```

        - 解决问题2（进程挂了，没机会释放锁）：加上一个「租期」。在 Redis 中实现时，就是给这个 key 设置一个「过期时间」。

            - 在 Redis 2.6.12 之后，Redis 扩展了 SET 命令的参数，把 NX/EX 集成到了 SET 命令中，用这一条命令就可以了：
                ```redis
                // 一条命令保证原子性执行
                SET lock 1 EX 10 NX
                ```
    - 存在2个问题：锁过期时间问题、锁被别人释放问题

        | 客户端 1                                                              | 客户端 2 |
        |-----------------------------------------------------------------------|----------|
        | 加锁成功，开始操作共享资源                                            |          |
        | 操作共享资源的时间，「超过」了锁的过期时间，锁被「自动释放」（问题1） |          |
        |                                                                       | 加锁成功 |
        | 操作共享资源完成，释放锁（问题2：但释放的是客户端 2 的锁）                   |          |

        - 解决锁过期时间问题：给锁续期
            - 加锁时，先设置一个过期时间，然后我们开启一个「守护线程」，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行「续期」，重新设置过期时间。
            - 如果你是 Java 技术栈，幸运的是，已经有一个库把这些工作都封装好了：Redisson。
                - Redisson 是一个 Java 语言实现的 Redis SDK 客户端，在使用分布式锁时，它就采用了「自动续期」的方案来避免锁过期，这个守护线程我们一般也把它叫做「看门狗」线程。
                - 除此之外，这个 SDK 还封装了很多易用的功能：可重入锁、乐观锁、公平锁、读写锁、Redlock（红锁）

        - 解决锁被别人释放问题：客户端在加锁时，设置一个只有自己知道的「唯一标识」进去

            - 加锁
            ```redis
            // 锁的VALUE设置为UUID
            SET lock $uuid EX 20 NX
            ```

            - 释放锁
            ```lua
            // 锁是自己的，才释放
            if redis.get("lock") == $uuid:
                redis.del("lock")
            ```

    - 释放锁原子性问题： GET + DEL 是两条命令

        | 客户端 1                                       | 客户端 2         |
        |------------------------------------------------|------------------|
        | 执行 GET，判断锁是自己的                       |                  |
        | 执行 GET 结束后，这个锁刚好超时自动释放        |                  |
        |                                                | 又获取到了这个锁 |
        | 执行 DEL 时，释放的却是客户端 2 的锁（冲突）   |                  |

        - 解决方法：Lua 脚本
            ```lua
            // 判断锁是自己的，才释放
            if redis.call("GET",KEYS[1]) == ARGV[1]
            then
                return redis.call("DEL",KEYS[1])
            else
                return 0
            end
            ```

    - Redis 分布锁小结：
        - 1.加锁：SET unique_id EX $expire_time NX
        - 2.操作共享资源：没操作完之前，开启守护线程，定期给锁续期
        - 3.释放锁：Lua 脚本，先 GET 判断锁是否归属自己，再 DEL 释放锁
        ![image](./Pictures/分布式/redis实现分布式锁.avif)

## Redlock（红锁）

- 那当「主从发生切换」时，这个分布锁会依旧安全吗？

    | 主从切换场景
    |------------------------------------------------------------------|
    | 客户端 1 在主库上执行 SET 命令，加锁成功                         |
    | 此时，主库异常宕机，SET 命令还未同步到从库上（主从复制是异步的） |
    | 从库被哨兵提升为新主库，这个锁在新的主库上，丢失了！             |

    - Redis 作者提出的Redlock方案，就是解决这个分布式问题

- Redlock 的方案基于 2 个前提：
    - 1.不再需要部署从库和哨兵实例，只部署主库
    - 2.但主库要部署多个，官方推荐至少 5 个实例
        - 不是部署 Redis Cluster，就是部署 5 个简单的 Redis 实例。
- Redlock流程
    - 1.客户端先获取「当前时间戳 T1」
    - 2.客户端依次向这 5 个 Redis 实例发起加锁请求（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁
        ![image](./Pictures/分布式/redlock.avif)
    - 3.如果客户端从 >=3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳 T2」，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败
    - 4.加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）
    - 5.加锁失败，向「全部节点」发起释放锁请求（前面讲到的 Lua 脚本释放锁）

    - 有 4 个重点：
        - 1.客户端在多个 Redis 实例上申请加锁
        - 2.必须保证大多数节点加锁成功
        - 3.大多数节点加锁的总耗时，要小于锁设置的过期时间
        - 4.释放锁，要向全部节点发起释放锁请求

### 争议

- [How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)

- 分布式专家Martin，是英国剑桥大学的一名分布式系统研究员。写的这本分布式系统领域的书《数据密集型应用系统设计》，豆瓣评分高达 9.7，好评如潮。

- Martin 对于 Redlock 的质疑。主要阐述了 4 个论点：

    - 1.分布式锁的目的是什么？

        - 1.效率：使用分布式锁的互斥能力，是避免不必要地做同样的两次工作（例如一些昂贵的计算任务）。
            - 如果锁失效，并不会带来「恶性」的后果，例如发了 2 次邮件等，无伤大雅。

        - 2.正确性（一致性）：如果锁失效，会造成多个进程同时操作同一条数据，产生的后果是数据严重错误、永久性不一致、数据丢失等恶性问题

        - 他认为
            - 如果是效率：那么使用单机版 Redis 就可以了，即使偶尔发生锁失效（宕机、主从切换），都不会产生严重的后果。而使用 Redlock 太重了，没必要。
            - 如果是为了正确性：Martin 认为 Redlock 根本达不到安全性的要求，也依旧存在锁失效的问题！

    - 2.锁在分布式系统中会遇到的问题

        - Martin 表示，一个分布式系统，更像一个复杂的「野兽」，存在着你想不到的各种异常情况。

        - 这些异常场景主要包括三大块，这也是分布式系统会遇到的三座大山：NPC。
            - N：Network Delay，网络延迟
            - P：Process Pause，进程暂停（GC）
            - C：Clock Drift，时钟漂移

        - Martin 用一个进程暂停（GC）的例子，指出了 Redlock 安全性问题：

            - 即使是使用没有 GC 的编程语言，在发生网络延迟时，也都有可能导致 Redlock 出现问题，这里 Martin 只是拿 GC 举例。

            | 客户端 1                                                       | 客户端 2                       |
            |----------------------------------------------------------------|--------------------------------|
            | 请求锁定节点 A、B、C、D、E                                     |                                |
            | 拿到锁后，进入 GC（时间比较久）。所有 Redis 节点上的锁都过期了 |                                |
            |                                                                | 获取到了 A、B、C、D、E 上的锁  |
            | GC 结束，认为成功获取锁                                        |                                |
            |                                                                | 也认为获取到了锁，发生「冲突」 |

            ![image](./Pictures/分布式/redlock-出现GC后的安全问题.avif)

    - 3.假设时钟正确的是不合理的

        - 当多个 Redis 节点「时钟」发生问题时，也会导致 Redlock 锁失效：
            - 客户端 1 获取节点 A、B、C 上的锁，但由于网络问题，无法访问 D 和 E
            - 节点 C 上的时钟「向前跳跃」，导致锁到期
            - 客户端 2 获取节点 C、D、E 上的锁，由于网络问题，无法访问 A 和 B
            - 客户端 1 和 2 现在都相信它们持有了锁（冲突）

        - Martin 觉得，Redlock 必须「强依赖」多个节点的时钟是保持同步的，一旦有节点时钟发生错误，那这个算法模型就失效了。

            - 即使 C 不是时钟跳跃，而是「崩溃后立即重启」，也会发生类似的问题。

            - Martin 继续阐述，机器的时钟发生错误，是很有可能发生的：
                - 系统管理员「手动修改」了机器时钟
                - 机器时钟在同步 NTP 时间时，发生了大的「跳跃」

        - 总之，Martin 认为，Redlock 的算法是建立在「同步模型」基础上的，有大量资料研究表明，同步模型的假设，在分布式系统中是有问题的。

            - 在混乱的分布式系统的中，你不能假设系统时钟就是对的，所以，你必须非常小心你的假设。

    - 4.提出 fecing token 的方案，保证正确性

        - 读者著：类似于版本号

        - fecing token的流程：
            - 1.客户端在获取锁时，锁服务可以提供一个「递增」的 token
            - 2.客户端拿着这个 token 去操作共享资源
            - 3.共享资源可以根据 token 拒绝「后来者」的请求

            ![image](./Pictures/分布式/fecing_token方案.avif)

        - 这样一来，无论 NPC 哪种异常情况发生，都可以保证分布式锁的安全性，因为它是建立在「异步模型」上的。

- Redis 作者 Antirez 的反驳：重点有 3 个

    - [Is Redlock safe?](http://antirez.com/news/101)

    - 1.解释时钟问题

        - Redis 作者一眼就看穿了对方提出的最为核心的问题：时钟问题。
        - Redis 作者表示，Redlock 并不需要完全一致的时钟，只需要大体一致就可以了，允许有「误差」。
            - 例如要计时 5s，但实际可能记了 4.5s，之后又记了 5.5s，有一定误差，但只要不超过「误差范围」锁失效时间即可，这种对于时钟的精度的要求并不是很高，而且这也符合现实环境。

        - 对于对方提到的「时钟修改」问题，Redis 作者反驳到：
            - 手动修改时钟：不要这么做就好了，否则你直接修改 Raft 日志，那 Raft 也会无法工作...
            - 时钟跳跃：通过「恰当的运维」，保证机器时钟不会大幅度跳跃（每次通过微小的调整来完成），实际上这是可以做到的

    - 2.解释网络延迟、GC 问题

        - Redis 作者反驳那个场景假设其实是有问题的，Redlock 是可以保证锁安全的。

            - 如果在redlock步骤 1-3 发生了网络延迟、进程 GC 等耗时长的异常情况，那在第 3 步 T2 - T1，是可以检测出来的，如果超出了锁设置的过期时间，那这时就认为加锁会失败，之后释放所有节点的锁就好了！

            - 如果对方认为，发生网络延迟、进程 GC 是在步骤 3 之后，也就是客户端确认拿到了锁，去操作共享资源的途中发生了问题，导致锁失效，那这不止是 Redlock 的问题，任何其它锁服务例如 Zookeeper，都有类似的问题，这不在讨论范畴内。

            - redis作者反驳的观点是，Martin提出GC问题场景，不止redlock，Zookeeper等也有这样的问题。
                - 客户端在拿到锁之前，无论经历什么耗时长问题，Redlock 都能够在第 3 步检测出来
                - 客户端在拿到锁之后，发生 NPC，那 Redlock、Zookeeper 都无能为力

    - 3.质疑 fencing token 机制

        - 1.这个方案必须要求要操作的「共享资源服务器」有拒绝「旧 token」的能力。

            - 例如，要操作 MySQL，从锁服务拿到一个递增数字的 token，然后客户端要带着这个 token 去改 MySQL 的某一行，这就需要利用 MySQL 的「事务隔离性」来做。

                ```sql
                // 两个客户端必须利用事务和隔离性达到目的
                // 注意 token 的判断条件
                UPDATE
                    table T
                SET
                    val = $new_val, current_token = $token
                WHERE
                    id = $id AND current_token < $token
                ```

            - 但如果操作的不是 MySQL 呢？例如向磁盘上写一个文件，或发起一个 HTTP 请求，那这个方案就无能为力了，这对要操作的资源服务器，提出了更高的要求。
                - 也就是说，大部分要操作的资源服务器，都是没有这种互斥能力的。

        - 2.退一步讲，即使 Redlock 没有提供 fecing token 的能力，但 Redlock 已经提供了随机值（就是前面讲的 UUID），利用这个随机值，也可以达到与 fecing token 同样的效果。

            - 笔者还原流程：
                - 1.客户端使用 Redlock 拿到锁
                - 2.客户端在操作共享资源之前，先把这个锁的 VALUE，在要操作的共享资源上做标记
                - 3.客户端处理业务逻辑，最后，在修改共享资源时，判断这个标记是否与之前一样，一样才修改（类似 CAS 的思路）

            - 还是以 MySQL 为例：

                - 1.客户端使用 Redlock 拿到锁
                - 2.客户端要修改 MySQL 表中的某一行数据之前，先把锁的 VALUE 更新到这一行的某个字段中（这里假设为 current_token 字段)
                - 3.客户端处理业务逻辑
                - 4.客户端修改 MySQL 的这一行数据，把 VALUE 当做 WHERE 条件，再修改

                ```sql
                UPDATE
                    table T
                SET
                    val = $new_val
                WHERE
                    id = $id AND current_token = $redlock_value
                ```

                - 可见，这种方案依赖 MySQL 的事物机制，也达到对方提到的 fecing token 一样的效果。

            - 但这里还有个小问题，是网友参与问题讨论时提出的：两个客户端通过这种方案，先「标记」再「检查+修改」共享资源，那这两个客户端的操作顺序无法保证啊？

                - 而用 Martin 提到的 fecing token，因为这个 token 是单调递增的数字，资源服务器可以拒绝小的 token 请求，保证了操作的「顺序性」！

                - Redis 作者对于这个问题做了不同的解释，我觉得很有道理，他解释道：分布式锁的本质，是为了「互斥」，只要能保证两个客户端在并发时，一个成功，一个失败就好了，不需要关心「顺序性」。

                    - 前面 Martin 的质疑中，一直很关心这个顺序性问题，但 Redis 的作者的看法却不同。

## 基于 Zookeeper 的分布式锁

- 流程

    - 1.客户端 1 和 2 都尝试创建「临时节点」，例如 /lock
    - 2.假设客户端 1 先到达，则加锁成功，客户端 2 加锁失败
    - 3.客户端 1 操作共享资源
    - 4.客户端 1 删除 /lock 节点，释放锁

    ![image](./Pictures/分布式/Zookeeper分布式锁原理.avif)

    - Zookeeper 不像 Redis 那样，需要考虑锁的过期时间问题，它是采用了「临时节点」，保证客户端拿到锁后，只要连接不断，就可以一直持有锁。

    - 如果客户端 1 异常崩溃了，这个临时节点也会自动删除，保证了锁一定会被释放。

- 不错，没有锁过期的烦恼，还能在异常时自动释放锁，是不是觉得很完美？

    - 其实不然。客户端 1 创建临时节点后，Zookeeper 是如何保证让这个客户端一直持有锁呢？

        - 客户端 1 此时会与 Zookeeper 服务器维护一个 Session，这个 Session 会依赖客户端「定时心跳」来维持连接。

        - 如果 Zookeeper 长时间收不到客户端的心跳，就认为这个 Session 过期了，也会把这个临时节点删除。

            ![image](./Pictures/分布式/Zookeeper心跳.avif)

    - GC（进程暂停）问题对 Zookeeper 的锁有何影响：

        | 客户端 1                                                | 客户端 2                          |
        |---------------------------------------------------------|-----------------------------------|
        | 创建临时节点 /lock 成功，拿到了锁                       |                                   |
        | 发生长时间 GC                                           |                                   |
        | 无法给 Zookeeper 发送心跳，Zookeeper 把临时节点「删除」 |                                   |
        |                                                         | 创建临时节点 /lock 成功，拿到了锁 |
        | GC 结束，它仍然认为自己持有锁（冲突）                   |                                   |

        - 这就是前面 Redis 作者在反驳的文章中提到的：如果客户端已经拿到了锁，但客户端与锁服务器发生「失联」（例如 GC），那不止 Redlock 有问题，其它锁服务都有类似的问题，Zookeeper 也是一样！

## 基于 Etcd 的分布式锁

- 流程：

    - Etcd 虽然没有像 Zookeeper 提供临时节点的概念，但 Etcd 提供了一个叫「租约」的概念。

        - 之后，我们定时给这个租约进行「续期」，保证我们创建的节点一直有效，一直持有锁。

            - 这里的定时给租约续期的步骤，和上面 Zookeeper 客户端定时给 Server 发心跳类似，其目的都是让服务端保持这个 Session 或 KV 持续有效。

    | 客户端 1                                   | 客户端 2                               |
    |--------------------------------------------|----------------------------------------|
    | 创建一个 lease 租约（设置过期时间）        |                                        |
    | 携带这个租约，创建 /lock 节点              |                                        |
    | 发现节点不存在，拿锁成功                   |                                        |
    |                                            | 同样方式创建节点，节点已存在，拿锁失败 |
    | 定时给这个租约「续期」，保持自己一直持有锁 |                                        |
    | 操作共享资源                               |                                        |
    | 删除 /lock 节点，释放锁                    |                                        |

    ![image](./Pictures/分布式/etcd分布式锁原理.avif)

- 它依旧存在和 Zookeeper 相同的GC（进程暂停）问题：

   | 客户端 1                                                        | 客户端 2                          |
   |-----------------------------------------------------------------|-----------------------------------|
   | 创建节点 /lock 成功，拿到了锁                                   |                                   |
   | 发生长时间 GC                                                   |                                   |
   | 无法向 Etcd 发请求给租约「续期」。租约到期，Etcd 「删除」锁节点 |                                   |
   |                                                                 | 创建临时节点 /lock 成功，拿到了锁 |
   | GC 结束，它仍然认为自己持有锁（冲突）                  |                                   |

- 结论：一个分布式锁，无论是基于 Redis 还是 Zookeeper、Etcd 实现，在极端情况下，都无法保证 100% 安全，都存在失效的可能。

- 但为什么我们总是能听到很多人使用 Zookeeper、Etcd 实现分布式锁呢？

    - 因为抛开安全性，Zookeeper 和 Etcd 相比于 Redis 实现分布锁，在功能层面有一个非常好用的特性：Watch。

        - 这个 API 允许客户端「监听」Zookeeper、Etcd 某个节点的变化，以此实现「公平」的分布式锁

# Zookeeper

- [腾讯技术工程：ZooKeeper 核心通识](https://cloud.tencent.com/developer/article/2181525)

- [腾讯技术工程：从0到1详解ZooKeeper的应用场景及架构](https://zhuanlan.zhihu.com/p/513804221?utm_id=0)

- [HelloGitHub：开篇：免费开源的趣讲 ZooKeeper 教程（连载）](https://baijiahao.baidu.com/s?id=1689467683287740035&wfr=spider&for=pc)

# etcd

- [阿里云开发者：学习分享｜Etcd/Raft 原理篇](https://www.163.com/dy/article/I83NV3JB0518E0HL.html)

- [腾讯技术工程：深入解读Raft算法与etcd工程实现](https://cloud.tencent.com/developer/article/2177980)
